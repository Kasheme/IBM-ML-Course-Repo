{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Import Keras objects for Deep Learning\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m  \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense, Flatten, Dropout, BatchNormalization\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam, SGD, RMSprop\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# DO NOT EDIT. Generated by api_gen.sh\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTypePolicy\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FloatDTypePolicy\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Function\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\api\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\api\\activations\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\activations\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m celu\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m elu\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exponential\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\activations\\activations.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\backend\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasTensor\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m any_symbolic_tensors\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\backend\\common\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_utils\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutocastScope\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable \u001b[38;5;28;01mas\u001b[39;00m KerasVariable\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\backend\\common\\dtypes.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m standardize_dtype\n\u001b[0;32m      7\u001b[0m BOOL_TYPES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[0;32m      8\u001b[0m INT_TYPES \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint16\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstateless_scope\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_stateless_scope\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstateless_scope\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_stateless_scope\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_name\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mVariable\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\utils\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_dataset_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_dataset_from_directory\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_file\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\utils\\audio_dataset_utils.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_utils\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow_io \u001b[38;5;28;01mas\u001b[39;00m tfio\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadPool\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\tree\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_same_paths\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_same_structure\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flatten\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\tree\\tree_api.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optree\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optree\u001b[38;5;241m.\u001b[39mavailable:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optree_impl \u001b[38;5;28;01mas\u001b[39;00m tree_impl\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dmtree\u001b[38;5;241m.\u001b[39mavailable:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dmtree_impl \u001b[38;5;28;01mas\u001b[39;00m tree_impl\n",
      "File \u001b[1;32mc:\\Users\\UK45812347\\AppData\\Local\\miniconda3\\envs\\keras\\Lib\\site-packages\\keras\\src\\tree\\optree_impl.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Register backend-specific node classes\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrackable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_structures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ListWrapper\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrackable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_structures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _DictWrapper\n\u001b[0;32m     16\u001b[0m     optree\u001b[38;5;241m.\u001b[39mregister_pytree_node(\n\u001b[0;32m     17\u001b[0m         ListWrapper,\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: (x, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m metadata, children: ListWrapper(\u001b[38;5;28mlist\u001b[39m(children)),\n\u001b[0;32m     20\u001b[0m         namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b2d5baf9c44f30959c5f05e9bcde91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading diabetes.csv:   0%|          | 0/23873 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to '.'\n"
     ]
    }
   ],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('./diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>6</td>\n",
       "      <td>102</td>\n",
       "      <td>90</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>35.7</td>\n",
       "      <td>0.674</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>14</td>\n",
       "      <td>59.4</td>\n",
       "      <td>2.420</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>60</td>\n",
       "      <td>33</td>\n",
       "      <td>192</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.966</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>70</td>\n",
       "      <td>32</td>\n",
       "      <td>68</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.122</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>160</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.674</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "410               6                     102              90              39   \n",
       "445               0                     180              78              63   \n",
       "35                4                     103              60              33   \n",
       "329               6                     105              70              32   \n",
       "709               2                      93              64              32   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "410        0  35.7              0.674   28             0  \n",
       "445       14  59.4              2.420   25             1  \n",
       "35       192  24.0              0.966   33             0  \n",
       "329       68  30.8              0.122   37             0  \n",
       "709      160  38.0              0.674   23             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all DeprecationWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.827\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for 108 parameters at the first layer:\n",
    "* We have 8 features + 1 bias term so thats 9 units in total. Then we have 12 hidden nodes. So the calculation is (8+1)*12 = 108\n",
    "* For the second layer it is going to be the 12 hidden nodes + the bias term so 12 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3075: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:977: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 16:04:05.384499: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2025-05-14 16:04:05.393192: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394320000 Hz\n",
      "2025-05-14 16:04:05.393951: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558a5f8f6fb0 executing computations on platform Host. Devices:\n",
      "2025-05-14 16:04:05.394001: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2025-05-14 16:04:05.461440: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 595us/step - loss: 0.6457 - acc: 0.6545 - val_loss: 0.6550 - val_acc: 0.6406\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.6444 - acc: 0.6545 - val_loss: 0.6537 - val_acc: 0.6406\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.6432 - acc: 0.6545 - val_loss: 0.6525 - val_acc: 0.6406\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.6421 - acc: 0.6545 - val_loss: 0.6513 - val_acc: 0.6406\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.6409 - acc: 0.6545 - val_loss: 0.6501 - val_acc: 0.6406\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.6399 - acc: 0.6545 - val_loss: 0.6490 - val_acc: 0.6406\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.6388 - acc: 0.6545 - val_loss: 0.6479 - val_acc: 0.6406\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.6378 - acc: 0.6545 - val_loss: 0.6468 - val_acc: 0.6406\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.6367 - acc: 0.6545 - val_loss: 0.6458 - val_acc: 0.6406\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.6358 - acc: 0.6545 - val_loss: 0.6447 - val_acc: 0.6406\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.6348 - acc: 0.6545 - val_loss: 0.6438 - val_acc: 0.6406\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.6338 - acc: 0.6545 - val_loss: 0.6428 - val_acc: 0.6406\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.6329 - acc: 0.6545 - val_loss: 0.6418 - val_acc: 0.6406\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.6320 - acc: 0.6545 - val_loss: 0.6409 - val_acc: 0.6406\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.6311 - acc: 0.6545 - val_loss: 0.6400 - val_acc: 0.6406\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 172us/step - loss: 0.6302 - acc: 0.6545 - val_loss: 0.6391 - val_acc: 0.6406\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.6294 - acc: 0.6545 - val_loss: 0.6382 - val_acc: 0.6406\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.6285 - acc: 0.6545 - val_loss: 0.6373 - val_acc: 0.6406\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.6277 - acc: 0.6545 - val_loss: 0.6365 - val_acc: 0.6406\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.6269 - acc: 0.6545 - val_loss: 0.6356 - val_acc: 0.6406\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.6261 - acc: 0.6545 - val_loss: 0.6348 - val_acc: 0.6406\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.6253 - acc: 0.6545 - val_loss: 0.6340 - val_acc: 0.6406\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.6244 - acc: 0.6545 - val_loss: 0.6331 - val_acc: 0.6406\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 181us/step - loss: 0.6237 - acc: 0.6545 - val_loss: 0.6323 - val_acc: 0.6406\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.6229 - acc: 0.6545 - val_loss: 0.6316 - val_acc: 0.6406\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.6221 - acc: 0.6545 - val_loss: 0.6308 - val_acc: 0.6406\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.6214 - acc: 0.6545 - val_loss: 0.6300 - val_acc: 0.6406\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.6206 - acc: 0.6545 - val_loss: 0.6292 - val_acc: 0.6406\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.6199 - acc: 0.6545 - val_loss: 0.6285 - val_acc: 0.6406\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.6192 - acc: 0.6545 - val_loss: 0.6277 - val_acc: 0.6406\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.6184 - acc: 0.6545 - val_loss: 0.6270 - val_acc: 0.6406\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.6177 - acc: 0.6545 - val_loss: 0.6262 - val_acc: 0.6406\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.6170 - acc: 0.6545 - val_loss: 0.6255 - val_acc: 0.6406\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.6163 - acc: 0.6545 - val_loss: 0.6248 - val_acc: 0.6406\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.6155 - acc: 0.6545 - val_loss: 0.6241 - val_acc: 0.6406\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.6148 - acc: 0.6545 - val_loss: 0.6234 - val_acc: 0.6406\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.6142 - acc: 0.6545 - val_loss: 0.6227 - val_acc: 0.6406\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.6134 - acc: 0.6545 - val_loss: 0.6220 - val_acc: 0.6406\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.6128 - acc: 0.6545 - val_loss: 0.6213 - val_acc: 0.6406\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.6121 - acc: 0.6545 - val_loss: 0.6206 - val_acc: 0.6406\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.6114 - acc: 0.6545 - val_loss: 0.6199 - val_acc: 0.6406\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.6107 - acc: 0.6545 - val_loss: 0.6192 - val_acc: 0.6406\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.6101 - acc: 0.6545 - val_loss: 0.6185 - val_acc: 0.6406\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.6094 - acc: 0.6545 - val_loss: 0.6179 - val_acc: 0.6406\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.6087 - acc: 0.6545 - val_loss: 0.6172 - val_acc: 0.6406\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.6080 - acc: 0.6545 - val_loss: 0.6165 - val_acc: 0.6406\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.6074 - acc: 0.6545 - val_loss: 0.6159 - val_acc: 0.6406\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.6067 - acc: 0.6545 - val_loss: 0.6152 - val_acc: 0.6406\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.6061 - acc: 0.6562 - val_loss: 0.6146 - val_acc: 0.6406\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.6055 - acc: 0.6562 - val_loss: 0.6139 - val_acc: 0.6406\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.6048 - acc: 0.6562 - val_loss: 0.6133 - val_acc: 0.6406\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.6042 - acc: 0.6562 - val_loss: 0.6126 - val_acc: 0.6406\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.6035 - acc: 0.6562 - val_loss: 0.6120 - val_acc: 0.6406\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.6029 - acc: 0.6562 - val_loss: 0.6114 - val_acc: 0.6406\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.6023 - acc: 0.6562 - val_loss: 0.6107 - val_acc: 0.6406\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.6017 - acc: 0.6580 - val_loss: 0.6101 - val_acc: 0.6406\n",
      "Epoch 57/200\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.6010 - acc: 0.6580 - val_loss: 0.6095 - val_acc: 0.6406\n",
      "Epoch 58/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.6004 - acc: 0.6597 - val_loss: 0.6089 - val_acc: 0.6406\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.5998 - acc: 0.6597 - val_loss: 0.6083 - val_acc: 0.6406\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.5992 - acc: 0.6615 - val_loss: 0.6076 - val_acc: 0.6406\n",
      "Epoch 61/200\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.5986 - acc: 0.6597 - val_loss: 0.6070 - val_acc: 0.6406\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.5980 - acc: 0.6597 - val_loss: 0.6064 - val_acc: 0.6458\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.5974 - acc: 0.6597 - val_loss: 0.6058 - val_acc: 0.6458\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.5968 - acc: 0.6597 - val_loss: 0.6052 - val_acc: 0.6458\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5962 - acc: 0.6615 - val_loss: 0.6046 - val_acc: 0.6458\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5956 - acc: 0.6615 - val_loss: 0.6040 - val_acc: 0.6510\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.5950 - acc: 0.6615 - val_loss: 0.6035 - val_acc: 0.6510\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.5944 - acc: 0.6615 - val_loss: 0.6029 - val_acc: 0.6510\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5938 - acc: 0.6615 - val_loss: 0.6023 - val_acc: 0.6562\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5932 - acc: 0.6615 - val_loss: 0.6017 - val_acc: 0.6615\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.5927 - acc: 0.6615 - val_loss: 0.6011 - val_acc: 0.6615\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5921 - acc: 0.6615 - val_loss: 0.6006 - val_acc: 0.6615\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.5915 - acc: 0.6632 - val_loss: 0.6000 - val_acc: 0.6615\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5909 - acc: 0.6632 - val_loss: 0.5994 - val_acc: 0.6615\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.5904 - acc: 0.6632 - val_loss: 0.5989 - val_acc: 0.6615\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5898 - acc: 0.6632 - val_loss: 0.5983 - val_acc: 0.6615\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.5892 - acc: 0.6667 - val_loss: 0.5977 - val_acc: 0.6667\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.5887 - acc: 0.6649 - val_loss: 0.5972 - val_acc: 0.6667\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5881 - acc: 0.6649 - val_loss: 0.5966 - val_acc: 0.6667\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.5876 - acc: 0.6632 - val_loss: 0.5961 - val_acc: 0.6667\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5870 - acc: 0.6684 - val_loss: 0.5955 - val_acc: 0.6667\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.5865 - acc: 0.6684 - val_loss: 0.5950 - val_acc: 0.6667\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5859 - acc: 0.6701 - val_loss: 0.5944 - val_acc: 0.6667\n",
      "Epoch 84/200\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5854 - acc: 0.6736 - val_loss: 0.5939 - val_acc: 0.6667\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.5848 - acc: 0.6719 - val_loss: 0.5934 - val_acc: 0.6667\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.5843 - acc: 0.6753 - val_loss: 0.5928 - val_acc: 0.6615\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.5837 - acc: 0.6753 - val_loss: 0.5923 - val_acc: 0.6667\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5832 - acc: 0.6753 - val_loss: 0.5918 - val_acc: 0.6771\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5827 - acc: 0.6753 - val_loss: 0.5912 - val_acc: 0.6771\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.5822 - acc: 0.6736 - val_loss: 0.5907 - val_acc: 0.6771\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5816 - acc: 0.6736 - val_loss: 0.5902 - val_acc: 0.6771\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.5811 - acc: 0.6736 - val_loss: 0.5897 - val_acc: 0.6823\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5806 - acc: 0.6736 - val_loss: 0.5891 - val_acc: 0.6823\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5800 - acc: 0.6753 - val_loss: 0.5886 - val_acc: 0.6823\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.5795 - acc: 0.6753 - val_loss: 0.5881 - val_acc: 0.6823\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.5790 - acc: 0.6753 - val_loss: 0.5876 - val_acc: 0.6823\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5785 - acc: 0.6753 - val_loss: 0.5871 - val_acc: 0.6823\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5780 - acc: 0.6771 - val_loss: 0.5866 - val_acc: 0.6823\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 193us/step - loss: 0.5775 - acc: 0.6788 - val_loss: 0.5861 - val_acc: 0.6823\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.5770 - acc: 0.6788 - val_loss: 0.5856 - val_acc: 0.6823\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5765 - acc: 0.6806 - val_loss: 0.5851 - val_acc: 0.6823\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.5760 - acc: 0.6806 - val_loss: 0.5846 - val_acc: 0.6875\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5754 - acc: 0.6788 - val_loss: 0.5841 - val_acc: 0.6875\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5750 - acc: 0.6840 - val_loss: 0.5836 - val_acc: 0.6875\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5745 - acc: 0.6806 - val_loss: 0.5831 - val_acc: 0.6927\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5740 - acc: 0.6823 - val_loss: 0.5826 - val_acc: 0.6979\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5735 - acc: 0.6823 - val_loss: 0.5822 - val_acc: 0.6979\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.5730 - acc: 0.6858 - val_loss: 0.5817 - val_acc: 0.6979\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5725 - acc: 0.6858 - val_loss: 0.5812 - val_acc: 0.6979\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.5720 - acc: 0.6840 - val_loss: 0.5807 - val_acc: 0.6979\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5715 - acc: 0.6858 - val_loss: 0.5802 - val_acc: 0.6979\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.5710 - acc: 0.6840 - val_loss: 0.5798 - val_acc: 0.6979\n",
      "Epoch 113/200\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.5705 - acc: 0.6875 - val_loss: 0.5793 - val_acc: 0.7031\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5701 - acc: 0.6858 - val_loss: 0.5788 - val_acc: 0.7031\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5696 - acc: 0.6858 - val_loss: 0.5784 - val_acc: 0.7031\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.5691 - acc: 0.6840 - val_loss: 0.5779 - val_acc: 0.7031\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.5687 - acc: 0.6840 - val_loss: 0.5774 - val_acc: 0.7031\n",
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.5682 - acc: 0.6823 - val_loss: 0.5770 - val_acc: 0.7031\n",
      "Epoch 119/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.5677 - acc: 0.6823 - val_loss: 0.5765 - val_acc: 0.7031\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.5673 - acc: 0.6823 - val_loss: 0.5761 - val_acc: 0.7031\n",
      "Epoch 121/200\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5668 - acc: 0.6840 - val_loss: 0.5756 - val_acc: 0.7031\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.5663 - acc: 0.6892 - val_loss: 0.5752 - val_acc: 0.7031\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.5659 - acc: 0.6858 - val_loss: 0.5747 - val_acc: 0.7031\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.5654 - acc: 0.6858 - val_loss: 0.5743 - val_acc: 0.7031\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.5650 - acc: 0.6875 - val_loss: 0.5738 - val_acc: 0.7031\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5645 - acc: 0.6858 - val_loss: 0.5734 - val_acc: 0.7031\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.5641 - acc: 0.6858 - val_loss: 0.5729 - val_acc: 0.7031\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.5636 - acc: 0.6875 - val_loss: 0.5725 - val_acc: 0.7031\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.5632 - acc: 0.6875 - val_loss: 0.5720 - val_acc: 0.7031\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.5627 - acc: 0.6875 - val_loss: 0.5716 - val_acc: 0.7083\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.5623 - acc: 0.6875 - val_loss: 0.5712 - val_acc: 0.7083\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5618 - acc: 0.6858 - val_loss: 0.5707 - val_acc: 0.7083\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.5614 - acc: 0.6875 - val_loss: 0.5703 - val_acc: 0.7083\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5610 - acc: 0.6858 - val_loss: 0.5699 - val_acc: 0.7083\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.5605 - acc: 0.6875 - val_loss: 0.5695 - val_acc: 0.7083\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.5601 - acc: 0.6875 - val_loss: 0.5690 - val_acc: 0.7083\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5597 - acc: 0.6875 - val_loss: 0.5686 - val_acc: 0.7083\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.5592 - acc: 0.6875 - val_loss: 0.5682 - val_acc: 0.7083\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.5588 - acc: 0.6910 - val_loss: 0.5678 - val_acc: 0.7083\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.5584 - acc: 0.6875 - val_loss: 0.5674 - val_acc: 0.7083\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.5579 - acc: 0.6910 - val_loss: 0.5670 - val_acc: 0.7083\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5575 - acc: 0.6910 - val_loss: 0.5665 - val_acc: 0.7135\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5571 - acc: 0.6927 - val_loss: 0.5661 - val_acc: 0.7083\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.5567 - acc: 0.6944 - val_loss: 0.5657 - val_acc: 0.7083\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.5563 - acc: 0.6927 - val_loss: 0.5653 - val_acc: 0.7083\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.5559 - acc: 0.6944 - val_loss: 0.5649 - val_acc: 0.7083\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.5554 - acc: 0.6944 - val_loss: 0.5645 - val_acc: 0.7083\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5550 - acc: 0.6979 - val_loss: 0.5641 - val_acc: 0.7083\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5546 - acc: 0.6979 - val_loss: 0.5637 - val_acc: 0.7083\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.5542 - acc: 0.6997 - val_loss: 0.5633 - val_acc: 0.7188\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.5538 - acc: 0.7014 - val_loss: 0.5629 - val_acc: 0.7188\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5534 - acc: 0.7014 - val_loss: 0.5625 - val_acc: 0.7188\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5530 - acc: 0.7014 - val_loss: 0.5621 - val_acc: 0.7240\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.5526 - acc: 0.7031 - val_loss: 0.5618 - val_acc: 0.7240\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.5522 - acc: 0.7049 - val_loss: 0.5614 - val_acc: 0.7292\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.5518 - acc: 0.7049 - val_loss: 0.5610 - val_acc: 0.7292\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.5514 - acc: 0.7049 - val_loss: 0.5606 - val_acc: 0.7292\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.5510 - acc: 0.7049 - val_loss: 0.5602 - val_acc: 0.7292\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.5506 - acc: 0.7049 - val_loss: 0.5598 - val_acc: 0.7292\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.5502 - acc: 0.7066 - val_loss: 0.5595 - val_acc: 0.7292\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5498 - acc: 0.7066 - val_loss: 0.5591 - val_acc: 0.7292\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.5494 - acc: 0.7066 - val_loss: 0.5587 - val_acc: 0.7292\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5490 - acc: 0.7066 - val_loss: 0.5583 - val_acc: 0.7292\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.5486 - acc: 0.7049 - val_loss: 0.5580 - val_acc: 0.7292\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5483 - acc: 0.7049 - val_loss: 0.5576 - val_acc: 0.7240\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5479 - acc: 0.7049 - val_loss: 0.5572 - val_acc: 0.7240\n",
      "Epoch 167/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5475 - acc: 0.7049 - val_loss: 0.5569 - val_acc: 0.7240\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5471 - acc: 0.7066 - val_loss: 0.5565 - val_acc: 0.7240\n",
      "Epoch 169/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5468 - acc: 0.7066 - val_loss: 0.5561 - val_acc: 0.7240\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.5464 - acc: 0.7083 - val_loss: 0.5558 - val_acc: 0.7240\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5460 - acc: 0.7101 - val_loss: 0.5554 - val_acc: 0.7188\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5457 - acc: 0.7083 - val_loss: 0.5550 - val_acc: 0.7188\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5453 - acc: 0.7118 - val_loss: 0.5547 - val_acc: 0.7188\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.5449 - acc: 0.7135 - val_loss: 0.5543 - val_acc: 0.7240\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5445 - acc: 0.7135 - val_loss: 0.5540 - val_acc: 0.7240\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.5442 - acc: 0.7135 - val_loss: 0.5536 - val_acc: 0.7292\n",
      "Epoch 177/200\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.5438 - acc: 0.7135 - val_loss: 0.5533 - val_acc: 0.7292\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.5434 - acc: 0.7135 - val_loss: 0.5529 - val_acc: 0.7292\n",
      "Epoch 179/200\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.5431 - acc: 0.7135 - val_loss: 0.5526 - val_acc: 0.7292\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5427 - acc: 0.7153 - val_loss: 0.5522 - val_acc: 0.7292\n",
      "Epoch 181/200\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.5424 - acc: 0.7153 - val_loss: 0.5519 - val_acc: 0.7292\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5420 - acc: 0.7153 - val_loss: 0.5516 - val_acc: 0.7292\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.5416 - acc: 0.7135 - val_loss: 0.5512 - val_acc: 0.7292\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.5413 - acc: 0.7135 - val_loss: 0.5509 - val_acc: 0.7292\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5410 - acc: 0.7135 - val_loss: 0.5505 - val_acc: 0.7292\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.5406 - acc: 0.7135 - val_loss: 0.5502 - val_acc: 0.7292\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.5403 - acc: 0.7170 - val_loss: 0.5499 - val_acc: 0.7344\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.5399 - acc: 0.7188 - val_loss: 0.5496 - val_acc: 0.7396\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5396 - acc: 0.7205 - val_loss: 0.5492 - val_acc: 0.7396\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.5392 - acc: 0.7205 - val_loss: 0.5489 - val_acc: 0.7396\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.5389 - acc: 0.7205 - val_loss: 0.5486 - val_acc: 0.7396\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5385 - acc: 0.7205 - val_loss: 0.5482 - val_acc: 0.7396\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.5382 - acc: 0.7205 - val_loss: 0.5479 - val_acc: 0.7396\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.5379 - acc: 0.7205 - val_loss: 0.5476 - val_acc: 0.7396\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5375 - acc: 0.7205 - val_loss: 0.5473 - val_acc: 0.7396\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.5372 - acc: 0.7205 - val_loss: 0.5470 - val_acc: 0.7396\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.5369 - acc: 0.7205 - val_loss: 0.5466 - val_acc: 0.7396\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.5365 - acc: 0.7205 - val_loss: 0.5463 - val_acc: 0.7396\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.5362 - acc: 0.7205 - val_loss: 0.5460 - val_acc: 0.7396\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.5358 - acc: 0.7205 - val_loss: 0.5457 - val_acc: 0.7396\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3563587 ],\n",
       "       [0.53372884],\n",
       "       [0.33515665],\n",
       "       [0.42041185],\n",
       "       [0.23849162],\n",
       "       [0.37871853],\n",
       "       [0.19195217],\n",
       "       [0.3937721 ],\n",
       "       [0.6044836 ],\n",
       "       [0.29602498]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.740\n",
      "roc-auc is 0.799\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6545138888888888"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(run_hist_1.history.values())[3][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe28e65fa90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.5355 - acc: 0.7205 - val_loss: 0.5454 - val_acc: 0.7396\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5352 - acc: 0.7188 - val_loss: 0.5451 - val_acc: 0.7396\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5349 - acc: 0.7205 - val_loss: 0.5448 - val_acc: 0.7396\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5345 - acc: 0.7205 - val_loss: 0.5445 - val_acc: 0.7396\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5342 - acc: 0.7222 - val_loss: 0.5441 - val_acc: 0.7396\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5339 - acc: 0.7240 - val_loss: 0.5438 - val_acc: 0.7396\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.5336 - acc: 0.7222 - val_loss: 0.5435 - val_acc: 0.7396\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.5333 - acc: 0.7257 - val_loss: 0.5432 - val_acc: 0.7396\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.5330 - acc: 0.7257 - val_loss: 0.5429 - val_acc: 0.7396\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.5327 - acc: 0.7257 - val_loss: 0.5426 - val_acc: 0.7396\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5323 - acc: 0.7257 - val_loss: 0.5423 - val_acc: 0.7396\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5320 - acc: 0.7257 - val_loss: 0.5420 - val_acc: 0.7396\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5317 - acc: 0.7257 - val_loss: 0.5418 - val_acc: 0.7396\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.5314 - acc: 0.7257 - val_loss: 0.5415 - val_acc: 0.7396\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.5311 - acc: 0.7292 - val_loss: 0.5412 - val_acc: 0.7448\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5308 - acc: 0.7292 - val_loss: 0.5409 - val_acc: 0.7448\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5305 - acc: 0.7292 - val_loss: 0.5406 - val_acc: 0.7448\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5302 - acc: 0.7309 - val_loss: 0.5403 - val_acc: 0.7448\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.5299 - acc: 0.7292 - val_loss: 0.5400 - val_acc: 0.7448\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.5296 - acc: 0.7309 - val_loss: 0.5397 - val_acc: 0.7448\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.5293 - acc: 0.7309 - val_loss: 0.5395 - val_acc: 0.7448\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5290 - acc: 0.7292 - val_loss: 0.5392 - val_acc: 0.7448\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5287 - acc: 0.7292 - val_loss: 0.5389 - val_acc: 0.7500\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5284 - acc: 0.7309 - val_loss: 0.5386 - val_acc: 0.7500\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5281 - acc: 0.7326 - val_loss: 0.5383 - val_acc: 0.7500\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5278 - acc: 0.7326 - val_loss: 0.5381 - val_acc: 0.7500\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.5275 - acc: 0.7326 - val_loss: 0.5378 - val_acc: 0.7448\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.5272 - acc: 0.7326 - val_loss: 0.5375 - val_acc: 0.7448\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 0s 191us/step - loss: 0.5269 - acc: 0.7326 - val_loss: 0.5372 - val_acc: 0.7448\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.5266 - acc: 0.7309 - val_loss: 0.5370 - val_acc: 0.7448\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5263 - acc: 0.7309 - val_loss: 0.5367 - val_acc: 0.7448\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.5260 - acc: 0.7309 - val_loss: 0.5364 - val_acc: 0.7448\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5258 - acc: 0.7292 - val_loss: 0.5362 - val_acc: 0.7448\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.5255 - acc: 0.7326 - val_loss: 0.5359 - val_acc: 0.7396\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5252 - acc: 0.7344 - val_loss: 0.5356 - val_acc: 0.7396\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.5249 - acc: 0.7344 - val_loss: 0.5354 - val_acc: 0.7396\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5246 - acc: 0.7344 - val_loss: 0.5351 - val_acc: 0.7396\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5244 - acc: 0.7326 - val_loss: 0.5348 - val_acc: 0.7396\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.5241 - acc: 0.7344 - val_loss: 0.5346 - val_acc: 0.7396\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.5238 - acc: 0.7344 - val_loss: 0.5343 - val_acc: 0.7396\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.5235 - acc: 0.7344 - val_loss: 0.5341 - val_acc: 0.7396\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5233 - acc: 0.7344 - val_loss: 0.5338 - val_acc: 0.7396\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5230 - acc: 0.7344 - val_loss: 0.5336 - val_acc: 0.7396\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.5227 - acc: 0.7344 - val_loss: 0.5333 - val_acc: 0.7396\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5225 - acc: 0.7344 - val_loss: 0.5331 - val_acc: 0.7396\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5222 - acc: 0.7361 - val_loss: 0.5328 - val_acc: 0.7396\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5219 - acc: 0.7361 - val_loss: 0.5326 - val_acc: 0.7396\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5217 - acc: 0.7361 - val_loss: 0.5323 - val_acc: 0.7448\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5214 - acc: 0.7361 - val_loss: 0.5321 - val_acc: 0.7448\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5211 - acc: 0.7361 - val_loss: 0.5318 - val_acc: 0.7448\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.5209 - acc: 0.7344 - val_loss: 0.5316 - val_acc: 0.7448\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5206 - acc: 0.7344 - val_loss: 0.5313 - val_acc: 0.7448\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.5203 - acc: 0.7344 - val_loss: 0.5311 - val_acc: 0.7448\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5201 - acc: 0.7344 - val_loss: 0.5308 - val_acc: 0.7448\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5198 - acc: 0.7361 - val_loss: 0.5306 - val_acc: 0.7448\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5196 - acc: 0.7361 - val_loss: 0.5304 - val_acc: 0.7448\n",
      "Epoch 57/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5193 - acc: 0.7361 - val_loss: 0.5301 - val_acc: 0.7448\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5191 - acc: 0.7361 - val_loss: 0.5299 - val_acc: 0.7448\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5188 - acc: 0.7361 - val_loss: 0.5297 - val_acc: 0.7448\n",
      "Epoch 60/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5185 - acc: 0.7361 - val_loss: 0.5294 - val_acc: 0.7500\n",
      "Epoch 61/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.5183 - acc: 0.7361 - val_loss: 0.5292 - val_acc: 0.7500\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5180 - acc: 0.7344 - val_loss: 0.5290 - val_acc: 0.7500\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.5178 - acc: 0.7344 - val_loss: 0.5287 - val_acc: 0.7500\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.5175 - acc: 0.7361 - val_loss: 0.5285 - val_acc: 0.7552\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.5173 - acc: 0.7344 - val_loss: 0.5283 - val_acc: 0.7552\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.5171 - acc: 0.7361 - val_loss: 0.5281 - val_acc: 0.7552\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.5168 - acc: 0.7378 - val_loss: 0.5278 - val_acc: 0.7552\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.5166 - acc: 0.7378 - val_loss: 0.5276 - val_acc: 0.7552\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.5163 - acc: 0.7378 - val_loss: 0.5274 - val_acc: 0.7552\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.5161 - acc: 0.7378 - val_loss: 0.5272 - val_acc: 0.7552\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.5158 - acc: 0.7378 - val_loss: 0.5269 - val_acc: 0.7552\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.5156 - acc: 0.7396 - val_loss: 0.5267 - val_acc: 0.7604\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.5154 - acc: 0.7396 - val_loss: 0.5265 - val_acc: 0.7604\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5151 - acc: 0.7396 - val_loss: 0.5263 - val_acc: 0.7656\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5149 - acc: 0.7413 - val_loss: 0.5261 - val_acc: 0.7656\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.5147 - acc: 0.7413 - val_loss: 0.5258 - val_acc: 0.7604\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5144 - acc: 0.7413 - val_loss: 0.5256 - val_acc: 0.7604\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.5142 - acc: 0.7413 - val_loss: 0.5254 - val_acc: 0.7604\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5140 - acc: 0.7413 - val_loss: 0.5252 - val_acc: 0.7604\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5137 - acc: 0.7413 - val_loss: 0.5250 - val_acc: 0.7604\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5135 - acc: 0.7413 - val_loss: 0.5248 - val_acc: 0.7604\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.5132 - acc: 0.7431 - val_loss: 0.5246 - val_acc: 0.7604\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.5130 - acc: 0.7431 - val_loss: 0.5244 - val_acc: 0.7604\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5128 - acc: 0.7431 - val_loss: 0.5242 - val_acc: 0.7604\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.5126 - acc: 0.7448 - val_loss: 0.5239 - val_acc: 0.7604\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.5124 - acc: 0.7448 - val_loss: 0.5237 - val_acc: 0.7604\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.5121 - acc: 0.7448 - val_loss: 0.5235 - val_acc: 0.7604\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5119 - acc: 0.7448 - val_loss: 0.5233 - val_acc: 0.7604\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5117 - acc: 0.7465 - val_loss: 0.5231 - val_acc: 0.7604\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5115 - acc: 0.7465 - val_loss: 0.5229 - val_acc: 0.7604\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.5113 - acc: 0.7465 - val_loss: 0.5227 - val_acc: 0.7604\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.5110 - acc: 0.7465 - val_loss: 0.5225 - val_acc: 0.7604\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.5108 - acc: 0.7465 - val_loss: 0.5223 - val_acc: 0.7604\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5106 - acc: 0.7483 - val_loss: 0.5221 - val_acc: 0.7552\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5104 - acc: 0.7483 - val_loss: 0.5219 - val_acc: 0.7552\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5102 - acc: 0.7483 - val_loss: 0.5217 - val_acc: 0.7552\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.5099 - acc: 0.7465 - val_loss: 0.5215 - val_acc: 0.7552\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.5097 - acc: 0.7483 - val_loss: 0.5214 - val_acc: 0.7552\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5095 - acc: 0.7483 - val_loss: 0.5212 - val_acc: 0.7552\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5093 - acc: 0.7517 - val_loss: 0.5210 - val_acc: 0.7552\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.5091 - acc: 0.7517 - val_loss: 0.5208 - val_acc: 0.7552\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5089 - acc: 0.7517 - val_loss: 0.5206 - val_acc: 0.7552\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5087 - acc: 0.7517 - val_loss: 0.5204 - val_acc: 0.7552\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.5085 - acc: 0.7535 - val_loss: 0.5202 - val_acc: 0.7552\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5083 - acc: 0.7535 - val_loss: 0.5200 - val_acc: 0.7552\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.5081 - acc: 0.7535 - val_loss: 0.5198 - val_acc: 0.7552\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.5078 - acc: 0.7535 - val_loss: 0.5197 - val_acc: 0.7552\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.5077 - acc: 0.7517 - val_loss: 0.5195 - val_acc: 0.7552\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.5074 - acc: 0.7517 - val_loss: 0.5193 - val_acc: 0.7552\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.5072 - acc: 0.7517 - val_loss: 0.5191 - val_acc: 0.7552\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.5070 - acc: 0.7517 - val_loss: 0.5189 - val_acc: 0.7552\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.5068 - acc: 0.7535 - val_loss: 0.5187 - val_acc: 0.7552\n",
      "Epoch 113/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.5066 - acc: 0.7517 - val_loss: 0.5186 - val_acc: 0.7552\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5064 - acc: 0.7535 - val_loss: 0.5184 - val_acc: 0.7552\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5062 - acc: 0.7535 - val_loss: 0.5182 - val_acc: 0.7552\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.5060 - acc: 0.7535 - val_loss: 0.5180 - val_acc: 0.7552\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.5059 - acc: 0.7517 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.5057 - acc: 0.7517 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 119/1000\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.5055 - acc: 0.7535 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.5053 - acc: 0.7517 - val_loss: 0.5173 - val_acc: 0.7500\n",
      "Epoch 121/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.5051 - acc: 0.7517 - val_loss: 0.5172 - val_acc: 0.7500\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.5049 - acc: 0.7552 - val_loss: 0.5170 - val_acc: 0.7500\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.5047 - acc: 0.7552 - val_loss: 0.5168 - val_acc: 0.7500\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.5045 - acc: 0.7552 - val_loss: 0.5167 - val_acc: 0.7552\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5043 - acc: 0.7552 - val_loss: 0.5165 - val_acc: 0.7552\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5041 - acc: 0.7552 - val_loss: 0.5163 - val_acc: 0.7500\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5039 - acc: 0.7552 - val_loss: 0.5162 - val_acc: 0.7500\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.5037 - acc: 0.7552 - val_loss: 0.5160 - val_acc: 0.7500\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5035 - acc: 0.7552 - val_loss: 0.5158 - val_acc: 0.7500\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5034 - acc: 0.7552 - val_loss: 0.5157 - val_acc: 0.7500\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.5032 - acc: 0.7552 - val_loss: 0.5155 - val_acc: 0.7500\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.5030 - acc: 0.7569 - val_loss: 0.5153 - val_acc: 0.7500\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.5028 - acc: 0.7569 - val_loss: 0.5152 - val_acc: 0.7500\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.5026 - acc: 0.7569 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5025 - acc: 0.7569 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5023 - acc: 0.7569 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5021 - acc: 0.7569 - val_loss: 0.5145 - val_acc: 0.7500\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5019 - acc: 0.7569 - val_loss: 0.5144 - val_acc: 0.7500\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.5017 - acc: 0.7569 - val_loss: 0.5142 - val_acc: 0.7500\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5016 - acc: 0.7569 - val_loss: 0.5141 - val_acc: 0.7552\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.5014 - acc: 0.7569 - val_loss: 0.5139 - val_acc: 0.7552\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.5012 - acc: 0.7569 - val_loss: 0.5137 - val_acc: 0.7552\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.5010 - acc: 0.7569 - val_loss: 0.5136 - val_acc: 0.7604\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.5009 - acc: 0.7569 - val_loss: 0.5134 - val_acc: 0.7604\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.5007 - acc: 0.7569 - val_loss: 0.5133 - val_acc: 0.7604\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.5005 - acc: 0.7569 - val_loss: 0.5131 - val_acc: 0.7604\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.5003 - acc: 0.7569 - val_loss: 0.5130 - val_acc: 0.7604\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.5002 - acc: 0.7569 - val_loss: 0.5128 - val_acc: 0.7604\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.5000 - acc: 0.7569 - val_loss: 0.5127 - val_acc: 0.7604\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4998 - acc: 0.7569 - val_loss: 0.5125 - val_acc: 0.7604\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4997 - acc: 0.7569 - val_loss: 0.5124 - val_acc: 0.7604\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4995 - acc: 0.7569 - val_loss: 0.5122 - val_acc: 0.7604\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4993 - acc: 0.7569 - val_loss: 0.5121 - val_acc: 0.7604\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4992 - acc: 0.7569 - val_loss: 0.5119 - val_acc: 0.7604\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4990 - acc: 0.7587 - val_loss: 0.5118 - val_acc: 0.7604\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4988 - acc: 0.7587 - val_loss: 0.5117 - val_acc: 0.7604\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4987 - acc: 0.7604 - val_loss: 0.5115 - val_acc: 0.7604\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4985 - acc: 0.7604 - val_loss: 0.5114 - val_acc: 0.7604\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4983 - acc: 0.7604 - val_loss: 0.5112 - val_acc: 0.7604\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4982 - acc: 0.7604 - val_loss: 0.5111 - val_acc: 0.7604\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4980 - acc: 0.7604 - val_loss: 0.5109 - val_acc: 0.7604\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4979 - acc: 0.7604 - val_loss: 0.5108 - val_acc: 0.7604\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4977 - acc: 0.7604 - val_loss: 0.5107 - val_acc: 0.7604\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4975 - acc: 0.7604 - val_loss: 0.5105 - val_acc: 0.7604\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4974 - acc: 0.7604 - val_loss: 0.5104 - val_acc: 0.7604\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4972 - acc: 0.7604 - val_loss: 0.5103 - val_acc: 0.7604\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4971 - acc: 0.7604 - val_loss: 0.5101 - val_acc: 0.7604\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4969 - acc: 0.7587 - val_loss: 0.5100 - val_acc: 0.7604\n",
      "Epoch 169/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4967 - acc: 0.7587 - val_loss: 0.5098 - val_acc: 0.7604\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4966 - acc: 0.7604 - val_loss: 0.5097 - val_acc: 0.7604\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4964 - acc: 0.7587 - val_loss: 0.5096 - val_acc: 0.7656\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4963 - acc: 0.7622 - val_loss: 0.5094 - val_acc: 0.7708\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4961 - acc: 0.7622 - val_loss: 0.5093 - val_acc: 0.7708\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4960 - acc: 0.7639 - val_loss: 0.5092 - val_acc: 0.7708\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4958 - acc: 0.7656 - val_loss: 0.5090 - val_acc: 0.7708\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4957 - acc: 0.7656 - val_loss: 0.5089 - val_acc: 0.7708\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4956 - acc: 0.7656 - val_loss: 0.5088 - val_acc: 0.7708\n",
      "Epoch 178/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4954 - acc: 0.7656 - val_loss: 0.5087 - val_acc: 0.7708\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4952 - acc: 0.7656 - val_loss: 0.5085 - val_acc: 0.7708\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4951 - acc: 0.7656 - val_loss: 0.5084 - val_acc: 0.7708\n",
      "Epoch 181/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4949 - acc: 0.7656 - val_loss: 0.5083 - val_acc: 0.7708\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4948 - acc: 0.7656 - val_loss: 0.5081 - val_acc: 0.7708\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4946 - acc: 0.7656 - val_loss: 0.5080 - val_acc: 0.7708\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4945 - acc: 0.7656 - val_loss: 0.5079 - val_acc: 0.7708\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4943 - acc: 0.7656 - val_loss: 0.5078 - val_acc: 0.7760\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4942 - acc: 0.7656 - val_loss: 0.5076 - val_acc: 0.7760\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4940 - acc: 0.7656 - val_loss: 0.5075 - val_acc: 0.7760\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4939 - acc: 0.7656 - val_loss: 0.5074 - val_acc: 0.7760\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4937 - acc: 0.7656 - val_loss: 0.5073 - val_acc: 0.7760\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4936 - acc: 0.7656 - val_loss: 0.5072 - val_acc: 0.7760\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4935 - acc: 0.7656 - val_loss: 0.5070 - val_acc: 0.7760\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4933 - acc: 0.7656 - val_loss: 0.5069 - val_acc: 0.7760\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4932 - acc: 0.7656 - val_loss: 0.5068 - val_acc: 0.7760\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4930 - acc: 0.7656 - val_loss: 0.5067 - val_acc: 0.7760\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4929 - acc: 0.7656 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4928 - acc: 0.7656 - val_loss: 0.5064 - val_acc: 0.7760\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4926 - acc: 0.7656 - val_loss: 0.5063 - val_acc: 0.7760\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4925 - acc: 0.7656 - val_loss: 0.5062 - val_acc: 0.7760\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4923 - acc: 0.7656 - val_loss: 0.5061 - val_acc: 0.7760\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4922 - acc: 0.7656 - val_loss: 0.5060 - val_acc: 0.7760\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4921 - acc: 0.7656 - val_loss: 0.5059 - val_acc: 0.7760\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4919 - acc: 0.7656 - val_loss: 0.5058 - val_acc: 0.7760\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4918 - acc: 0.7656 - val_loss: 0.5056 - val_acc: 0.7760\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 0s 174us/step - loss: 0.4917 - acc: 0.7656 - val_loss: 0.5055 - val_acc: 0.7760\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4915 - acc: 0.7656 - val_loss: 0.5054 - val_acc: 0.7760\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4914 - acc: 0.7674 - val_loss: 0.5053 - val_acc: 0.7760\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4913 - acc: 0.7674 - val_loss: 0.5052 - val_acc: 0.7760\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4911 - acc: 0.7674 - val_loss: 0.5051 - val_acc: 0.7760\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4910 - acc: 0.7708 - val_loss: 0.5050 - val_acc: 0.7760\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4909 - acc: 0.7708 - val_loss: 0.5049 - val_acc: 0.7760\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4907 - acc: 0.7708 - val_loss: 0.5047 - val_acc: 0.7760\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4906 - acc: 0.7708 - val_loss: 0.5046 - val_acc: 0.7760\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4905 - acc: 0.7708 - val_loss: 0.5045 - val_acc: 0.7760\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4903 - acc: 0.7708 - val_loss: 0.5044 - val_acc: 0.7760\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4902 - acc: 0.7708 - val_loss: 0.5043 - val_acc: 0.7760\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4901 - acc: 0.7708 - val_loss: 0.5042 - val_acc: 0.7760\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4900 - acc: 0.7708 - val_loss: 0.5041 - val_acc: 0.7760\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4898 - acc: 0.7726 - val_loss: 0.5040 - val_acc: 0.7760\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4897 - acc: 0.7708 - val_loss: 0.5039 - val_acc: 0.7760\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4896 - acc: 0.7726 - val_loss: 0.5038 - val_acc: 0.7760\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4895 - acc: 0.7726 - val_loss: 0.5037 - val_acc: 0.7760\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4893 - acc: 0.7726 - val_loss: 0.5036 - val_acc: 0.7760\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4892 - acc: 0.7726 - val_loss: 0.5035 - val_acc: 0.7760\n",
      "Epoch 224/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4891 - acc: 0.7743 - val_loss: 0.5034 - val_acc: 0.7760\n",
      "Epoch 225/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4890 - acc: 0.7743 - val_loss: 0.5033 - val_acc: 0.7760\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4889 - acc: 0.7743 - val_loss: 0.5032 - val_acc: 0.7760\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4887 - acc: 0.7743 - val_loss: 0.5031 - val_acc: 0.7760\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4886 - acc: 0.7743 - val_loss: 0.5030 - val_acc: 0.7760\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4885 - acc: 0.7743 - val_loss: 0.5029 - val_acc: 0.7760\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4884 - acc: 0.7743 - val_loss: 0.5028 - val_acc: 0.7760\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4882 - acc: 0.7743 - val_loss: 0.5027 - val_acc: 0.7760\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4881 - acc: 0.7743 - val_loss: 0.5026 - val_acc: 0.7760\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4880 - acc: 0.7743 - val_loss: 0.5025 - val_acc: 0.7760\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4879 - acc: 0.7743 - val_loss: 0.5024 - val_acc: 0.7760\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4878 - acc: 0.7743 - val_loss: 0.5023 - val_acc: 0.7760\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4876 - acc: 0.7743 - val_loss: 0.5022 - val_acc: 0.7760\n",
      "Epoch 237/1000\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4875 - acc: 0.7726 - val_loss: 0.5021 - val_acc: 0.7760\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4874 - acc: 0.7726 - val_loss: 0.5020 - val_acc: 0.7760\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4873 - acc: 0.7726 - val_loss: 0.5019 - val_acc: 0.7760\n",
      "Epoch 240/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4872 - acc: 0.7708 - val_loss: 0.5018 - val_acc: 0.7760\n",
      "Epoch 241/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4871 - acc: 0.7708 - val_loss: 0.5017 - val_acc: 0.7760\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4869 - acc: 0.7708 - val_loss: 0.5016 - val_acc: 0.7760\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4868 - acc: 0.7708 - val_loss: 0.5015 - val_acc: 0.7760\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4867 - acc: 0.7708 - val_loss: 0.5014 - val_acc: 0.7760\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4866 - acc: 0.7708 - val_loss: 0.5013 - val_acc: 0.7760\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4865 - acc: 0.7708 - val_loss: 0.5013 - val_acc: 0.7760\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4864 - acc: 0.7708 - val_loss: 0.5012 - val_acc: 0.7760\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4863 - acc: 0.7708 - val_loss: 0.5011 - val_acc: 0.7708\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4862 - acc: 0.7708 - val_loss: 0.5010 - val_acc: 0.7708\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4860 - acc: 0.7708 - val_loss: 0.5009 - val_acc: 0.7708\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4859 - acc: 0.7691 - val_loss: 0.5008 - val_acc: 0.7708\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4859 - acc: 0.7708 - val_loss: 0.5007 - val_acc: 0.7708\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4857 - acc: 0.7674 - val_loss: 0.5006 - val_acc: 0.7708\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4856 - acc: 0.7674 - val_loss: 0.5005 - val_acc: 0.7708\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4855 - acc: 0.7674 - val_loss: 0.5005 - val_acc: 0.7708\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4854 - acc: 0.7674 - val_loss: 0.5004 - val_acc: 0.7708\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4853 - acc: 0.7674 - val_loss: 0.5003 - val_acc: 0.7708\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4852 - acc: 0.7674 - val_loss: 0.5002 - val_acc: 0.7708\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4851 - acc: 0.7674 - val_loss: 0.5001 - val_acc: 0.7708\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4850 - acc: 0.7674 - val_loss: 0.5000 - val_acc: 0.7708\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4849 - acc: 0.7674 - val_loss: 0.4999 - val_acc: 0.7708\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4847 - acc: 0.7674 - val_loss: 0.4999 - val_acc: 0.7708\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4846 - acc: 0.7674 - val_loss: 0.4998 - val_acc: 0.7708\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4846 - acc: 0.7674 - val_loss: 0.4997 - val_acc: 0.7708\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4844 - acc: 0.7674 - val_loss: 0.4996 - val_acc: 0.7708\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4843 - acc: 0.7674 - val_loss: 0.4995 - val_acc: 0.7708\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4843 - acc: 0.7674 - val_loss: 0.4994 - val_acc: 0.7708\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4841 - acc: 0.7674 - val_loss: 0.4994 - val_acc: 0.7708\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4840 - acc: 0.7674 - val_loss: 0.4993 - val_acc: 0.7708\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4839 - acc: 0.7674 - val_loss: 0.4992 - val_acc: 0.7708\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4838 - acc: 0.7674 - val_loss: 0.4991 - val_acc: 0.7708\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4837 - acc: 0.7674 - val_loss: 0.4990 - val_acc: 0.7708\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4836 - acc: 0.7674 - val_loss: 0.4990 - val_acc: 0.7656\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4835 - acc: 0.7674 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4834 - acc: 0.7674 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4833 - acc: 0.7674 - val_loss: 0.4987 - val_acc: 0.7656\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4832 - acc: 0.7674 - val_loss: 0.4986 - val_acc: 0.7656\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4831 - acc: 0.7674 - val_loss: 0.4986 - val_acc: 0.7656\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4830 - acc: 0.7674 - val_loss: 0.4985 - val_acc: 0.7656\n",
      "Epoch 280/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4829 - acc: 0.7674 - val_loss: 0.4984 - val_acc: 0.7656\n",
      "Epoch 281/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4828 - acc: 0.7656 - val_loss: 0.4983 - val_acc: 0.7656\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4827 - acc: 0.7674 - val_loss: 0.4983 - val_acc: 0.7656\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4826 - acc: 0.7674 - val_loss: 0.4982 - val_acc: 0.7656\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4825 - acc: 0.7674 - val_loss: 0.4981 - val_acc: 0.7656\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4824 - acc: 0.7674 - val_loss: 0.4980 - val_acc: 0.7656\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4823 - acc: 0.7691 - val_loss: 0.4980 - val_acc: 0.7656\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4823 - acc: 0.7674 - val_loss: 0.4979 - val_acc: 0.7656\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4822 - acc: 0.7674 - val_loss: 0.4978 - val_acc: 0.7656\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4821 - acc: 0.7691 - val_loss: 0.4977 - val_acc: 0.7656\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4820 - acc: 0.7674 - val_loss: 0.4977 - val_acc: 0.7604\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4819 - acc: 0.7691 - val_loss: 0.4976 - val_acc: 0.7604\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4818 - acc: 0.7691 - val_loss: 0.4975 - val_acc: 0.7604\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4817 - acc: 0.7691 - val_loss: 0.4974 - val_acc: 0.7604\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4816 - acc: 0.7674 - val_loss: 0.4974 - val_acc: 0.7604\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4815 - acc: 0.7691 - val_loss: 0.4973 - val_acc: 0.7604\n",
      "Epoch 296/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4814 - acc: 0.7691 - val_loss: 0.4972 - val_acc: 0.7604\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4813 - acc: 0.7691 - val_loss: 0.4972 - val_acc: 0.7604\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4812 - acc: 0.7691 - val_loss: 0.4971 - val_acc: 0.7604\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4811 - acc: 0.7708 - val_loss: 0.4970 - val_acc: 0.7604\n",
      "Epoch 300/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4811 - acc: 0.7708 - val_loss: 0.4969 - val_acc: 0.7604\n",
      "Epoch 301/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4810 - acc: 0.7691 - val_loss: 0.4969 - val_acc: 0.7604\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4809 - acc: 0.7708 - val_loss: 0.4968 - val_acc: 0.7604\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4808 - acc: 0.7691 - val_loss: 0.4967 - val_acc: 0.7604\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4807 - acc: 0.7691 - val_loss: 0.4967 - val_acc: 0.7604\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4806 - acc: 0.7708 - val_loss: 0.4966 - val_acc: 0.7604\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4806 - acc: 0.7708 - val_loss: 0.4965 - val_acc: 0.7604\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4804 - acc: 0.7708 - val_loss: 0.4965 - val_acc: 0.7604\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4803 - acc: 0.7708 - val_loss: 0.4964 - val_acc: 0.7604\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4802 - acc: 0.7708 - val_loss: 0.4963 - val_acc: 0.7604\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 0s 238us/step - loss: 0.4802 - acc: 0.7708 - val_loss: 0.4963 - val_acc: 0.7604\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 0s 216us/step - loss: 0.4801 - acc: 0.7708 - val_loss: 0.4962 - val_acc: 0.7604\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 0s 238us/step - loss: 0.4800 - acc: 0.7708 - val_loss: 0.4961 - val_acc: 0.7604\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 0s 236us/step - loss: 0.4799 - acc: 0.7726 - val_loss: 0.4961 - val_acc: 0.7604\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 0s 209us/step - loss: 0.4798 - acc: 0.7726 - val_loss: 0.4960 - val_acc: 0.7604\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 0s 275us/step - loss: 0.4798 - acc: 0.7726 - val_loss: 0.4959 - val_acc: 0.7604\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 0s 208us/step - loss: 0.4797 - acc: 0.7726 - val_loss: 0.4959 - val_acc: 0.7604\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 0s 235us/step - loss: 0.4796 - acc: 0.7708 - val_loss: 0.4958 - val_acc: 0.7604\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 0s 276us/step - loss: 0.4795 - acc: 0.7708 - val_loss: 0.4958 - val_acc: 0.7656\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4794 - acc: 0.7708 - val_loss: 0.4957 - val_acc: 0.7656\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 0s 231us/step - loss: 0.4793 - acc: 0.7726 - val_loss: 0.4956 - val_acc: 0.7656\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 0s 181us/step - loss: 0.4792 - acc: 0.7708 - val_loss: 0.4956 - val_acc: 0.7656\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 0s 240us/step - loss: 0.4792 - acc: 0.7708 - val_loss: 0.4955 - val_acc: 0.7656\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 0s 275us/step - loss: 0.4791 - acc: 0.7708 - val_loss: 0.4954 - val_acc: 0.7656\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 0s 270us/step - loss: 0.4790 - acc: 0.7708 - val_loss: 0.4954 - val_acc: 0.7656\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 0s 219us/step - loss: 0.4789 - acc: 0.7726 - val_loss: 0.4953 - val_acc: 0.7656\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 0s 228us/step - loss: 0.4788 - acc: 0.7726 - val_loss: 0.4953 - val_acc: 0.7656\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 0s 183us/step - loss: 0.4788 - acc: 0.7708 - val_loss: 0.4952 - val_acc: 0.7708\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 0s 234us/step - loss: 0.4787 - acc: 0.7708 - val_loss: 0.4951 - val_acc: 0.7708\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 0s 244us/step - loss: 0.4786 - acc: 0.7708 - val_loss: 0.4951 - val_acc: 0.7708\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 0s 241us/step - loss: 0.4785 - acc: 0.7708 - val_loss: 0.4950 - val_acc: 0.7708\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 0s 209us/step - loss: 0.4784 - acc: 0.7708 - val_loss: 0.4950 - val_acc: 0.7708\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 0s 215us/step - loss: 0.4784 - acc: 0.7708 - val_loss: 0.4949 - val_acc: 0.7708\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 0s 209us/step - loss: 0.4783 - acc: 0.7708 - val_loss: 0.4948 - val_acc: 0.7708\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 0s 216us/step - loss: 0.4782 - acc: 0.7726 - val_loss: 0.4948 - val_acc: 0.7708\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4781 - acc: 0.7726 - val_loss: 0.4947 - val_acc: 0.7708\n",
      "Epoch 336/1000\n",
      "576/576 [==============================] - 0s 209us/step - loss: 0.4780 - acc: 0.7743 - val_loss: 0.4947 - val_acc: 0.7708\n",
      "Epoch 337/1000\n",
      "576/576 [==============================] - 0s 212us/step - loss: 0.4780 - acc: 0.7743 - val_loss: 0.4946 - val_acc: 0.7708\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 0s 187us/step - loss: 0.4779 - acc: 0.7726 - val_loss: 0.4946 - val_acc: 0.7708\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4778 - acc: 0.7760 - val_loss: 0.4945 - val_acc: 0.7708\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4777 - acc: 0.7743 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4776 - acc: 0.7743 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4776 - acc: 0.7743 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4775 - acc: 0.7743 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4774 - acc: 0.7743 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4773 - acc: 0.7760 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4773 - acc: 0.7760 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4772 - acc: 0.7743 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4771 - acc: 0.7760 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4770 - acc: 0.7760 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4770 - acc: 0.7743 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4769 - acc: 0.7743 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4768 - acc: 0.7760 - val_loss: 0.4938 - val_acc: 0.7708\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4768 - acc: 0.7743 - val_loss: 0.4937 - val_acc: 0.7708\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4767 - acc: 0.7743 - val_loss: 0.4937 - val_acc: 0.7708\n",
      "Epoch 355/1000\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4766 - acc: 0.7743 - val_loss: 0.4936 - val_acc: 0.7708\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4765 - acc: 0.7760 - val_loss: 0.4936 - val_acc: 0.7708\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4765 - acc: 0.7743 - val_loss: 0.4935 - val_acc: 0.7708\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4764 - acc: 0.7743 - val_loss: 0.4935 - val_acc: 0.7708\n",
      "Epoch 359/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4763 - acc: 0.7760 - val_loss: 0.4934 - val_acc: 0.7708\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4763 - acc: 0.7743 - val_loss: 0.4934 - val_acc: 0.7708\n",
      "Epoch 361/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4762 - acc: 0.7743 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4761 - acc: 0.7726 - val_loss: 0.4933 - val_acc: 0.7708\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4760 - acc: 0.7760 - val_loss: 0.4932 - val_acc: 0.7708\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4760 - acc: 0.7760 - val_loss: 0.4932 - val_acc: 0.7708\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4759 - acc: 0.7760 - val_loss: 0.4931 - val_acc: 0.7708\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4758 - acc: 0.7778 - val_loss: 0.4931 - val_acc: 0.7708\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4758 - acc: 0.7760 - val_loss: 0.4930 - val_acc: 0.7708\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4757 - acc: 0.7760 - val_loss: 0.4930 - val_acc: 0.7708\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4756 - acc: 0.7778 - val_loss: 0.4929 - val_acc: 0.7708\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4755 - acc: 0.7743 - val_loss: 0.4929 - val_acc: 0.7708\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4755 - acc: 0.7726 - val_loss: 0.4928 - val_acc: 0.7708\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4754 - acc: 0.7743 - val_loss: 0.4928 - val_acc: 0.7708\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4754 - acc: 0.7726 - val_loss: 0.4927 - val_acc: 0.7708\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4753 - acc: 0.7708 - val_loss: 0.4927 - val_acc: 0.7708\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4752 - acc: 0.7726 - val_loss: 0.4926 - val_acc: 0.7708\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4752 - acc: 0.7708 - val_loss: 0.4926 - val_acc: 0.7708\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4751 - acc: 0.7743 - val_loss: 0.4925 - val_acc: 0.7708\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4750 - acc: 0.7726 - val_loss: 0.4925 - val_acc: 0.7708\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4749 - acc: 0.7726 - val_loss: 0.4925 - val_acc: 0.7708\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4749 - acc: 0.7743 - val_loss: 0.4924 - val_acc: 0.7708\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4748 - acc: 0.7726 - val_loss: 0.4924 - val_acc: 0.7708\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4748 - acc: 0.7708 - val_loss: 0.4923 - val_acc: 0.7708\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4747 - acc: 0.7726 - val_loss: 0.4923 - val_acc: 0.7708\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4746 - acc: 0.7726 - val_loss: 0.4922 - val_acc: 0.7708\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4746 - acc: 0.7708 - val_loss: 0.4922 - val_acc: 0.7708\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4745 - acc: 0.7691 - val_loss: 0.4921 - val_acc: 0.7708\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4744 - acc: 0.7691 - val_loss: 0.4921 - val_acc: 0.7708\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4744 - acc: 0.7691 - val_loss: 0.4920 - val_acc: 0.7708\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4743 - acc: 0.7708 - val_loss: 0.4920 - val_acc: 0.7708\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4743 - acc: 0.7691 - val_loss: 0.4920 - val_acc: 0.7708\n",
      "Epoch 391/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4742 - acc: 0.7708 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 392/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4741 - acc: 0.7691 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 393/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4741 - acc: 0.7708 - val_loss: 0.4918 - val_acc: 0.7708\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4740 - acc: 0.7708 - val_loss: 0.4918 - val_acc: 0.7708\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4739 - acc: 0.7708 - val_loss: 0.4917 - val_acc: 0.7708\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4739 - acc: 0.7708 - val_loss: 0.4917 - val_acc: 0.7708\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4738 - acc: 0.7708 - val_loss: 0.4917 - val_acc: 0.7708\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4737 - acc: 0.7691 - val_loss: 0.4916 - val_acc: 0.7708\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4737 - acc: 0.7708 - val_loss: 0.4916 - val_acc: 0.7708\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4736 - acc: 0.7708 - val_loss: 0.4915 - val_acc: 0.7708\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4736 - acc: 0.7708 - val_loss: 0.4915 - val_acc: 0.7708\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4735 - acc: 0.7708 - val_loss: 0.4915 - val_acc: 0.7708\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4734 - acc: 0.7708 - val_loss: 0.4914 - val_acc: 0.7708\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4734 - acc: 0.7708 - val_loss: 0.4914 - val_acc: 0.7708\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4733 - acc: 0.7708 - val_loss: 0.4913 - val_acc: 0.7708\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4733 - acc: 0.7708 - val_loss: 0.4913 - val_acc: 0.7708\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4732 - acc: 0.7708 - val_loss: 0.4913 - val_acc: 0.7708\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4731 - acc: 0.7708 - val_loss: 0.4912 - val_acc: 0.7708\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4731 - acc: 0.7708 - val_loss: 0.4912 - val_acc: 0.7708\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4730 - acc: 0.7708 - val_loss: 0.4911 - val_acc: 0.7708\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4730 - acc: 0.7708 - val_loss: 0.4911 - val_acc: 0.7708\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4729 - acc: 0.7708 - val_loss: 0.4911 - val_acc: 0.7708\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4729 - acc: 0.7691 - val_loss: 0.4910 - val_acc: 0.7708\n",
      "Epoch 414/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4728 - acc: 0.7708 - val_loss: 0.4910 - val_acc: 0.7708\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4727 - acc: 0.7708 - val_loss: 0.4909 - val_acc: 0.7708\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4727 - acc: 0.7691 - val_loss: 0.4909 - val_acc: 0.7708\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4726 - acc: 0.7708 - val_loss: 0.4909 - val_acc: 0.7708\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4726 - acc: 0.7708 - val_loss: 0.4908 - val_acc: 0.7708\n",
      "Epoch 419/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4725 - acc: 0.7674 - val_loss: 0.4908 - val_acc: 0.7708\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4725 - acc: 0.7691 - val_loss: 0.4908 - val_acc: 0.7708\n",
      "Epoch 421/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4724 - acc: 0.7691 - val_loss: 0.4907 - val_acc: 0.7708\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4723 - acc: 0.7691 - val_loss: 0.4907 - val_acc: 0.7708\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4723 - acc: 0.7691 - val_loss: 0.4906 - val_acc: 0.7708\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4722 - acc: 0.7691 - val_loss: 0.4906 - val_acc: 0.7708\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4722 - acc: 0.7691 - val_loss: 0.4906 - val_acc: 0.7708\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4721 - acc: 0.7674 - val_loss: 0.4905 - val_acc: 0.7708\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4721 - acc: 0.7674 - val_loss: 0.4905 - val_acc: 0.7708\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4720 - acc: 0.7674 - val_loss: 0.4905 - val_acc: 0.7708\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4720 - acc: 0.7674 - val_loss: 0.4904 - val_acc: 0.7708\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4719 - acc: 0.7674 - val_loss: 0.4904 - val_acc: 0.7708\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4718 - acc: 0.7674 - val_loss: 0.4904 - val_acc: 0.7708\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4718 - acc: 0.7674 - val_loss: 0.4903 - val_acc: 0.7708\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4718 - acc: 0.7674 - val_loss: 0.4903 - val_acc: 0.7708\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4717 - acc: 0.7674 - val_loss: 0.4903 - val_acc: 0.7708\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4716 - acc: 0.7691 - val_loss: 0.4902 - val_acc: 0.7708\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4716 - acc: 0.7674 - val_loss: 0.4902 - val_acc: 0.7708\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4715 - acc: 0.7691 - val_loss: 0.4901 - val_acc: 0.7708\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4715 - acc: 0.7691 - val_loss: 0.4901 - val_acc: 0.7708\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4714 - acc: 0.7691 - val_loss: 0.4901 - val_acc: 0.7708\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4714 - acc: 0.7691 - val_loss: 0.4900 - val_acc: 0.7708\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4713 - acc: 0.7691 - val_loss: 0.4900 - val_acc: 0.7708\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4713 - acc: 0.7691 - val_loss: 0.4900 - val_acc: 0.7708\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4712 - acc: 0.7691 - val_loss: 0.4899 - val_acc: 0.7708\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4712 - acc: 0.7691 - val_loss: 0.4899 - val_acc: 0.7708\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4711 - acc: 0.7691 - val_loss: 0.4899 - val_acc: 0.7708\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4711 - acc: 0.7708 - val_loss: 0.4898 - val_acc: 0.7708\n",
      "Epoch 447/1000\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4710 - acc: 0.7708 - val_loss: 0.4898 - val_acc: 0.7708\n",
      "Epoch 448/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4710 - acc: 0.7708 - val_loss: 0.4898 - val_acc: 0.7708\n",
      "Epoch 449/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4709 - acc: 0.7708 - val_loss: 0.4898 - val_acc: 0.7708\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4709 - acc: 0.7726 - val_loss: 0.4897 - val_acc: 0.7708\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4708 - acc: 0.7708 - val_loss: 0.4897 - val_acc: 0.7708\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4708 - acc: 0.7726 - val_loss: 0.4897 - val_acc: 0.7708\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4707 - acc: 0.7726 - val_loss: 0.4896 - val_acc: 0.7708\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4707 - acc: 0.7726 - val_loss: 0.4896 - val_acc: 0.7708\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4706 - acc: 0.7726 - val_loss: 0.4896 - val_acc: 0.7708\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4706 - acc: 0.7726 - val_loss: 0.4895 - val_acc: 0.7708\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4705 - acc: 0.7726 - val_loss: 0.4895 - val_acc: 0.7708\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4705 - acc: 0.7726 - val_loss: 0.4895 - val_acc: 0.7708\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4704 - acc: 0.7726 - val_loss: 0.4894 - val_acc: 0.7708\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4704 - acc: 0.7726 - val_loss: 0.4894 - val_acc: 0.7708\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4703 - acc: 0.7726 - val_loss: 0.4894 - val_acc: 0.7708\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4703 - acc: 0.7726 - val_loss: 0.4894 - val_acc: 0.7708\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4702 - acc: 0.7726 - val_loss: 0.4893 - val_acc: 0.7708\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4702 - acc: 0.7726 - val_loss: 0.4893 - val_acc: 0.7708\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4702 - acc: 0.7726 - val_loss: 0.4893 - val_acc: 0.7708\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4701 - acc: 0.7726 - val_loss: 0.4892 - val_acc: 0.7708\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4700 - acc: 0.7726 - val_loss: 0.4892 - val_acc: 0.7708\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4700 - acc: 0.7726 - val_loss: 0.4892 - val_acc: 0.7708\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4700 - acc: 0.7726 - val_loss: 0.4892 - val_acc: 0.7708\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4699 - acc: 0.7726 - val_loss: 0.4891 - val_acc: 0.7708\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4699 - acc: 0.7726 - val_loss: 0.4891 - val_acc: 0.7708\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4698 - acc: 0.7726 - val_loss: 0.4891 - val_acc: 0.7708\n",
      "Epoch 473/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4698 - acc: 0.7743 - val_loss: 0.4890 - val_acc: 0.7708\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4697 - acc: 0.7726 - val_loss: 0.4890 - val_acc: 0.7708\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4697 - acc: 0.7743 - val_loss: 0.4890 - val_acc: 0.7708\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4696 - acc: 0.7743 - val_loss: 0.4890 - val_acc: 0.7708\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4696 - acc: 0.7743 - val_loss: 0.4889 - val_acc: 0.7708\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4695 - acc: 0.7743 - val_loss: 0.4889 - val_acc: 0.7708\n",
      "Epoch 479/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4695 - acc: 0.7726 - val_loss: 0.4889 - val_acc: 0.7708\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4695 - acc: 0.7726 - val_loss: 0.4888 - val_acc: 0.7708\n",
      "Epoch 481/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4694 - acc: 0.7726 - val_loss: 0.4888 - val_acc: 0.7708\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4694 - acc: 0.7726 - val_loss: 0.4888 - val_acc: 0.7708\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4693 - acc: 0.7743 - val_loss: 0.4888 - val_acc: 0.7708\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4693 - acc: 0.7726 - val_loss: 0.4887 - val_acc: 0.7708\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4692 - acc: 0.7743 - val_loss: 0.4887 - val_acc: 0.7708\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4692 - acc: 0.7726 - val_loss: 0.4887 - val_acc: 0.7708\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4692 - acc: 0.7726 - val_loss: 0.4887 - val_acc: 0.7708\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4691 - acc: 0.7726 - val_loss: 0.4886 - val_acc: 0.7708\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4691 - acc: 0.7726 - val_loss: 0.4886 - val_acc: 0.7708\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4690 - acc: 0.7726 - val_loss: 0.4886 - val_acc: 0.7708\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4690 - acc: 0.7726 - val_loss: 0.4886 - val_acc: 0.7708\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4690 - acc: 0.7726 - val_loss: 0.4885 - val_acc: 0.7708\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4689 - acc: 0.7726 - val_loss: 0.4885 - val_acc: 0.7708\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4688 - acc: 0.7726 - val_loss: 0.4885 - val_acc: 0.7708\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4688 - acc: 0.7726 - val_loss: 0.4885 - val_acc: 0.7708\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4688 - acc: 0.7726 - val_loss: 0.4884 - val_acc: 0.7708\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4687 - acc: 0.7708 - val_loss: 0.4884 - val_acc: 0.7708\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4687 - acc: 0.7726 - val_loss: 0.4884 - val_acc: 0.7708\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4686 - acc: 0.7708 - val_loss: 0.4884 - val_acc: 0.7708\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4686 - acc: 0.7726 - val_loss: 0.4883 - val_acc: 0.7708\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4686 - acc: 0.7726 - val_loss: 0.4883 - val_acc: 0.7708\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4685 - acc: 0.7726 - val_loss: 0.4883 - val_acc: 0.7708\n",
      "Epoch 503/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4685 - acc: 0.7726 - val_loss: 0.4883 - val_acc: 0.7708\n",
      "Epoch 504/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4684 - acc: 0.7726 - val_loss: 0.4882 - val_acc: 0.7708\n",
      "Epoch 505/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4684 - acc: 0.7726 - val_loss: 0.4882 - val_acc: 0.7708\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4683 - acc: 0.7726 - val_loss: 0.4882 - val_acc: 0.7708\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4683 - acc: 0.7726 - val_loss: 0.4882 - val_acc: 0.7708\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4683 - acc: 0.7726 - val_loss: 0.4881 - val_acc: 0.7708\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4682 - acc: 0.7726 - val_loss: 0.4881 - val_acc: 0.7708\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4682 - acc: 0.7726 - val_loss: 0.4881 - val_acc: 0.7708\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4682 - acc: 0.7726 - val_loss: 0.4881 - val_acc: 0.7708\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4681 - acc: 0.7726 - val_loss: 0.4881 - val_acc: 0.7708\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4681 - acc: 0.7726 - val_loss: 0.4880 - val_acc: 0.7708\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4680 - acc: 0.7708 - val_loss: 0.4880 - val_acc: 0.7708\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4680 - acc: 0.7726 - val_loss: 0.4880 - val_acc: 0.7708\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4680 - acc: 0.7726 - val_loss: 0.4880 - val_acc: 0.7708\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4679 - acc: 0.7726 - val_loss: 0.4879 - val_acc: 0.7708\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.4679 - acc: 0.7726 - val_loss: 0.4879 - val_acc: 0.7708\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4678 - acc: 0.7726 - val_loss: 0.4879 - val_acc: 0.7708\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4678 - acc: 0.7726 - val_loss: 0.4879 - val_acc: 0.7708\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4678 - acc: 0.7726 - val_loss: 0.4879 - val_acc: 0.7708\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4677 - acc: 0.7708 - val_loss: 0.4878 - val_acc: 0.7708\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4677 - acc: 0.7708 - val_loss: 0.4878 - val_acc: 0.7708\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4677 - acc: 0.7708 - val_loss: 0.4878 - val_acc: 0.7708\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4676 - acc: 0.7726 - val_loss: 0.4878 - val_acc: 0.7708\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4676 - acc: 0.7708 - val_loss: 0.4878 - val_acc: 0.7708\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4675 - acc: 0.7708 - val_loss: 0.4877 - val_acc: 0.7708\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4675 - acc: 0.7726 - val_loss: 0.4877 - val_acc: 0.7708\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4675 - acc: 0.7726 - val_loss: 0.4877 - val_acc: 0.7708\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4674 - acc: 0.7708 - val_loss: 0.4877 - val_acc: 0.7708\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4674 - acc: 0.7708 - val_loss: 0.4877 - val_acc: 0.7708\n",
      "Epoch 532/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4674 - acc: 0.7708 - val_loss: 0.4876 - val_acc: 0.7708\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4673 - acc: 0.7726 - val_loss: 0.4876 - val_acc: 0.7708\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4673 - acc: 0.7708 - val_loss: 0.4876 - val_acc: 0.7708\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4672 - acc: 0.7708 - val_loss: 0.4876 - val_acc: 0.7708\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4672 - acc: 0.7708 - val_loss: 0.4876 - val_acc: 0.7708\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4672 - acc: 0.7726 - val_loss: 0.4875 - val_acc: 0.7708\n",
      "Epoch 538/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4672 - acc: 0.7726 - val_loss: 0.4875 - val_acc: 0.7708\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4671 - acc: 0.7708 - val_loss: 0.4875 - val_acc: 0.7708\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4671 - acc: 0.7708 - val_loss: 0.4875 - val_acc: 0.7708\n",
      "Epoch 541/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4670 - acc: 0.7708 - val_loss: 0.4875 - val_acc: 0.7708\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4670 - acc: 0.7726 - val_loss: 0.4874 - val_acc: 0.7708\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4670 - acc: 0.7743 - val_loss: 0.4874 - val_acc: 0.7708\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4669 - acc: 0.7708 - val_loss: 0.4874 - val_acc: 0.7708\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4669 - acc: 0.7708 - val_loss: 0.4874 - val_acc: 0.7708\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4669 - acc: 0.7708 - val_loss: 0.4874 - val_acc: 0.7708\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4668 - acc: 0.7708 - val_loss: 0.4873 - val_acc: 0.7708\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4668 - acc: 0.7726 - val_loss: 0.4873 - val_acc: 0.7708\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4668 - acc: 0.7708 - val_loss: 0.4873 - val_acc: 0.7708\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4667 - acc: 0.7708 - val_loss: 0.4873 - val_acc: 0.7708\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4667 - acc: 0.7743 - val_loss: 0.4873 - val_acc: 0.7708\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4666 - acc: 0.7726 - val_loss: 0.4873 - val_acc: 0.7708\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4666 - acc: 0.7726 - val_loss: 0.4872 - val_acc: 0.7708\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4666 - acc: 0.7743 - val_loss: 0.4872 - val_acc: 0.7708\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4665 - acc: 0.7726 - val_loss: 0.4872 - val_acc: 0.7708\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4666 - acc: 0.7743 - val_loss: 0.4872 - val_acc: 0.7708\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4665 - acc: 0.7743 - val_loss: 0.4872 - val_acc: 0.7708\n",
      "Epoch 558/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4665 - acc: 0.7743 - val_loss: 0.4871 - val_acc: 0.7708\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4664 - acc: 0.7743 - val_loss: 0.4871 - val_acc: 0.7708\n",
      "Epoch 560/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4664 - acc: 0.7760 - val_loss: 0.4871 - val_acc: 0.7708\n",
      "Epoch 561/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4663 - acc: 0.7760 - val_loss: 0.4871 - val_acc: 0.7708\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4663 - acc: 0.7743 - val_loss: 0.4871 - val_acc: 0.7708\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4663 - acc: 0.7743 - val_loss: 0.4871 - val_acc: 0.7708\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4662 - acc: 0.7743 - val_loss: 0.4870 - val_acc: 0.7708\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4662 - acc: 0.7743 - val_loss: 0.4870 - val_acc: 0.7708\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4662 - acc: 0.7760 - val_loss: 0.4870 - val_acc: 0.7708\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4662 - acc: 0.7743 - val_loss: 0.4870 - val_acc: 0.7708\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4661 - acc: 0.7743 - val_loss: 0.4870 - val_acc: 0.7708\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4661 - acc: 0.7743 - val_loss: 0.4870 - val_acc: 0.7708\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4661 - acc: 0.7743 - val_loss: 0.4869 - val_acc: 0.7708\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4660 - acc: 0.7760 - val_loss: 0.4869 - val_acc: 0.7708\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4660 - acc: 0.7743 - val_loss: 0.4869 - val_acc: 0.7708\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4660 - acc: 0.7743 - val_loss: 0.4869 - val_acc: 0.7708\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4659 - acc: 0.7726 - val_loss: 0.4869 - val_acc: 0.7708\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4659 - acc: 0.7726 - val_loss: 0.4869 - val_acc: 0.7708\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4659 - acc: 0.7726 - val_loss: 0.4869 - val_acc: 0.7708\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4658 - acc: 0.7726 - val_loss: 0.4868 - val_acc: 0.7708\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4658 - acc: 0.7726 - val_loss: 0.4868 - val_acc: 0.7708\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4658 - acc: 0.7743 - val_loss: 0.4868 - val_acc: 0.7708\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4658 - acc: 0.7743 - val_loss: 0.4868 - val_acc: 0.7708\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4657 - acc: 0.7726 - val_loss: 0.4868 - val_acc: 0.7708\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4657 - acc: 0.7726 - val_loss: 0.4868 - val_acc: 0.7708\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4657 - acc: 0.7726 - val_loss: 0.4867 - val_acc: 0.7708\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4656 - acc: 0.7726 - val_loss: 0.4867 - val_acc: 0.7708\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4656 - acc: 0.7726 - val_loss: 0.4867 - val_acc: 0.7708\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4656 - acc: 0.7726 - val_loss: 0.4867 - val_acc: 0.7708\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4655 - acc: 0.7743 - val_loss: 0.4867 - val_acc: 0.7708\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4655 - acc: 0.7726 - val_loss: 0.4867 - val_acc: 0.7708\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4655 - acc: 0.7726 - val_loss: 0.4867 - val_acc: 0.7708\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4654 - acc: 0.7726 - val_loss: 0.4866 - val_acc: 0.7708\n",
      "Epoch 591/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4654 - acc: 0.7708 - val_loss: 0.4866 - val_acc: 0.7708\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4654 - acc: 0.7726 - val_loss: 0.4866 - val_acc: 0.7708\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4654 - acc: 0.7726 - val_loss: 0.4866 - val_acc: 0.7708\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4653 - acc: 0.7726 - val_loss: 0.4866 - val_acc: 0.7708\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4653 - acc: 0.7726 - val_loss: 0.4866 - val_acc: 0.7708\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4653 - acc: 0.7726 - val_loss: 0.4866 - val_acc: 0.7708\n",
      "Epoch 597/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4652 - acc: 0.7708 - val_loss: 0.4865 - val_acc: 0.7708\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4652 - acc: 0.7708 - val_loss: 0.4865 - val_acc: 0.7708\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4652 - acc: 0.7708 - val_loss: 0.4865 - val_acc: 0.7708\n",
      "Epoch 600/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4652 - acc: 0.7726 - val_loss: 0.4865 - val_acc: 0.7708\n",
      "Epoch 601/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4651 - acc: 0.7726 - val_loss: 0.4865 - val_acc: 0.7708\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4651 - acc: 0.7726 - val_loss: 0.4865 - val_acc: 0.7708\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4651 - acc: 0.7726 - val_loss: 0.4865 - val_acc: 0.7708\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4651 - acc: 0.7726 - val_loss: 0.4865 - val_acc: 0.7708\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4650 - acc: 0.7726 - val_loss: 0.4864 - val_acc: 0.7708\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.4650 - acc: 0.7726 - val_loss: 0.4864 - val_acc: 0.7708\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4650 - acc: 0.7726 - val_loss: 0.4864 - val_acc: 0.7708\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4649 - acc: 0.7726 - val_loss: 0.4864 - val_acc: 0.7708\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4649 - acc: 0.7743 - val_loss: 0.4864 - val_acc: 0.7708\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4649 - acc: 0.7726 - val_loss: 0.4864 - val_acc: 0.7708\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4649 - acc: 0.7726 - val_loss: 0.4864 - val_acc: 0.7708\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4648 - acc: 0.7726 - val_loss: 0.4864 - val_acc: 0.7708\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4648 - acc: 0.7726 - val_loss: 0.4863 - val_acc: 0.7708\n",
      "Epoch 614/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4648 - acc: 0.7726 - val_loss: 0.4863 - val_acc: 0.7708\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4647 - acc: 0.7726 - val_loss: 0.4863 - val_acc: 0.7708\n",
      "Epoch 616/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4647 - acc: 0.7726 - val_loss: 0.4863 - val_acc: 0.7708\n",
      "Epoch 617/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4647 - acc: 0.7726 - val_loss: 0.4863 - val_acc: 0.7708\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4647 - acc: 0.7726 - val_loss: 0.4863 - val_acc: 0.7708\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4647 - acc: 0.7726 - val_loss: 0.4863 - val_acc: 0.7708\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4646 - acc: 0.7726 - val_loss: 0.4863 - val_acc: 0.7708\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4646 - acc: 0.7726 - val_loss: 0.4862 - val_acc: 0.7708\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4646 - acc: 0.7726 - val_loss: 0.4862 - val_acc: 0.7708\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4645 - acc: 0.7726 - val_loss: 0.4862 - val_acc: 0.7708\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4645 - acc: 0.7726 - val_loss: 0.4862 - val_acc: 0.7708\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4645 - acc: 0.7726 - val_loss: 0.4862 - val_acc: 0.7708\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4644 - acc: 0.7726 - val_loss: 0.4862 - val_acc: 0.7708\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4644 - acc: 0.7726 - val_loss: 0.4862 - val_acc: 0.7708\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4644 - acc: 0.7726 - val_loss: 0.4862 - val_acc: 0.7708\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4644 - acc: 0.7726 - val_loss: 0.4862 - val_acc: 0.7760\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4643 - acc: 0.7708 - val_loss: 0.4861 - val_acc: 0.7760\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4643 - acc: 0.7708 - val_loss: 0.4861 - val_acc: 0.7760\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4643 - acc: 0.7726 - val_loss: 0.4861 - val_acc: 0.7760\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4643 - acc: 0.7726 - val_loss: 0.4861 - val_acc: 0.7760\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4643 - acc: 0.7708 - val_loss: 0.4861 - val_acc: 0.7760\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4642 - acc: 0.7708 - val_loss: 0.4861 - val_acc: 0.7760\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4642 - acc: 0.7708 - val_loss: 0.4861 - val_acc: 0.7760\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4642 - acc: 0.7708 - val_loss: 0.4861 - val_acc: 0.7760\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4642 - acc: 0.7708 - val_loss: 0.4861 - val_acc: 0.7760\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4641 - acc: 0.7708 - val_loss: 0.4860 - val_acc: 0.7760\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4641 - acc: 0.7708 - val_loss: 0.4860 - val_acc: 0.7760\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4641 - acc: 0.7726 - val_loss: 0.4860 - val_acc: 0.7760\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4641 - acc: 0.7726 - val_loss: 0.4860 - val_acc: 0.7760\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4640 - acc: 0.7726 - val_loss: 0.4860 - val_acc: 0.7760\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4640 - acc: 0.7726 - val_loss: 0.4860 - val_acc: 0.7760\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4640 - acc: 0.7726 - val_loss: 0.4860 - val_acc: 0.7760\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4640 - acc: 0.7726 - val_loss: 0.4860 - val_acc: 0.7760\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4639 - acc: 0.7726 - val_loss: 0.4860 - val_acc: 0.7760\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4639 - acc: 0.7743 - val_loss: 0.4860 - val_acc: 0.7760\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4639 - acc: 0.7726 - val_loss: 0.4859 - val_acc: 0.7760\n",
      "Epoch 650/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4639 - acc: 0.7726 - val_loss: 0.4859 - val_acc: 0.7760\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4638 - acc: 0.7726 - val_loss: 0.4859 - val_acc: 0.7760\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4638 - acc: 0.7726 - val_loss: 0.4859 - val_acc: 0.7760\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4638 - acc: 0.7726 - val_loss: 0.4859 - val_acc: 0.7760\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4638 - acc: 0.7726 - val_loss: 0.4859 - val_acc: 0.7760\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4638 - acc: 0.7726 - val_loss: 0.4859 - val_acc: 0.7760\n",
      "Epoch 656/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4637 - acc: 0.7726 - val_loss: 0.4859 - val_acc: 0.7760\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4637 - acc: 0.7726 - val_loss: 0.4859 - val_acc: 0.7760\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4637 - acc: 0.7743 - val_loss: 0.4859 - val_acc: 0.7760\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4637 - acc: 0.7743 - val_loss: 0.4859 - val_acc: 0.7760\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4636 - acc: 0.7726 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 661/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4636 - acc: 0.7743 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4636 - acc: 0.7743 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4636 - acc: 0.7743 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4635 - acc: 0.7743 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4635 - acc: 0.7743 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4635 - acc: 0.7726 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4635 - acc: 0.7743 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4635 - acc: 0.7743 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 669/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4634 - acc: 0.7760 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4634 - acc: 0.7743 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4634 - acc: 0.7743 - val_loss: 0.4858 - val_acc: 0.7760\n",
      "Epoch 672/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4634 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 673/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4634 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4633 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4633 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4633 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4633 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4632 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4632 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4632 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4632 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4631 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4631 - acc: 0.7743 - val_loss: 0.4857 - val_acc: 0.7760\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4631 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4631 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4631 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4630 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4630 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4630 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4630 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4630 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4629 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4629 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4629 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4629 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4629 - acc: 0.7760 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4628 - acc: 0.7743 - val_loss: 0.4856 - val_acc: 0.7760\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4628 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4628 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4628 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4627 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4627 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4627 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4627 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4627 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4627 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4626 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4626 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 709/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4626 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4626 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4626 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4626 - acc: 0.7743 - val_loss: 0.4855 - val_acc: 0.7760\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4625 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4625 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 715/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4625 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4625 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4625 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4624 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 719/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4624 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4624 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 721/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4624 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4624 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4623 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4623 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 725/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4623 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4623 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4623 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7760\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4622 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7708\n",
      "Epoch 729/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4622 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7708\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4622 - acc: 0.7743 - val_loss: 0.4854 - val_acc: 0.7708\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4622 - acc: 0.7726 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4622 - acc: 0.7743 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4621 - acc: 0.7743 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4621 - acc: 0.7743 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4621 - acc: 0.7726 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4621 - acc: 0.7726 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4621 - acc: 0.7743 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4621 - acc: 0.7726 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4621 - acc: 0.7726 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4620 - acc: 0.7726 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4620 - acc: 0.7726 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4620 - acc: 0.7726 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4620 - acc: 0.7708 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4620 - acc: 0.7708 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4619 - acc: 0.7708 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4619 - acc: 0.7708 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4619 - acc: 0.7726 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4619 - acc: 0.7708 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4619 - acc: 0.7708 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4618 - acc: 0.7708 - val_loss: 0.4853 - val_acc: 0.7708\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4618 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4619 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4618 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4618 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4618 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4618 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4618 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4617 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4617 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4617 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4617 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4617 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4617 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4616 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4616 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4616 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4616 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 768/1000\n",
      "576/576 [==============================] - 0s 91us/step - loss: 0.4616 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4615 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4615 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4615 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4615 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4615 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4615 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 775/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4615 - acc: 0.7708 - val_loss: 0.4852 - val_acc: 0.7708\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4614 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4614 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4614 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 779/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4614 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 780/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4614 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 781/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4614 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4613 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 783/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4613 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4613 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 785/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4613 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4613 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4613 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4612 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4612 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4612 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4612 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4612 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4612 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4612 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4612 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4611 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4612 - acc: 0.7708 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4611 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4611 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4611 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4611 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4611 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4610 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4610 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4610 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4610 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7708\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4610 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7656\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4610 - acc: 0.7726 - val_loss: 0.4851 - val_acc: 0.7656\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4610 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4610 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4609 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4609 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4609 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4609 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4609 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4609 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4609 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4608 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4608 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4608 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4608 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4608 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4608 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4607 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4607 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4607 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 827/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4607 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4607 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4607 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4607 - acc: 0.7726 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4607 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4607 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4606 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 834/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4606 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4606 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 836/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4606 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4606 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4606 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 839/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4606 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 840/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4606 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 841/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4605 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4605 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4605 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4605 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4605 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4605 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4605 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4605 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4604 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4604 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7604\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4604 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4604 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4604 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 0s 102us/step - loss: 0.4604 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4604 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4604 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4603 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4603 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4603 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4603 - acc: 0.7743 - val_loss: 0.4850 - val_acc: 0.7656\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4603 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4603 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4603 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4603 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4602 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4602 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4602 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4602 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4602 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4602 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4602 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4602 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4602 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4602 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4601 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4601 - acc: 0.7743 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4601 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4601 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4601 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4601 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 0s 176us/step - loss: 0.4601 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4601 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4601 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4600 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4600 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 886/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4600 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4600 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4600 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4600 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4600 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 891/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4599 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4600 - acc: 0.7760 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 893/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4599 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4599 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4599 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 896/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4599 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4599 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4599 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 899/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4599 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4599 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 901/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4598 - acc: 0.7795 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7708\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4597 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4597 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4597 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4597 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.4597 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4597 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4597 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4597 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4597 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4596 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4596 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4596 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4596 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4596 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4596 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4596 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4596 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4596 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.4596 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.4595 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4595 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4595 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4595 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4595 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4595 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4595 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4595 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.4595 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4595 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4594 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4594 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4594 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 945/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4594 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 946/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4594 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4594 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4594 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4594 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 950/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4594 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4594 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 952/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 961/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4593 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 0s 93us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 0s 87us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 0s 94us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4592 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.4591 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 0s 162us/step - loss: 0.4591 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.4591 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.4591 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4591 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4591 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4591 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.4591 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4591 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4591 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 0s 103us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 0s 95us/step - loss: 0.4590 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4589 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4589 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.4589 - acc: 0.7778 - val_loss: 0.4849 - val_acc: 0.7656\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe28e570490>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1500\n",
      "576/576 [==============================] - 0s 547us/step - loss: 0.6970 - acc: 0.5816 - val_loss: 0.6995 - val_acc: 0.6146\n",
      "Epoch 2/1500\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.6908 - acc: 0.5990 - val_loss: 0.6947 - val_acc: 0.6302\n",
      "Epoch 3/1500\n",
      "576/576 [==============================] - 0s 174us/step - loss: 0.6851 - acc: 0.6094 - val_loss: 0.6901 - val_acc: 0.6354\n",
      "Epoch 4/1500\n",
      "576/576 [==============================] - 0s 196us/step - loss: 0.6797 - acc: 0.6181 - val_loss: 0.6857 - val_acc: 0.6354\n",
      "Epoch 5/1500\n",
      "576/576 [==============================] - 0s 172us/step - loss: 0.6747 - acc: 0.6233 - val_loss: 0.6817 - val_acc: 0.6406\n",
      "Epoch 6/1500\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.6701 - acc: 0.6233 - val_loss: 0.6779 - val_acc: 0.6458\n",
      "Epoch 7/1500\n",
      "576/576 [==============================] - 0s 183us/step - loss: 0.6658 - acc: 0.6319 - val_loss: 0.6744 - val_acc: 0.6406\n",
      "Epoch 8/1500\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.6617 - acc: 0.6319 - val_loss: 0.6710 - val_acc: 0.6406\n",
      "Epoch 9/1500\n",
      "576/576 [==============================] - 0s 172us/step - loss: 0.6579 - acc: 0.6372 - val_loss: 0.6679 - val_acc: 0.6406\n",
      "Epoch 10/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.6543 - acc: 0.6372 - val_loss: 0.6649 - val_acc: 0.6406\n",
      "Epoch 11/1500\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.6510 - acc: 0.6354 - val_loss: 0.6621 - val_acc: 0.6406\n",
      "Epoch 12/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.6478 - acc: 0.6389 - val_loss: 0.6595 - val_acc: 0.6406\n",
      "Epoch 13/1500\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.6448 - acc: 0.6406 - val_loss: 0.6569 - val_acc: 0.6406\n",
      "Epoch 14/1500\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.6419 - acc: 0.6458 - val_loss: 0.6545 - val_acc: 0.6406\n",
      "Epoch 15/1500\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.6392 - acc: 0.6458 - val_loss: 0.6522 - val_acc: 0.6406\n",
      "Epoch 16/1500\n",
      "576/576 [==============================] - 0s 174us/step - loss: 0.6366 - acc: 0.6458 - val_loss: 0.6500 - val_acc: 0.6406\n",
      "Epoch 17/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.6341 - acc: 0.6476 - val_loss: 0.6479 - val_acc: 0.6406\n",
      "Epoch 18/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.6317 - acc: 0.6545 - val_loss: 0.6458 - val_acc: 0.6406\n",
      "Epoch 19/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.6294 - acc: 0.6562 - val_loss: 0.6438 - val_acc: 0.6406\n",
      "Epoch 20/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.6272 - acc: 0.6562 - val_loss: 0.6419 - val_acc: 0.6406\n",
      "Epoch 21/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.6250 - acc: 0.6562 - val_loss: 0.6400 - val_acc: 0.6406\n",
      "Epoch 22/1500\n",
      "576/576 [==============================] - 0s 216us/step - loss: 0.6229 - acc: 0.6597 - val_loss: 0.6382 - val_acc: 0.6406\n",
      "Epoch 23/1500\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.6208 - acc: 0.6597 - val_loss: 0.6364 - val_acc: 0.6406\n",
      "Epoch 24/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.6189 - acc: 0.6615 - val_loss: 0.6347 - val_acc: 0.6458\n",
      "Epoch 25/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.6169 - acc: 0.6632 - val_loss: 0.6330 - val_acc: 0.6458\n",
      "Epoch 26/1500\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.6151 - acc: 0.6667 - val_loss: 0.6314 - val_acc: 0.6458\n",
      "Epoch 27/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.6133 - acc: 0.6701 - val_loss: 0.6298 - val_acc: 0.6458\n",
      "Epoch 28/1500\n",
      "576/576 [==============================] - 0s 195us/step - loss: 0.6114 - acc: 0.6719 - val_loss: 0.6282 - val_acc: 0.6562\n",
      "Epoch 29/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.6097 - acc: 0.6701 - val_loss: 0.6266 - val_acc: 0.6615\n",
      "Epoch 30/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.6080 - acc: 0.6736 - val_loss: 0.6250 - val_acc: 0.6667\n",
      "Epoch 31/1500\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.6063 - acc: 0.6736 - val_loss: 0.6235 - val_acc: 0.6667\n",
      "Epoch 32/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.6046 - acc: 0.6719 - val_loss: 0.6219 - val_acc: 0.6667\n",
      "Epoch 33/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.6030 - acc: 0.6719 - val_loss: 0.6204 - val_acc: 0.6719\n",
      "Epoch 34/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.6014 - acc: 0.6719 - val_loss: 0.6189 - val_acc: 0.6771\n",
      "Epoch 35/1500\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.5998 - acc: 0.6701 - val_loss: 0.6174 - val_acc: 0.6771\n",
      "Epoch 36/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.5983 - acc: 0.6684 - val_loss: 0.6159 - val_acc: 0.6771\n",
      "Epoch 37/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.5968 - acc: 0.6684 - val_loss: 0.6145 - val_acc: 0.6771\n",
      "Epoch 38/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.5954 - acc: 0.6684 - val_loss: 0.6131 - val_acc: 0.6823\n",
      "Epoch 39/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5939 - acc: 0.6684 - val_loss: 0.6117 - val_acc: 0.6823\n",
      "Epoch 40/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5925 - acc: 0.6701 - val_loss: 0.6104 - val_acc: 0.6823\n",
      "Epoch 41/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.5912 - acc: 0.6701 - val_loss: 0.6090 - val_acc: 0.6823\n",
      "Epoch 42/1500\n",
      "576/576 [==============================] - 0s 172us/step - loss: 0.5898 - acc: 0.6701 - val_loss: 0.6077 - val_acc: 0.6823\n",
      "Epoch 43/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.5885 - acc: 0.6771 - val_loss: 0.6065 - val_acc: 0.6823\n",
      "Epoch 44/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.5872 - acc: 0.6753 - val_loss: 0.6052 - val_acc: 0.6823\n",
      "Epoch 45/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.5859 - acc: 0.6788 - val_loss: 0.6040 - val_acc: 0.6823\n",
      "Epoch 46/1500\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.5847 - acc: 0.6736 - val_loss: 0.6028 - val_acc: 0.6823\n",
      "Epoch 47/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5834 - acc: 0.6753 - val_loss: 0.6015 - val_acc: 0.6771\n",
      "Epoch 48/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.5822 - acc: 0.6753 - val_loss: 0.6003 - val_acc: 0.6719\n",
      "Epoch 49/1500\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.5810 - acc: 0.6771 - val_loss: 0.5992 - val_acc: 0.6719\n",
      "Epoch 50/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.5798 - acc: 0.6806 - val_loss: 0.5980 - val_acc: 0.6719\n",
      "Epoch 51/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.5786 - acc: 0.6823 - val_loss: 0.5969 - val_acc: 0.6719\n",
      "Epoch 52/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.5775 - acc: 0.6858 - val_loss: 0.5958 - val_acc: 0.6771\n",
      "Epoch 53/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.5763 - acc: 0.6892 - val_loss: 0.5947 - val_acc: 0.6771\n",
      "Epoch 54/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5752 - acc: 0.6910 - val_loss: 0.5936 - val_acc: 0.6719\n",
      "Epoch 55/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.5741 - acc: 0.6927 - val_loss: 0.5925 - val_acc: 0.6719\n",
      "Epoch 56/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.5730 - acc: 0.6927 - val_loss: 0.5914 - val_acc: 0.6719\n",
      "Epoch 57/1500\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.5719 - acc: 0.6927 - val_loss: 0.5904 - val_acc: 0.6719\n",
      "Epoch 58/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.5708 - acc: 0.6927 - val_loss: 0.5893 - val_acc: 0.6823\n",
      "Epoch 59/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5697 - acc: 0.6944 - val_loss: 0.5882 - val_acc: 0.6823\n",
      "Epoch 60/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.5687 - acc: 0.6944 - val_loss: 0.5871 - val_acc: 0.6823\n",
      "Epoch 61/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.5676 - acc: 0.6944 - val_loss: 0.5861 - val_acc: 0.6823\n",
      "Epoch 62/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5665 - acc: 0.6979 - val_loss: 0.5850 - val_acc: 0.6875\n",
      "Epoch 63/1500\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.5654 - acc: 0.6997 - val_loss: 0.5840 - val_acc: 0.6875\n",
      "Epoch 64/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.5643 - acc: 0.7014 - val_loss: 0.5829 - val_acc: 0.6875\n",
      "Epoch 65/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.5632 - acc: 0.7014 - val_loss: 0.5819 - val_acc: 0.6875\n",
      "Epoch 66/1500\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.5621 - acc: 0.7014 - val_loss: 0.5808 - val_acc: 0.6823\n",
      "Epoch 67/1500\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.5611 - acc: 0.7014 - val_loss: 0.5798 - val_acc: 0.6823\n",
      "Epoch 68/1500\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.5600 - acc: 0.7049 - val_loss: 0.5788 - val_acc: 0.6823\n",
      "Epoch 69/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.5590 - acc: 0.7066 - val_loss: 0.5778 - val_acc: 0.6823\n",
      "Epoch 70/1500\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.5580 - acc: 0.7066 - val_loss: 0.5768 - val_acc: 0.6771\n",
      "Epoch 71/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.5570 - acc: 0.7101 - val_loss: 0.5759 - val_acc: 0.6823\n",
      "Epoch 72/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5560 - acc: 0.7135 - val_loss: 0.5749 - val_acc: 0.6823\n",
      "Epoch 73/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5551 - acc: 0.7101 - val_loss: 0.5740 - val_acc: 0.6875\n",
      "Epoch 74/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.5541 - acc: 0.7101 - val_loss: 0.5730 - val_acc: 0.6875\n",
      "Epoch 75/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5531 - acc: 0.7066 - val_loss: 0.5721 - val_acc: 0.6875\n",
      "Epoch 76/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.5522 - acc: 0.7031 - val_loss: 0.5711 - val_acc: 0.6875\n",
      "Epoch 77/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.5513 - acc: 0.7014 - val_loss: 0.5702 - val_acc: 0.6875\n",
      "Epoch 78/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5503 - acc: 0.6997 - val_loss: 0.5693 - val_acc: 0.6927\n",
      "Epoch 79/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5495 - acc: 0.7014 - val_loss: 0.5685 - val_acc: 0.6927\n",
      "Epoch 80/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.5486 - acc: 0.7014 - val_loss: 0.5676 - val_acc: 0.6979\n",
      "Epoch 81/1500\n",
      "576/576 [==============================] - 0s 215us/step - loss: 0.5477 - acc: 0.7031 - val_loss: 0.5668 - val_acc: 0.6979\n",
      "Epoch 82/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.5468 - acc: 0.7031 - val_loss: 0.5659 - val_acc: 0.6979\n",
      "Epoch 83/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.5460 - acc: 0.7031 - val_loss: 0.5651 - val_acc: 0.6979\n",
      "Epoch 84/1500\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.5451 - acc: 0.7014 - val_loss: 0.5643 - val_acc: 0.6979\n",
      "Epoch 85/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.5443 - acc: 0.6997 - val_loss: 0.5635 - val_acc: 0.6979\n",
      "Epoch 86/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.5435 - acc: 0.7014 - val_loss: 0.5627 - val_acc: 0.6927\n",
      "Epoch 87/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.5427 - acc: 0.7014 - val_loss: 0.5620 - val_acc: 0.6875\n",
      "Epoch 88/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5419 - acc: 0.7031 - val_loss: 0.5612 - val_acc: 0.6927\n",
      "Epoch 89/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5411 - acc: 0.7101 - val_loss: 0.5604 - val_acc: 0.6927\n",
      "Epoch 90/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5402 - acc: 0.7101 - val_loss: 0.5597 - val_acc: 0.6927\n",
      "Epoch 91/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5395 - acc: 0.7101 - val_loss: 0.5589 - val_acc: 0.6927\n",
      "Epoch 92/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.5387 - acc: 0.7101 - val_loss: 0.5582 - val_acc: 0.6927\n",
      "Epoch 93/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.5379 - acc: 0.7135 - val_loss: 0.5575 - val_acc: 0.6927\n",
      "Epoch 94/1500\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.5371 - acc: 0.7135 - val_loss: 0.5568 - val_acc: 0.6927\n",
      "Epoch 95/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.5363 - acc: 0.7170 - val_loss: 0.5561 - val_acc: 0.6979\n",
      "Epoch 96/1500\n",
      "576/576 [==============================] - 0s 162us/step - loss: 0.5355 - acc: 0.7170 - val_loss: 0.5554 - val_acc: 0.6979\n",
      "Epoch 97/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.5347 - acc: 0.7170 - val_loss: 0.5547 - val_acc: 0.6979\n",
      "Epoch 98/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.5339 - acc: 0.7188 - val_loss: 0.5540 - val_acc: 0.6979\n",
      "Epoch 99/1500\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.5332 - acc: 0.7188 - val_loss: 0.5534 - val_acc: 0.6979\n",
      "Epoch 100/1500\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.5325 - acc: 0.7205 - val_loss: 0.5527 - val_acc: 0.7031\n",
      "Epoch 101/1500\n",
      "576/576 [==============================] - 0s 149us/step - loss: 0.5318 - acc: 0.7222 - val_loss: 0.5521 - val_acc: 0.7031\n",
      "Epoch 102/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.5310 - acc: 0.7257 - val_loss: 0.5514 - val_acc: 0.7031\n",
      "Epoch 103/1500\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.5303 - acc: 0.7257 - val_loss: 0.5508 - val_acc: 0.7031\n",
      "Epoch 104/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.5296 - acc: 0.7344 - val_loss: 0.5502 - val_acc: 0.7031\n",
      "Epoch 105/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5289 - acc: 0.7344 - val_loss: 0.5496 - val_acc: 0.7031\n",
      "Epoch 106/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.5282 - acc: 0.7326 - val_loss: 0.5490 - val_acc: 0.7083\n",
      "Epoch 107/1500\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.5275 - acc: 0.7309 - val_loss: 0.5484 - val_acc: 0.7083\n",
      "Epoch 108/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.5268 - acc: 0.7309 - val_loss: 0.5478 - val_acc: 0.7083\n",
      "Epoch 109/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5262 - acc: 0.7326 - val_loss: 0.5472 - val_acc: 0.7083\n",
      "Epoch 110/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5255 - acc: 0.7326 - val_loss: 0.5467 - val_acc: 0.7083\n",
      "Epoch 111/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.5249 - acc: 0.7309 - val_loss: 0.5461 - val_acc: 0.7083\n",
      "Epoch 112/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5242 - acc: 0.7326 - val_loss: 0.5456 - val_acc: 0.7083\n",
      "Epoch 113/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5236 - acc: 0.7344 - val_loss: 0.5450 - val_acc: 0.7083\n",
      "Epoch 114/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5230 - acc: 0.7326 - val_loss: 0.5445 - val_acc: 0.7135\n",
      "Epoch 115/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.5224 - acc: 0.7326 - val_loss: 0.5440 - val_acc: 0.7240\n",
      "Epoch 116/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.5217 - acc: 0.7309 - val_loss: 0.5435 - val_acc: 0.7240\n",
      "Epoch 117/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.5212 - acc: 0.7309 - val_loss: 0.5430 - val_acc: 0.7240\n",
      "Epoch 118/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.5206 - acc: 0.7309 - val_loss: 0.5425 - val_acc: 0.7240\n",
      "Epoch 119/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.5200 - acc: 0.7326 - val_loss: 0.5420 - val_acc: 0.7240\n",
      "Epoch 120/1500\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.5194 - acc: 0.7326 - val_loss: 0.5415 - val_acc: 0.7240\n",
      "Epoch 121/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.5188 - acc: 0.7344 - val_loss: 0.5410 - val_acc: 0.7292\n",
      "Epoch 122/1500\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.5182 - acc: 0.7378 - val_loss: 0.5406 - val_acc: 0.7292\n",
      "Epoch 123/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5176 - acc: 0.7378 - val_loss: 0.5401 - val_acc: 0.7292\n",
      "Epoch 124/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.5171 - acc: 0.7361 - val_loss: 0.5397 - val_acc: 0.7292\n",
      "Epoch 125/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.5165 - acc: 0.7344 - val_loss: 0.5392 - val_acc: 0.7240\n",
      "Epoch 126/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.5160 - acc: 0.7344 - val_loss: 0.5388 - val_acc: 0.7240\n",
      "Epoch 127/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.5154 - acc: 0.7361 - val_loss: 0.5383 - val_acc: 0.7240\n",
      "Epoch 128/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5149 - acc: 0.7361 - val_loss: 0.5379 - val_acc: 0.7240\n",
      "Epoch 129/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.5143 - acc: 0.7344 - val_loss: 0.5375 - val_acc: 0.7240\n",
      "Epoch 130/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.5137 - acc: 0.7344 - val_loss: 0.5371 - val_acc: 0.7240\n",
      "Epoch 131/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.5132 - acc: 0.7361 - val_loss: 0.5367 - val_acc: 0.7240\n",
      "Epoch 132/1500\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.5126 - acc: 0.7361 - val_loss: 0.5363 - val_acc: 0.7240\n",
      "Epoch 133/1500\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.5121 - acc: 0.7361 - val_loss: 0.5358 - val_acc: 0.7240\n",
      "Epoch 134/1500\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.5116 - acc: 0.7361 - val_loss: 0.5354 - val_acc: 0.7240\n",
      "Epoch 135/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.5110 - acc: 0.7361 - val_loss: 0.5350 - val_acc: 0.7240\n",
      "Epoch 136/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5105 - acc: 0.7396 - val_loss: 0.5346 - val_acc: 0.7240\n",
      "Epoch 137/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.5100 - acc: 0.7396 - val_loss: 0.5343 - val_acc: 0.7240\n",
      "Epoch 138/1500\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.5095 - acc: 0.7396 - val_loss: 0.5339 - val_acc: 0.7292\n",
      "Epoch 139/1500\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.5090 - acc: 0.7396 - val_loss: 0.5335 - val_acc: 0.7292\n",
      "Epoch 140/1500\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.5085 - acc: 0.7396 - val_loss: 0.5331 - val_acc: 0.7292\n",
      "Epoch 141/1500\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.5080 - acc: 0.7431 - val_loss: 0.5328 - val_acc: 0.7292\n",
      "Epoch 142/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.5075 - acc: 0.7431 - val_loss: 0.5324 - val_acc: 0.7292\n",
      "Epoch 143/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.5071 - acc: 0.7431 - val_loss: 0.5320 - val_acc: 0.7292\n",
      "Epoch 144/1500\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.5066 - acc: 0.7431 - val_loss: 0.5317 - val_acc: 0.7292\n",
      "Epoch 145/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.5061 - acc: 0.7413 - val_loss: 0.5313 - val_acc: 0.7292\n",
      "Epoch 146/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.5057 - acc: 0.7413 - val_loss: 0.5310 - val_acc: 0.7292\n",
      "Epoch 147/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.5052 - acc: 0.7413 - val_loss: 0.5307 - val_acc: 0.7292\n",
      "Epoch 148/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.5048 - acc: 0.7413 - val_loss: 0.5303 - val_acc: 0.7292\n",
      "Epoch 149/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.5044 - acc: 0.7413 - val_loss: 0.5300 - val_acc: 0.7292\n",
      "Epoch 150/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.5039 - acc: 0.7431 - val_loss: 0.5296 - val_acc: 0.7292\n",
      "Epoch 151/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5036 - acc: 0.7431 - val_loss: 0.5293 - val_acc: 0.7292\n",
      "Epoch 152/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.5031 - acc: 0.7448 - val_loss: 0.5290 - val_acc: 0.7292\n",
      "Epoch 153/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5027 - acc: 0.7448 - val_loss: 0.5287 - val_acc: 0.7292\n",
      "Epoch 154/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5023 - acc: 0.7448 - val_loss: 0.5283 - val_acc: 0.7292\n",
      "Epoch 155/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.5019 - acc: 0.7448 - val_loss: 0.5280 - val_acc: 0.7292\n",
      "Epoch 156/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.5015 - acc: 0.7448 - val_loss: 0.5277 - val_acc: 0.7292\n",
      "Epoch 157/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.5010 - acc: 0.7431 - val_loss: 0.5274 - val_acc: 0.7292\n",
      "Epoch 158/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5006 - acc: 0.7431 - val_loss: 0.5271 - val_acc: 0.7292\n",
      "Epoch 159/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.5002 - acc: 0.7431 - val_loss: 0.5267 - val_acc: 0.7292\n",
      "Epoch 160/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4998 - acc: 0.7431 - val_loss: 0.5264 - val_acc: 0.7292\n",
      "Epoch 161/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4994 - acc: 0.7431 - val_loss: 0.5261 - val_acc: 0.7292\n",
      "Epoch 162/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4991 - acc: 0.7448 - val_loss: 0.5258 - val_acc: 0.7292\n",
      "Epoch 163/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4987 - acc: 0.7431 - val_loss: 0.5255 - val_acc: 0.7292\n",
      "Epoch 164/1500\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4983 - acc: 0.7465 - val_loss: 0.5252 - val_acc: 0.7292\n",
      "Epoch 165/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4979 - acc: 0.7448 - val_loss: 0.5249 - val_acc: 0.7292\n",
      "Epoch 166/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4975 - acc: 0.7483 - val_loss: 0.5247 - val_acc: 0.7292\n",
      "Epoch 167/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4971 - acc: 0.7465 - val_loss: 0.5244 - val_acc: 0.7292\n",
      "Epoch 168/1500\n",
      "576/576 [==============================] - 0s 149us/step - loss: 0.4968 - acc: 0.7448 - val_loss: 0.5241 - val_acc: 0.7292\n",
      "Epoch 169/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4964 - acc: 0.7431 - val_loss: 0.5238 - val_acc: 0.7292\n",
      "Epoch 170/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4961 - acc: 0.7431 - val_loss: 0.5235 - val_acc: 0.7292\n",
      "Epoch 171/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4958 - acc: 0.7448 - val_loss: 0.5232 - val_acc: 0.7292\n",
      "Epoch 172/1500\n",
      "576/576 [==============================] - 0s 162us/step - loss: 0.4954 - acc: 0.7448 - val_loss: 0.5230 - val_acc: 0.7292\n",
      "Epoch 173/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4950 - acc: 0.7431 - val_loss: 0.5227 - val_acc: 0.7292\n",
      "Epoch 174/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4947 - acc: 0.7483 - val_loss: 0.5225 - val_acc: 0.7292\n",
      "Epoch 175/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4944 - acc: 0.7483 - val_loss: 0.5222 - val_acc: 0.7292\n",
      "Epoch 176/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4940 - acc: 0.7500 - val_loss: 0.5220 - val_acc: 0.7292\n",
      "Epoch 177/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4937 - acc: 0.7483 - val_loss: 0.5217 - val_acc: 0.7292\n",
      "Epoch 178/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4934 - acc: 0.7500 - val_loss: 0.5215 - val_acc: 0.7292\n",
      "Epoch 179/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4931 - acc: 0.7500 - val_loss: 0.5213 - val_acc: 0.7292\n",
      "Epoch 180/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4928 - acc: 0.7500 - val_loss: 0.5210 - val_acc: 0.7292\n",
      "Epoch 181/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4925 - acc: 0.7500 - val_loss: 0.5208 - val_acc: 0.7292\n",
      "Epoch 182/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4921 - acc: 0.7500 - val_loss: 0.5206 - val_acc: 0.7292\n",
      "Epoch 183/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4918 - acc: 0.7500 - val_loss: 0.5203 - val_acc: 0.7292\n",
      "Epoch 184/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4915 - acc: 0.7500 - val_loss: 0.5201 - val_acc: 0.7292\n",
      "Epoch 185/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4912 - acc: 0.7500 - val_loss: 0.5199 - val_acc: 0.7292\n",
      "Epoch 186/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4908 - acc: 0.7517 - val_loss: 0.5196 - val_acc: 0.7292\n",
      "Epoch 187/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4905 - acc: 0.7500 - val_loss: 0.5194 - val_acc: 0.7292\n",
      "Epoch 188/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4903 - acc: 0.7517 - val_loss: 0.5192 - val_acc: 0.7292\n",
      "Epoch 189/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4899 - acc: 0.7500 - val_loss: 0.5190 - val_acc: 0.7344\n",
      "Epoch 190/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4896 - acc: 0.7500 - val_loss: 0.5188 - val_acc: 0.7344\n",
      "Epoch 191/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4893 - acc: 0.7517 - val_loss: 0.5185 - val_acc: 0.7344\n",
      "Epoch 192/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4890 - acc: 0.7535 - val_loss: 0.5183 - val_acc: 0.7396\n",
      "Epoch 193/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4886 - acc: 0.7517 - val_loss: 0.5180 - val_acc: 0.7396\n",
      "Epoch 194/1500\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4883 - acc: 0.7517 - val_loss: 0.5178 - val_acc: 0.7396\n",
      "Epoch 195/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4880 - acc: 0.7517 - val_loss: 0.5176 - val_acc: 0.7396\n",
      "Epoch 196/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4877 - acc: 0.7535 - val_loss: 0.5174 - val_acc: 0.7396\n",
      "Epoch 197/1500\n",
      "576/576 [==============================] - 0s 149us/step - loss: 0.4874 - acc: 0.7552 - val_loss: 0.5172 - val_acc: 0.7448\n",
      "Epoch 198/1500\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4871 - acc: 0.7552 - val_loss: 0.5169 - val_acc: 0.7448\n",
      "Epoch 199/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4868 - acc: 0.7552 - val_loss: 0.5167 - val_acc: 0.7448\n",
      "Epoch 200/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4864 - acc: 0.7552 - val_loss: 0.5165 - val_acc: 0.7448\n",
      "Epoch 201/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4861 - acc: 0.7552 - val_loss: 0.5163 - val_acc: 0.7448\n",
      "Epoch 202/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4859 - acc: 0.7552 - val_loss: 0.5161 - val_acc: 0.7448\n",
      "Epoch 203/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4856 - acc: 0.7552 - val_loss: 0.5160 - val_acc: 0.7448\n",
      "Epoch 204/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4853 - acc: 0.7552 - val_loss: 0.5158 - val_acc: 0.7448\n",
      "Epoch 205/1500\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4850 - acc: 0.7552 - val_loss: 0.5156 - val_acc: 0.7448\n",
      "Epoch 206/1500\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.4848 - acc: 0.7552 - val_loss: 0.5154 - val_acc: 0.7448\n",
      "Epoch 207/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4845 - acc: 0.7552 - val_loss: 0.5152 - val_acc: 0.7448\n",
      "Epoch 208/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4842 - acc: 0.7535 - val_loss: 0.5150 - val_acc: 0.7448\n",
      "Epoch 209/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4840 - acc: 0.7517 - val_loss: 0.5148 - val_acc: 0.7448\n",
      "Epoch 210/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4837 - acc: 0.7535 - val_loss: 0.5147 - val_acc: 0.7448\n",
      "Epoch 211/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4834 - acc: 0.7517 - val_loss: 0.5145 - val_acc: 0.7448\n",
      "Epoch 212/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4831 - acc: 0.7517 - val_loss: 0.5143 - val_acc: 0.7448\n",
      "Epoch 213/1500\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4829 - acc: 0.7517 - val_loss: 0.5141 - val_acc: 0.7448\n",
      "Epoch 214/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4826 - acc: 0.7517 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 215/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4824 - acc: 0.7517 - val_loss: 0.5138 - val_acc: 0.7448\n",
      "Epoch 216/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4821 - acc: 0.7517 - val_loss: 0.5136 - val_acc: 0.7448\n",
      "Epoch 217/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4819 - acc: 0.7535 - val_loss: 0.5135 - val_acc: 0.7448\n",
      "Epoch 218/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4817 - acc: 0.7535 - val_loss: 0.5133 - val_acc: 0.7448\n",
      "Epoch 219/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4814 - acc: 0.7535 - val_loss: 0.5131 - val_acc: 0.7448\n",
      "Epoch 220/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4811 - acc: 0.7535 - val_loss: 0.5130 - val_acc: 0.7448\n",
      "Epoch 221/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4809 - acc: 0.7535 - val_loss: 0.5128 - val_acc: 0.7448\n",
      "Epoch 222/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4807 - acc: 0.7535 - val_loss: 0.5127 - val_acc: 0.7448\n",
      "Epoch 223/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4804 - acc: 0.7535 - val_loss: 0.5125 - val_acc: 0.7448\n",
      "Epoch 224/1500\n",
      "576/576 [==============================] - 0s 153us/step - loss: 0.4802 - acc: 0.7535 - val_loss: 0.5123 - val_acc: 0.7448\n",
      "Epoch 225/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4799 - acc: 0.7552 - val_loss: 0.5121 - val_acc: 0.7448\n",
      "Epoch 226/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4797 - acc: 0.7552 - val_loss: 0.5120 - val_acc: 0.7448\n",
      "Epoch 227/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4795 - acc: 0.7552 - val_loss: 0.5118 - val_acc: 0.7448\n",
      "Epoch 228/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4792 - acc: 0.7552 - val_loss: 0.5116 - val_acc: 0.7448\n",
      "Epoch 229/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4790 - acc: 0.7535 - val_loss: 0.5115 - val_acc: 0.7448\n",
      "Epoch 230/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4787 - acc: 0.7552 - val_loss: 0.5113 - val_acc: 0.7448\n",
      "Epoch 231/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4785 - acc: 0.7535 - val_loss: 0.5111 - val_acc: 0.7448\n",
      "Epoch 232/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4783 - acc: 0.7535 - val_loss: 0.5110 - val_acc: 0.7448\n",
      "Epoch 233/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4781 - acc: 0.7535 - val_loss: 0.5108 - val_acc: 0.7500\n",
      "Epoch 234/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4778 - acc: 0.7535 - val_loss: 0.5106 - val_acc: 0.7500\n",
      "Epoch 235/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4776 - acc: 0.7535 - val_loss: 0.5105 - val_acc: 0.7500\n",
      "Epoch 236/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4773 - acc: 0.7535 - val_loss: 0.5103 - val_acc: 0.7552\n",
      "Epoch 237/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4771 - acc: 0.7517 - val_loss: 0.5101 - val_acc: 0.7552\n",
      "Epoch 238/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4769 - acc: 0.7517 - val_loss: 0.5100 - val_acc: 0.7552\n",
      "Epoch 239/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4766 - acc: 0.7535 - val_loss: 0.5098 - val_acc: 0.7500\n",
      "Epoch 240/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4764 - acc: 0.7535 - val_loss: 0.5097 - val_acc: 0.7500\n",
      "Epoch 241/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4762 - acc: 0.7535 - val_loss: 0.5095 - val_acc: 0.7500\n",
      "Epoch 242/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4760 - acc: 0.7535 - val_loss: 0.5094 - val_acc: 0.7500\n",
      "Epoch 243/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4757 - acc: 0.7535 - val_loss: 0.5092 - val_acc: 0.7500\n",
      "Epoch 244/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4755 - acc: 0.7552 - val_loss: 0.5091 - val_acc: 0.7500\n",
      "Epoch 245/1500\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4753 - acc: 0.7552 - val_loss: 0.5089 - val_acc: 0.7500\n",
      "Epoch 246/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4750 - acc: 0.7552 - val_loss: 0.5088 - val_acc: 0.7500\n",
      "Epoch 247/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4748 - acc: 0.7552 - val_loss: 0.5086 - val_acc: 0.7500\n",
      "Epoch 248/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4746 - acc: 0.7552 - val_loss: 0.5085 - val_acc: 0.7500\n",
      "Epoch 249/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4744 - acc: 0.7552 - val_loss: 0.5083 - val_acc: 0.7500\n",
      "Epoch 250/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4742 - acc: 0.7552 - val_loss: 0.5082 - val_acc: 0.7500\n",
      "Epoch 251/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4740 - acc: 0.7552 - val_loss: 0.5080 - val_acc: 0.7500\n",
      "Epoch 252/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4737 - acc: 0.7552 - val_loss: 0.5079 - val_acc: 0.7500\n",
      "Epoch 253/1500\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4735 - acc: 0.7552 - val_loss: 0.5077 - val_acc: 0.7500\n",
      "Epoch 254/1500\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4733 - acc: 0.7552 - val_loss: 0.5076 - val_acc: 0.7500\n",
      "Epoch 255/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4730 - acc: 0.7569 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 256/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4728 - acc: 0.7569 - val_loss: 0.5073 - val_acc: 0.7552\n",
      "Epoch 257/1500\n",
      "576/576 [==============================] - 0s 177us/step - loss: 0.4726 - acc: 0.7569 - val_loss: 0.5071 - val_acc: 0.7552\n",
      "Epoch 258/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4724 - acc: 0.7569 - val_loss: 0.5070 - val_acc: 0.7552\n",
      "Epoch 259/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4721 - acc: 0.7569 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 260/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4719 - acc: 0.7604 - val_loss: 0.5067 - val_acc: 0.7656\n",
      "Epoch 261/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4717 - acc: 0.7587 - val_loss: 0.5065 - val_acc: 0.7656\n",
      "Epoch 262/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4714 - acc: 0.7604 - val_loss: 0.5063 - val_acc: 0.7656\n",
      "Epoch 263/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4712 - acc: 0.7587 - val_loss: 0.5062 - val_acc: 0.7656\n",
      "Epoch 264/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4710 - acc: 0.7622 - val_loss: 0.5060 - val_acc: 0.7656\n",
      "Epoch 265/1500\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4707 - acc: 0.7604 - val_loss: 0.5059 - val_acc: 0.7656\n",
      "Epoch 266/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4705 - acc: 0.7622 - val_loss: 0.5057 - val_acc: 0.7656\n",
      "Epoch 267/1500\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4703 - acc: 0.7622 - val_loss: 0.5055 - val_acc: 0.7656\n",
      "Epoch 268/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4700 - acc: 0.7622 - val_loss: 0.5054 - val_acc: 0.7656\n",
      "Epoch 269/1500\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.4698 - acc: 0.7622 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 270/1500\n",
      "576/576 [==============================] - 0s 179us/step - loss: 0.4696 - acc: 0.7622 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 271/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4694 - acc: 0.7622 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 272/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4691 - acc: 0.7622 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 273/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4688 - acc: 0.7622 - val_loss: 0.5045 - val_acc: 0.7708\n",
      "Epoch 274/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4686 - acc: 0.7622 - val_loss: 0.5044 - val_acc: 0.7708\n",
      "Epoch 275/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4683 - acc: 0.7622 - val_loss: 0.5042 - val_acc: 0.7708\n",
      "Epoch 276/1500\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4681 - acc: 0.7622 - val_loss: 0.5040 - val_acc: 0.7708\n",
      "Epoch 277/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4678 - acc: 0.7622 - val_loss: 0.5039 - val_acc: 0.7708\n",
      "Epoch 278/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4676 - acc: 0.7622 - val_loss: 0.5037 - val_acc: 0.7708\n",
      "Epoch 279/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4673 - acc: 0.7622 - val_loss: 0.5035 - val_acc: 0.7708\n",
      "Epoch 280/1500\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.4671 - acc: 0.7622 - val_loss: 0.5034 - val_acc: 0.7708\n",
      "Epoch 281/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4669 - acc: 0.7622 - val_loss: 0.5032 - val_acc: 0.7708\n",
      "Epoch 282/1500\n",
      "576/576 [==============================] - 0s 156us/step - loss: 0.4666 - acc: 0.7622 - val_loss: 0.5031 - val_acc: 0.7708\n",
      "Epoch 283/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4664 - acc: 0.7639 - val_loss: 0.5030 - val_acc: 0.7708\n",
      "Epoch 284/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4662 - acc: 0.7656 - val_loss: 0.5028 - val_acc: 0.7708\n",
      "Epoch 285/1500\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4659 - acc: 0.7639 - val_loss: 0.5027 - val_acc: 0.7708\n",
      "Epoch 286/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4657 - acc: 0.7656 - val_loss: 0.5025 - val_acc: 0.7760\n",
      "Epoch 287/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4655 - acc: 0.7691 - val_loss: 0.5024 - val_acc: 0.7760\n",
      "Epoch 288/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4653 - acc: 0.7674 - val_loss: 0.5022 - val_acc: 0.7760\n",
      "Epoch 289/1500\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.4651 - acc: 0.7691 - val_loss: 0.5021 - val_acc: 0.7760\n",
      "Epoch 290/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4648 - acc: 0.7708 - val_loss: 0.5020 - val_acc: 0.7760\n",
      "Epoch 291/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4646 - acc: 0.7691 - val_loss: 0.5018 - val_acc: 0.7760\n",
      "Epoch 292/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4644 - acc: 0.7691 - val_loss: 0.5017 - val_acc: 0.7760\n",
      "Epoch 293/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4642 - acc: 0.7691 - val_loss: 0.5015 - val_acc: 0.7760\n",
      "Epoch 294/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4640 - acc: 0.7691 - val_loss: 0.5014 - val_acc: 0.7760\n",
      "Epoch 295/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4638 - acc: 0.7691 - val_loss: 0.5012 - val_acc: 0.7760\n",
      "Epoch 296/1500\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4636 - acc: 0.7691 - val_loss: 0.5011 - val_acc: 0.7760\n",
      "Epoch 297/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4634 - acc: 0.7691 - val_loss: 0.5010 - val_acc: 0.7760\n",
      "Epoch 298/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4632 - acc: 0.7691 - val_loss: 0.5008 - val_acc: 0.7760\n",
      "Epoch 299/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4629 - acc: 0.7691 - val_loss: 0.5007 - val_acc: 0.7760\n",
      "Epoch 300/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4628 - acc: 0.7691 - val_loss: 0.5005 - val_acc: 0.7760\n",
      "Epoch 301/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4626 - acc: 0.7708 - val_loss: 0.5004 - val_acc: 0.7760\n",
      "Epoch 302/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4624 - acc: 0.7726 - val_loss: 0.5003 - val_acc: 0.7760\n",
      "Epoch 303/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4621 - acc: 0.7726 - val_loss: 0.5001 - val_acc: 0.7760\n",
      "Epoch 304/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4620 - acc: 0.7726 - val_loss: 0.5000 - val_acc: 0.7760\n",
      "Epoch 305/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4617 - acc: 0.7726 - val_loss: 0.4999 - val_acc: 0.7760\n",
      "Epoch 306/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4616 - acc: 0.7726 - val_loss: 0.4997 - val_acc: 0.7760\n",
      "Epoch 307/1500\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4614 - acc: 0.7726 - val_loss: 0.4996 - val_acc: 0.7760\n",
      "Epoch 308/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4612 - acc: 0.7743 - val_loss: 0.4995 - val_acc: 0.7812\n",
      "Epoch 309/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4610 - acc: 0.7726 - val_loss: 0.4993 - val_acc: 0.7812\n",
      "Epoch 310/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4608 - acc: 0.7743 - val_loss: 0.4992 - val_acc: 0.7812\n",
      "Epoch 311/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4606 - acc: 0.7743 - val_loss: 0.4991 - val_acc: 0.7812\n",
      "Epoch 312/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4604 - acc: 0.7743 - val_loss: 0.4990 - val_acc: 0.7812\n",
      "Epoch 313/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4602 - acc: 0.7743 - val_loss: 0.4988 - val_acc: 0.7812\n",
      "Epoch 314/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4600 - acc: 0.7726 - val_loss: 0.4987 - val_acc: 0.7812\n",
      "Epoch 315/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4598 - acc: 0.7743 - val_loss: 0.4986 - val_acc: 0.7812\n",
      "Epoch 316/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4597 - acc: 0.7743 - val_loss: 0.4985 - val_acc: 0.7812\n",
      "Epoch 317/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4595 - acc: 0.7743 - val_loss: 0.4984 - val_acc: 0.7865\n",
      "Epoch 318/1500\n",
      "576/576 [==============================] - 0s 179us/step - loss: 0.4593 - acc: 0.7743 - val_loss: 0.4983 - val_acc: 0.7865\n",
      "Epoch 319/1500\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4592 - acc: 0.7743 - val_loss: 0.4982 - val_acc: 0.7865\n",
      "Epoch 320/1500\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4590 - acc: 0.7743 - val_loss: 0.4981 - val_acc: 0.7865\n",
      "Epoch 321/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4588 - acc: 0.7743 - val_loss: 0.4980 - val_acc: 0.7865\n",
      "Epoch 322/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4586 - acc: 0.7726 - val_loss: 0.4979 - val_acc: 0.7865\n",
      "Epoch 323/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4584 - acc: 0.7726 - val_loss: 0.4978 - val_acc: 0.7812\n",
      "Epoch 324/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4583 - acc: 0.7726 - val_loss: 0.4977 - val_acc: 0.7812\n",
      "Epoch 325/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4581 - acc: 0.7726 - val_loss: 0.4976 - val_acc: 0.7812\n",
      "Epoch 326/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4580 - acc: 0.7726 - val_loss: 0.4975 - val_acc: 0.7812\n",
      "Epoch 327/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4578 - acc: 0.7726 - val_loss: 0.4974 - val_acc: 0.7812\n",
      "Epoch 328/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4577 - acc: 0.7726 - val_loss: 0.4973 - val_acc: 0.7812\n",
      "Epoch 329/1500\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4575 - acc: 0.7726 - val_loss: 0.4973 - val_acc: 0.7812\n",
      "Epoch 330/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4573 - acc: 0.7726 - val_loss: 0.4972 - val_acc: 0.7812\n",
      "Epoch 331/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4572 - acc: 0.7726 - val_loss: 0.4971 - val_acc: 0.7812\n",
      "Epoch 332/1500\n",
      "576/576 [==============================] - 0s 189us/step - loss: 0.4570 - acc: 0.7726 - val_loss: 0.4970 - val_acc: 0.7812\n",
      "Epoch 333/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4569 - acc: 0.7726 - val_loss: 0.4969 - val_acc: 0.7812\n",
      "Epoch 334/1500\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4567 - acc: 0.7726 - val_loss: 0.4968 - val_acc: 0.7812\n",
      "Epoch 335/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4566 - acc: 0.7708 - val_loss: 0.4967 - val_acc: 0.7812\n",
      "Epoch 336/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4564 - acc: 0.7708 - val_loss: 0.4966 - val_acc: 0.7760\n",
      "Epoch 337/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4563 - acc: 0.7726 - val_loss: 0.4966 - val_acc: 0.7760\n",
      "Epoch 338/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4561 - acc: 0.7726 - val_loss: 0.4965 - val_acc: 0.7760\n",
      "Epoch 339/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4560 - acc: 0.7743 - val_loss: 0.4964 - val_acc: 0.7760\n",
      "Epoch 340/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4558 - acc: 0.7743 - val_loss: 0.4963 - val_acc: 0.7760\n",
      "Epoch 341/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4556 - acc: 0.7743 - val_loss: 0.4962 - val_acc: 0.7760\n",
      "Epoch 342/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4555 - acc: 0.7743 - val_loss: 0.4962 - val_acc: 0.7760\n",
      "Epoch 343/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4553 - acc: 0.7743 - val_loss: 0.4961 - val_acc: 0.7760\n",
      "Epoch 344/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4552 - acc: 0.7743 - val_loss: 0.4960 - val_acc: 0.7760\n",
      "Epoch 345/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4551 - acc: 0.7743 - val_loss: 0.4960 - val_acc: 0.7760\n",
      "Epoch 346/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4549 - acc: 0.7743 - val_loss: 0.4959 - val_acc: 0.7760\n",
      "Epoch 347/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4548 - acc: 0.7743 - val_loss: 0.4958 - val_acc: 0.7760\n",
      "Epoch 348/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4546 - acc: 0.7743 - val_loss: 0.4958 - val_acc: 0.7760\n",
      "Epoch 349/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4545 - acc: 0.7743 - val_loss: 0.4957 - val_acc: 0.7760\n",
      "Epoch 350/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4543 - acc: 0.7743 - val_loss: 0.4956 - val_acc: 0.7760\n",
      "Epoch 351/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4542 - acc: 0.7760 - val_loss: 0.4956 - val_acc: 0.7760\n",
      "Epoch 352/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4541 - acc: 0.7743 - val_loss: 0.4955 - val_acc: 0.7760\n",
      "Epoch 353/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4540 - acc: 0.7760 - val_loss: 0.4954 - val_acc: 0.7760\n",
      "Epoch 354/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4538 - acc: 0.7760 - val_loss: 0.4954 - val_acc: 0.7760\n",
      "Epoch 355/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4536 - acc: 0.7760 - val_loss: 0.4953 - val_acc: 0.7760\n",
      "Epoch 356/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4535 - acc: 0.7778 - val_loss: 0.4952 - val_acc: 0.7760\n",
      "Epoch 357/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4534 - acc: 0.7743 - val_loss: 0.4952 - val_acc: 0.7760\n",
      "Epoch 358/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4532 - acc: 0.7726 - val_loss: 0.4951 - val_acc: 0.7760\n",
      "Epoch 359/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4531 - acc: 0.7743 - val_loss: 0.4951 - val_acc: 0.7760\n",
      "Epoch 360/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4529 - acc: 0.7743 - val_loss: 0.4950 - val_acc: 0.7760\n",
      "Epoch 361/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4528 - acc: 0.7743 - val_loss: 0.4949 - val_acc: 0.7760\n",
      "Epoch 362/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4526 - acc: 0.7726 - val_loss: 0.4949 - val_acc: 0.7760\n",
      "Epoch 363/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4524 - acc: 0.7743 - val_loss: 0.4948 - val_acc: 0.7812\n",
      "Epoch 364/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4524 - acc: 0.7726 - val_loss: 0.4948 - val_acc: 0.7812\n",
      "Epoch 365/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4522 - acc: 0.7743 - val_loss: 0.4947 - val_acc: 0.7812\n",
      "Epoch 366/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4520 - acc: 0.7743 - val_loss: 0.4947 - val_acc: 0.7812\n",
      "Epoch 367/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4519 - acc: 0.7726 - val_loss: 0.4946 - val_acc: 0.7812\n",
      "Epoch 368/1500\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4518 - acc: 0.7708 - val_loss: 0.4946 - val_acc: 0.7812\n",
      "Epoch 369/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4516 - acc: 0.7726 - val_loss: 0.4945 - val_acc: 0.7812\n",
      "Epoch 370/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4515 - acc: 0.7726 - val_loss: 0.4945 - val_acc: 0.7812\n",
      "Epoch 371/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4513 - acc: 0.7726 - val_loss: 0.4944 - val_acc: 0.7812\n",
      "Epoch 372/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4512 - acc: 0.7726 - val_loss: 0.4944 - val_acc: 0.7812\n",
      "Epoch 373/1500\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4510 - acc: 0.7726 - val_loss: 0.4944 - val_acc: 0.7812\n",
      "Epoch 374/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4509 - acc: 0.7726 - val_loss: 0.4943 - val_acc: 0.7812\n",
      "Epoch 375/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4507 - acc: 0.7743 - val_loss: 0.4943 - val_acc: 0.7812\n",
      "Epoch 376/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4506 - acc: 0.7743 - val_loss: 0.4942 - val_acc: 0.7812\n",
      "Epoch 377/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4506 - acc: 0.7743 - val_loss: 0.4942 - val_acc: 0.7812\n",
      "Epoch 378/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4504 - acc: 0.7726 - val_loss: 0.4942 - val_acc: 0.7812\n",
      "Epoch 379/1500\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.4502 - acc: 0.7743 - val_loss: 0.4941 - val_acc: 0.7812\n",
      "Epoch 380/1500\n",
      "576/576 [==============================] - 0s 150us/step - loss: 0.4501 - acc: 0.7743 - val_loss: 0.4941 - val_acc: 0.7812\n",
      "Epoch 381/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4499 - acc: 0.7743 - val_loss: 0.4941 - val_acc: 0.7812\n",
      "Epoch 382/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4498 - acc: 0.7743 - val_loss: 0.4940 - val_acc: 0.7812\n",
      "Epoch 383/1500\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4497 - acc: 0.7743 - val_loss: 0.4940 - val_acc: 0.7812\n",
      "Epoch 384/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4495 - acc: 0.7743 - val_loss: 0.4940 - val_acc: 0.7760\n",
      "Epoch 385/1500\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4494 - acc: 0.7743 - val_loss: 0.4939 - val_acc: 0.7760\n",
      "Epoch 386/1500\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4493 - acc: 0.7778 - val_loss: 0.4939 - val_acc: 0.7812\n",
      "Epoch 387/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4491 - acc: 0.7760 - val_loss: 0.4939 - val_acc: 0.7812\n",
      "Epoch 388/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4490 - acc: 0.7760 - val_loss: 0.4938 - val_acc: 0.7812\n",
      "Epoch 389/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4489 - acc: 0.7795 - val_loss: 0.4938 - val_acc: 0.7812\n",
      "Epoch 390/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4487 - acc: 0.7778 - val_loss: 0.4937 - val_acc: 0.7812\n",
      "Epoch 391/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4486 - acc: 0.7795 - val_loss: 0.4937 - val_acc: 0.7812\n",
      "Epoch 392/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4485 - acc: 0.7795 - val_loss: 0.4937 - val_acc: 0.7812\n",
      "Epoch 393/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4483 - acc: 0.7795 - val_loss: 0.4936 - val_acc: 0.7812\n",
      "Epoch 394/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4482 - acc: 0.7795 - val_loss: 0.4936 - val_acc: 0.7812\n",
      "Epoch 395/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4481 - acc: 0.7795 - val_loss: 0.4936 - val_acc: 0.7812\n",
      "Epoch 396/1500\n",
      "576/576 [==============================] - 0s 232us/step - loss: 0.4479 - acc: 0.7812 - val_loss: 0.4936 - val_acc: 0.7812\n",
      "Epoch 397/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4478 - acc: 0.7812 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 398/1500\n",
      "576/576 [==============================] - 0s 156us/step - loss: 0.4477 - acc: 0.7812 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 399/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4476 - acc: 0.7812 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 400/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4474 - acc: 0.7812 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 401/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4473 - acc: 0.7812 - val_loss: 0.4935 - val_acc: 0.7812\n",
      "Epoch 402/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4472 - acc: 0.7812 - val_loss: 0.4934 - val_acc: 0.7812\n",
      "Epoch 403/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4471 - acc: 0.7795 - val_loss: 0.4934 - val_acc: 0.7812\n",
      "Epoch 404/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4469 - acc: 0.7795 - val_loss: 0.4933 - val_acc: 0.7812\n",
      "Epoch 405/1500\n",
      "576/576 [==============================] - 0s 152us/step - loss: 0.4468 - acc: 0.7795 - val_loss: 0.4933 - val_acc: 0.7812\n",
      "Epoch 406/1500\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4467 - acc: 0.7795 - val_loss: 0.4933 - val_acc: 0.7812\n",
      "Epoch 407/1500\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4466 - acc: 0.7795 - val_loss: 0.4932 - val_acc: 0.7812\n",
      "Epoch 408/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4464 - acc: 0.7812 - val_loss: 0.4932 - val_acc: 0.7812\n",
      "Epoch 409/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4464 - acc: 0.7812 - val_loss: 0.4932 - val_acc: 0.7812\n",
      "Epoch 410/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4462 - acc: 0.7795 - val_loss: 0.4931 - val_acc: 0.7812\n",
      "Epoch 411/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4461 - acc: 0.7795 - val_loss: 0.4931 - val_acc: 0.7812\n",
      "Epoch 412/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4460 - acc: 0.7795 - val_loss: 0.4931 - val_acc: 0.7812\n",
      "Epoch 413/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4459 - acc: 0.7795 - val_loss: 0.4930 - val_acc: 0.7812\n",
      "Epoch 414/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4458 - acc: 0.7795 - val_loss: 0.4930 - val_acc: 0.7812\n",
      "Epoch 415/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4456 - acc: 0.7795 - val_loss: 0.4930 - val_acc: 0.7812\n",
      "Epoch 416/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4455 - acc: 0.7778 - val_loss: 0.4929 - val_acc: 0.7812\n",
      "Epoch 417/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4454 - acc: 0.7795 - val_loss: 0.4929 - val_acc: 0.7812\n",
      "Epoch 418/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4453 - acc: 0.7778 - val_loss: 0.4929 - val_acc: 0.7812\n",
      "Epoch 419/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4452 - acc: 0.7778 - val_loss: 0.4928 - val_acc: 0.7812\n",
      "Epoch 420/1500\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4451 - acc: 0.7760 - val_loss: 0.4928 - val_acc: 0.7812\n",
      "Epoch 421/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4450 - acc: 0.7778 - val_loss: 0.4927 - val_acc: 0.7812\n",
      "Epoch 422/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4448 - acc: 0.7778 - val_loss: 0.4927 - val_acc: 0.7812\n",
      "Epoch 423/1500\n",
      "576/576 [==============================] - 0s 165us/step - loss: 0.4448 - acc: 0.7778 - val_loss: 0.4927 - val_acc: 0.7812\n",
      "Epoch 424/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4446 - acc: 0.7778 - val_loss: 0.4927 - val_acc: 0.7812\n",
      "Epoch 425/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4445 - acc: 0.7778 - val_loss: 0.4926 - val_acc: 0.7812\n",
      "Epoch 426/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4444 - acc: 0.7778 - val_loss: 0.4926 - val_acc: 0.7812\n",
      "Epoch 427/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4443 - acc: 0.7778 - val_loss: 0.4926 - val_acc: 0.7812\n",
      "Epoch 428/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4442 - acc: 0.7760 - val_loss: 0.4926 - val_acc: 0.7812\n",
      "Epoch 429/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4441 - acc: 0.7760 - val_loss: 0.4925 - val_acc: 0.7812\n",
      "Epoch 430/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4439 - acc: 0.7743 - val_loss: 0.4925 - val_acc: 0.7812\n",
      "Epoch 431/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4438 - acc: 0.7726 - val_loss: 0.4924 - val_acc: 0.7812\n",
      "Epoch 432/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4437 - acc: 0.7760 - val_loss: 0.4924 - val_acc: 0.7760\n",
      "Epoch 433/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4436 - acc: 0.7726 - val_loss: 0.4924 - val_acc: 0.7760\n",
      "Epoch 434/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4435 - acc: 0.7760 - val_loss: 0.4923 - val_acc: 0.7760\n",
      "Epoch 435/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4433 - acc: 0.7743 - val_loss: 0.4923 - val_acc: 0.7760\n",
      "Epoch 436/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4432 - acc: 0.7760 - val_loss: 0.4922 - val_acc: 0.7760\n",
      "Epoch 437/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4431 - acc: 0.7760 - val_loss: 0.4922 - val_acc: 0.7760\n",
      "Epoch 438/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4431 - acc: 0.7760 - val_loss: 0.4922 - val_acc: 0.7760\n",
      "Epoch 439/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4428 - acc: 0.7760 - val_loss: 0.4921 - val_acc: 0.7760\n",
      "Epoch 440/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4427 - acc: 0.7743 - val_loss: 0.4921 - val_acc: 0.7760\n",
      "Epoch 441/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4426 - acc: 0.7760 - val_loss: 0.4921 - val_acc: 0.7760\n",
      "Epoch 442/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4425 - acc: 0.7760 - val_loss: 0.4921 - val_acc: 0.7760\n",
      "Epoch 443/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4423 - acc: 0.7778 - val_loss: 0.4921 - val_acc: 0.7760\n",
      "Epoch 444/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4422 - acc: 0.7778 - val_loss: 0.4921 - val_acc: 0.7760\n",
      "Epoch 445/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4421 - acc: 0.7778 - val_loss: 0.4920 - val_acc: 0.7760\n",
      "Epoch 446/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4420 - acc: 0.7760 - val_loss: 0.4920 - val_acc: 0.7760\n",
      "Epoch 447/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4419 - acc: 0.7760 - val_loss: 0.4920 - val_acc: 0.7760\n",
      "Epoch 448/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4418 - acc: 0.7778 - val_loss: 0.4920 - val_acc: 0.7708\n",
      "Epoch 449/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4417 - acc: 0.7778 - val_loss: 0.4920 - val_acc: 0.7708\n",
      "Epoch 450/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4415 - acc: 0.7778 - val_loss: 0.4920 - val_acc: 0.7708\n",
      "Epoch 451/1500\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4413 - acc: 0.7778 - val_loss: 0.4920 - val_acc: 0.7708\n",
      "Epoch 452/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4413 - acc: 0.7760 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 453/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4411 - acc: 0.7778 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 454/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4410 - acc: 0.7778 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 455/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4409 - acc: 0.7778 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 456/1500\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.4409 - acc: 0.7760 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 457/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4407 - acc: 0.7760 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 458/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4406 - acc: 0.7760 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 459/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4405 - acc: 0.7795 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 460/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4404 - acc: 0.7778 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 461/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4403 - acc: 0.7795 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 462/1500\n",
      "576/576 [==============================] - 0s 184us/step - loss: 0.4402 - acc: 0.7795 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 463/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4401 - acc: 0.7795 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 464/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4400 - acc: 0.7795 - val_loss: 0.4919 - val_acc: 0.7708\n",
      "Epoch 465/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4399 - acc: 0.7795 - val_loss: 0.4920 - val_acc: 0.7708\n",
      "Epoch 466/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4398 - acc: 0.7795 - val_loss: 0.4920 - val_acc: 0.7708\n",
      "Epoch 467/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4397 - acc: 0.7795 - val_loss: 0.4920 - val_acc: 0.7708\n",
      "Epoch 468/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4396 - acc: 0.7795 - val_loss: 0.4920 - val_acc: 0.7708\n",
      "Epoch 469/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4395 - acc: 0.7795 - val_loss: 0.4920 - val_acc: 0.7760\n",
      "Epoch 470/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4394 - acc: 0.7812 - val_loss: 0.4920 - val_acc: 0.7760\n",
      "Epoch 471/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4393 - acc: 0.7795 - val_loss: 0.4921 - val_acc: 0.7760\n",
      "Epoch 472/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4392 - acc: 0.7812 - val_loss: 0.4921 - val_acc: 0.7760\n",
      "Epoch 473/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4390 - acc: 0.7812 - val_loss: 0.4921 - val_acc: 0.7760\n",
      "Epoch 474/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4390 - acc: 0.7812 - val_loss: 0.4921 - val_acc: 0.7760\n",
      "Epoch 475/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4389 - acc: 0.7812 - val_loss: 0.4921 - val_acc: 0.7760\n",
      "Epoch 476/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4388 - acc: 0.7795 - val_loss: 0.4922 - val_acc: 0.7812\n",
      "Epoch 477/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4387 - acc: 0.7812 - val_loss: 0.4922 - val_acc: 0.7812\n",
      "Epoch 478/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4386 - acc: 0.7795 - val_loss: 0.4922 - val_acc: 0.7812\n",
      "Epoch 479/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4385 - acc: 0.7812 - val_loss: 0.4922 - val_acc: 0.7812\n",
      "Epoch 480/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4384 - acc: 0.7812 - val_loss: 0.4922 - val_acc: 0.7812\n",
      "Epoch 481/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4383 - acc: 0.7812 - val_loss: 0.4922 - val_acc: 0.7812\n",
      "Epoch 482/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4382 - acc: 0.7812 - val_loss: 0.4922 - val_acc: 0.7812\n",
      "Epoch 483/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4381 - acc: 0.7795 - val_loss: 0.4923 - val_acc: 0.7812\n",
      "Epoch 484/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4380 - acc: 0.7795 - val_loss: 0.4923 - val_acc: 0.7812\n",
      "Epoch 485/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4380 - acc: 0.7795 - val_loss: 0.4923 - val_acc: 0.7812\n",
      "Epoch 486/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4378 - acc: 0.7795 - val_loss: 0.4923 - val_acc: 0.7812\n",
      "Epoch 487/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4378 - acc: 0.7795 - val_loss: 0.4924 - val_acc: 0.7812\n",
      "Epoch 488/1500\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4377 - acc: 0.7795 - val_loss: 0.4924 - val_acc: 0.7760\n",
      "Epoch 489/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4376 - acc: 0.7795 - val_loss: 0.4924 - val_acc: 0.7760\n",
      "Epoch 490/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4375 - acc: 0.7812 - val_loss: 0.4924 - val_acc: 0.7760\n",
      "Epoch 491/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4374 - acc: 0.7812 - val_loss: 0.4924 - val_acc: 0.7760\n",
      "Epoch 492/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4373 - acc: 0.7795 - val_loss: 0.4925 - val_acc: 0.7760\n",
      "Epoch 493/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4372 - acc: 0.7795 - val_loss: 0.4925 - val_acc: 0.7760\n",
      "Epoch 494/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4371 - acc: 0.7795 - val_loss: 0.4925 - val_acc: 0.7760\n",
      "Epoch 495/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4371 - acc: 0.7795 - val_loss: 0.4925 - val_acc: 0.7812\n",
      "Epoch 496/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4370 - acc: 0.7830 - val_loss: 0.4926 - val_acc: 0.7812\n",
      "Epoch 497/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4369 - acc: 0.7795 - val_loss: 0.4926 - val_acc: 0.7812\n",
      "Epoch 498/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4368 - acc: 0.7795 - val_loss: 0.4926 - val_acc: 0.7812\n",
      "Epoch 499/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4367 - acc: 0.7812 - val_loss: 0.4927 - val_acc: 0.7812\n",
      "Epoch 500/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4367 - acc: 0.7812 - val_loss: 0.4927 - val_acc: 0.7812\n",
      "Epoch 501/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4365 - acc: 0.7812 - val_loss: 0.4927 - val_acc: 0.7812\n",
      "Epoch 502/1500\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4364 - acc: 0.7830 - val_loss: 0.4927 - val_acc: 0.7812\n",
      "Epoch 503/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4364 - acc: 0.7830 - val_loss: 0.4928 - val_acc: 0.7760\n",
      "Epoch 504/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4363 - acc: 0.7830 - val_loss: 0.4928 - val_acc: 0.7760\n",
      "Epoch 505/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4363 - acc: 0.7812 - val_loss: 0.4928 - val_acc: 0.7760\n",
      "Epoch 506/1500\n",
      "576/576 [==============================] - 0s 165us/step - loss: 0.4362 - acc: 0.7830 - val_loss: 0.4929 - val_acc: 0.7760\n",
      "Epoch 507/1500\n",
      "576/576 [==============================] - 0s 204us/step - loss: 0.4361 - acc: 0.7830 - val_loss: 0.4929 - val_acc: 0.7760\n",
      "Epoch 508/1500\n",
      "576/576 [==============================] - 0s 243us/step - loss: 0.4360 - acc: 0.7830 - val_loss: 0.4929 - val_acc: 0.7760\n",
      "Epoch 509/1500\n",
      "576/576 [==============================] - 0s 303us/step - loss: 0.4359 - acc: 0.7847 - val_loss: 0.4930 - val_acc: 0.7760\n",
      "Epoch 510/1500\n",
      "576/576 [==============================] - 0s 274us/step - loss: 0.4358 - acc: 0.7830 - val_loss: 0.4930 - val_acc: 0.7760\n",
      "Epoch 511/1500\n",
      "576/576 [==============================] - 0s 280us/step - loss: 0.4357 - acc: 0.7830 - val_loss: 0.4931 - val_acc: 0.7760\n",
      "Epoch 512/1500\n",
      "576/576 [==============================] - 0s 249us/step - loss: 0.4357 - acc: 0.7847 - val_loss: 0.4931 - val_acc: 0.7760\n",
      "Epoch 513/1500\n",
      "576/576 [==============================] - 0s 305us/step - loss: 0.4356 - acc: 0.7830 - val_loss: 0.4932 - val_acc: 0.7760\n",
      "Epoch 514/1500\n",
      "576/576 [==============================] - 0s 284us/step - loss: 0.4355 - acc: 0.7830 - val_loss: 0.4932 - val_acc: 0.7760\n",
      "Epoch 515/1500\n",
      "576/576 [==============================] - 0s 242us/step - loss: 0.4354 - acc: 0.7847 - val_loss: 0.4933 - val_acc: 0.7760\n",
      "Epoch 516/1500\n",
      "576/576 [==============================] - 0s 252us/step - loss: 0.4353 - acc: 0.7847 - val_loss: 0.4934 - val_acc: 0.7760\n",
      "Epoch 517/1500\n",
      "576/576 [==============================] - 0s 219us/step - loss: 0.4352 - acc: 0.7847 - val_loss: 0.4934 - val_acc: 0.7760\n",
      "Epoch 518/1500\n",
      "576/576 [==============================] - 0s 272us/step - loss: 0.4351 - acc: 0.7847 - val_loss: 0.4935 - val_acc: 0.7760\n",
      "Epoch 519/1500\n",
      "576/576 [==============================] - 0s 243us/step - loss: 0.4350 - acc: 0.7847 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 520/1500\n",
      "576/576 [==============================] - 0s 272us/step - loss: 0.4349 - acc: 0.7847 - val_loss: 0.4936 - val_acc: 0.7760\n",
      "Epoch 521/1500\n",
      "576/576 [==============================] - 0s 273us/step - loss: 0.4349 - acc: 0.7847 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 522/1500\n",
      "576/576 [==============================] - 0s 277us/step - loss: 0.4348 - acc: 0.7847 - val_loss: 0.4937 - val_acc: 0.7760\n",
      "Epoch 523/1500\n",
      "576/576 [==============================] - 0s 274us/step - loss: 0.4347 - acc: 0.7847 - val_loss: 0.4938 - val_acc: 0.7760\n",
      "Epoch 524/1500\n",
      "576/576 [==============================] - 0s 273us/step - loss: 0.4347 - acc: 0.7847 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 525/1500\n",
      "576/576 [==============================] - 0s 274us/step - loss: 0.4346 - acc: 0.7847 - val_loss: 0.4939 - val_acc: 0.7708\n",
      "Epoch 526/1500\n",
      "576/576 [==============================] - 0s 247us/step - loss: 0.4344 - acc: 0.7847 - val_loss: 0.4940 - val_acc: 0.7708\n",
      "Epoch 527/1500\n",
      "576/576 [==============================] - 0s 281us/step - loss: 0.4344 - acc: 0.7847 - val_loss: 0.4941 - val_acc: 0.7708\n",
      "Epoch 528/1500\n",
      "576/576 [==============================] - 0s 278us/step - loss: 0.4343 - acc: 0.7830 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 529/1500\n",
      "576/576 [==============================] - 0s 314us/step - loss: 0.4342 - acc: 0.7847 - val_loss: 0.4942 - val_acc: 0.7708\n",
      "Epoch 530/1500\n",
      "576/576 [==============================] - 0s 274us/step - loss: 0.4341 - acc: 0.7847 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 531/1500\n",
      "576/576 [==============================] - 0s 314us/step - loss: 0.4341 - acc: 0.7865 - val_loss: 0.4943 - val_acc: 0.7708\n",
      "Epoch 532/1500\n",
      "576/576 [==============================] - 0s 241us/step - loss: 0.4339 - acc: 0.7865 - val_loss: 0.4944 - val_acc: 0.7708\n",
      "Epoch 533/1500\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4338 - acc: 0.7865 - val_loss: 0.4945 - val_acc: 0.7708\n",
      "Epoch 534/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4338 - acc: 0.7882 - val_loss: 0.4945 - val_acc: 0.7708\n",
      "Epoch 535/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4337 - acc: 0.7847 - val_loss: 0.4946 - val_acc: 0.7708\n",
      "Epoch 536/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4336 - acc: 0.7847 - val_loss: 0.4946 - val_acc: 0.7708\n",
      "Epoch 537/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4335 - acc: 0.7865 - val_loss: 0.4947 - val_acc: 0.7708\n",
      "Epoch 538/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4334 - acc: 0.7882 - val_loss: 0.4947 - val_acc: 0.7708\n",
      "Epoch 539/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4334 - acc: 0.7882 - val_loss: 0.4948 - val_acc: 0.7708\n",
      "Epoch 540/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4333 - acc: 0.7899 - val_loss: 0.4948 - val_acc: 0.7708\n",
      "Epoch 541/1500\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4332 - acc: 0.7865 - val_loss: 0.4948 - val_acc: 0.7708\n",
      "Epoch 542/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4332 - acc: 0.7899 - val_loss: 0.4949 - val_acc: 0.7708\n",
      "Epoch 543/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4330 - acc: 0.7882 - val_loss: 0.4949 - val_acc: 0.7708\n",
      "Epoch 544/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4330 - acc: 0.7882 - val_loss: 0.4950 - val_acc: 0.7708\n",
      "Epoch 545/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4329 - acc: 0.7865 - val_loss: 0.4950 - val_acc: 0.7708\n",
      "Epoch 546/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4328 - acc: 0.7899 - val_loss: 0.4951 - val_acc: 0.7708\n",
      "Epoch 547/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4328 - acc: 0.7899 - val_loss: 0.4951 - val_acc: 0.7708\n",
      "Epoch 548/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4327 - acc: 0.7882 - val_loss: 0.4951 - val_acc: 0.7708\n",
      "Epoch 549/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4327 - acc: 0.7899 - val_loss: 0.4952 - val_acc: 0.7708\n",
      "Epoch 550/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4326 - acc: 0.7882 - val_loss: 0.4952 - val_acc: 0.7708\n",
      "Epoch 551/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4325 - acc: 0.7899 - val_loss: 0.4952 - val_acc: 0.7708\n",
      "Epoch 552/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4325 - acc: 0.7899 - val_loss: 0.4952 - val_acc: 0.7708\n",
      "Epoch 553/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4324 - acc: 0.7899 - val_loss: 0.4952 - val_acc: 0.7708\n",
      "Epoch 554/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4323 - acc: 0.7899 - val_loss: 0.4953 - val_acc: 0.7708\n",
      "Epoch 555/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4322 - acc: 0.7899 - val_loss: 0.4953 - val_acc: 0.7708\n",
      "Epoch 556/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4322 - acc: 0.7899 - val_loss: 0.4953 - val_acc: 0.7708\n",
      "Epoch 557/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4322 - acc: 0.7899 - val_loss: 0.4954 - val_acc: 0.7708\n",
      "Epoch 558/1500\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4321 - acc: 0.7899 - val_loss: 0.4954 - val_acc: 0.7708\n",
      "Epoch 559/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4320 - acc: 0.7899 - val_loss: 0.4954 - val_acc: 0.7708\n",
      "Epoch 560/1500\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4320 - acc: 0.7899 - val_loss: 0.4954 - val_acc: 0.7708\n",
      "Epoch 561/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4319 - acc: 0.7917 - val_loss: 0.4954 - val_acc: 0.7708\n",
      "Epoch 562/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4319 - acc: 0.7899 - val_loss: 0.4955 - val_acc: 0.7708\n",
      "Epoch 563/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4318 - acc: 0.7917 - val_loss: 0.4955 - val_acc: 0.7708\n",
      "Epoch 564/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4318 - acc: 0.7899 - val_loss: 0.4955 - val_acc: 0.7708\n",
      "Epoch 565/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4317 - acc: 0.7917 - val_loss: 0.4956 - val_acc: 0.7708\n",
      "Epoch 566/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4316 - acc: 0.7917 - val_loss: 0.4956 - val_acc: 0.7708\n",
      "Epoch 567/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4316 - acc: 0.7917 - val_loss: 0.4956 - val_acc: 0.7708\n",
      "Epoch 568/1500\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4315 - acc: 0.7917 - val_loss: 0.4956 - val_acc: 0.7708\n",
      "Epoch 569/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4315 - acc: 0.7917 - val_loss: 0.4956 - val_acc: 0.7708\n",
      "Epoch 570/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4314 - acc: 0.7934 - val_loss: 0.4957 - val_acc: 0.7708\n",
      "Epoch 571/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4313 - acc: 0.7934 - val_loss: 0.4957 - val_acc: 0.7708\n",
      "Epoch 572/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4313 - acc: 0.7917 - val_loss: 0.4957 - val_acc: 0.7708\n",
      "Epoch 573/1500\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4313 - acc: 0.7934 - val_loss: 0.4957 - val_acc: 0.7708\n",
      "Epoch 574/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4312 - acc: 0.7917 - val_loss: 0.4957 - val_acc: 0.7708\n",
      "Epoch 575/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4311 - acc: 0.7917 - val_loss: 0.4957 - val_acc: 0.7708\n",
      "Epoch 576/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4311 - acc: 0.7934 - val_loss: 0.4958 - val_acc: 0.7708\n",
      "Epoch 577/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4310 - acc: 0.7934 - val_loss: 0.4958 - val_acc: 0.7708\n",
      "Epoch 578/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4309 - acc: 0.7934 - val_loss: 0.4958 - val_acc: 0.7708\n",
      "Epoch 579/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4309 - acc: 0.7934 - val_loss: 0.4959 - val_acc: 0.7708\n",
      "Epoch 580/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4309 - acc: 0.7934 - val_loss: 0.4959 - val_acc: 0.7708\n",
      "Epoch 581/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4307 - acc: 0.7934 - val_loss: 0.4959 - val_acc: 0.7708\n",
      "Epoch 582/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4307 - acc: 0.7934 - val_loss: 0.4959 - val_acc: 0.7708\n",
      "Epoch 583/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4307 - acc: 0.7934 - val_loss: 0.4960 - val_acc: 0.7708\n",
      "Epoch 584/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4306 - acc: 0.7951 - val_loss: 0.4960 - val_acc: 0.7708\n",
      "Epoch 585/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4305 - acc: 0.7951 - val_loss: 0.4960 - val_acc: 0.7708\n",
      "Epoch 586/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4305 - acc: 0.7951 - val_loss: 0.4960 - val_acc: 0.7708\n",
      "Epoch 587/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4304 - acc: 0.7951 - val_loss: 0.4961 - val_acc: 0.7708\n",
      "Epoch 588/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4303 - acc: 0.7951 - val_loss: 0.4961 - val_acc: 0.7708\n",
      "Epoch 589/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4302 - acc: 0.7951 - val_loss: 0.4961 - val_acc: 0.7708\n",
      "Epoch 590/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4302 - acc: 0.7951 - val_loss: 0.4961 - val_acc: 0.7656\n",
      "Epoch 591/1500\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4302 - acc: 0.7951 - val_loss: 0.4961 - val_acc: 0.7656\n",
      "Epoch 592/1500\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4301 - acc: 0.7951 - val_loss: 0.4962 - val_acc: 0.7656\n",
      "Epoch 593/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4300 - acc: 0.7951 - val_loss: 0.4962 - val_acc: 0.7656\n",
      "Epoch 594/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4300 - acc: 0.7951 - val_loss: 0.4962 - val_acc: 0.7656\n",
      "Epoch 595/1500\n",
      "576/576 [==============================] - 0s 211us/step - loss: 0.4299 - acc: 0.7951 - val_loss: 0.4963 - val_acc: 0.7656\n",
      "Epoch 596/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4299 - acc: 0.7951 - val_loss: 0.4963 - val_acc: 0.7656\n",
      "Epoch 597/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4298 - acc: 0.7951 - val_loss: 0.4963 - val_acc: 0.7656\n",
      "Epoch 598/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4297 - acc: 0.7951 - val_loss: 0.4964 - val_acc: 0.7656\n",
      "Epoch 599/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4297 - acc: 0.7951 - val_loss: 0.4964 - val_acc: 0.7656\n",
      "Epoch 600/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4296 - acc: 0.7969 - val_loss: 0.4965 - val_acc: 0.7656\n",
      "Epoch 601/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4296 - acc: 0.7951 - val_loss: 0.4965 - val_acc: 0.7656\n",
      "Epoch 602/1500\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4295 - acc: 0.7969 - val_loss: 0.4965 - val_acc: 0.7656\n",
      "Epoch 603/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4294 - acc: 0.7951 - val_loss: 0.4966 - val_acc: 0.7656\n",
      "Epoch 604/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4294 - acc: 0.7951 - val_loss: 0.4966 - val_acc: 0.7656\n",
      "Epoch 605/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4293 - acc: 0.7951 - val_loss: 0.4967 - val_acc: 0.7656\n",
      "Epoch 606/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4293 - acc: 0.7969 - val_loss: 0.4967 - val_acc: 0.7656\n",
      "Epoch 607/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4292 - acc: 0.7969 - val_loss: 0.4967 - val_acc: 0.7656\n",
      "Epoch 608/1500\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4292 - acc: 0.7969 - val_loss: 0.4968 - val_acc: 0.7656\n",
      "Epoch 609/1500\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.4292 - acc: 0.7969 - val_loss: 0.4968 - val_acc: 0.7656\n",
      "Epoch 610/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4291 - acc: 0.7986 - val_loss: 0.4969 - val_acc: 0.7656\n",
      "Epoch 611/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4290 - acc: 0.7969 - val_loss: 0.4969 - val_acc: 0.7656\n",
      "Epoch 612/1500\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4290 - acc: 0.7969 - val_loss: 0.4970 - val_acc: 0.7656\n",
      "Epoch 613/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4289 - acc: 0.7986 - val_loss: 0.4970 - val_acc: 0.7656\n",
      "Epoch 614/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4290 - acc: 0.7986 - val_loss: 0.4971 - val_acc: 0.7656\n",
      "Epoch 615/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4288 - acc: 0.7986 - val_loss: 0.4971 - val_acc: 0.7656\n",
      "Epoch 616/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4288 - acc: 0.7986 - val_loss: 0.4972 - val_acc: 0.7656\n",
      "Epoch 617/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4287 - acc: 0.7986 - val_loss: 0.4972 - val_acc: 0.7656\n",
      "Epoch 618/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4288 - acc: 0.7986 - val_loss: 0.4972 - val_acc: 0.7656\n",
      "Epoch 619/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4286 - acc: 0.7986 - val_loss: 0.4973 - val_acc: 0.7656\n",
      "Epoch 620/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4286 - acc: 0.7986 - val_loss: 0.4973 - val_acc: 0.7656\n",
      "Epoch 621/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4285 - acc: 0.7986 - val_loss: 0.4973 - val_acc: 0.7656\n",
      "Epoch 622/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4285 - acc: 0.7986 - val_loss: 0.4974 - val_acc: 0.7656\n",
      "Epoch 623/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4284 - acc: 0.7986 - val_loss: 0.4974 - val_acc: 0.7604\n",
      "Epoch 624/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4284 - acc: 0.7986 - val_loss: 0.4974 - val_acc: 0.7604\n",
      "Epoch 625/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4283 - acc: 0.7986 - val_loss: 0.4975 - val_acc: 0.7604\n",
      "Epoch 626/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4283 - acc: 0.7986 - val_loss: 0.4975 - val_acc: 0.7604\n",
      "Epoch 627/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4283 - acc: 0.8003 - val_loss: 0.4976 - val_acc: 0.7604\n",
      "Epoch 628/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4282 - acc: 0.7969 - val_loss: 0.4976 - val_acc: 0.7604\n",
      "Epoch 629/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4282 - acc: 0.7986 - val_loss: 0.4976 - val_acc: 0.7604\n",
      "Epoch 630/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4282 - acc: 0.7986 - val_loss: 0.4977 - val_acc: 0.7604\n",
      "Epoch 631/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4280 - acc: 0.7986 - val_loss: 0.4977 - val_acc: 0.7604\n",
      "Epoch 632/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4281 - acc: 0.7969 - val_loss: 0.4977 - val_acc: 0.7604\n",
      "Epoch 633/1500\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4280 - acc: 0.7986 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 634/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4279 - acc: 0.7986 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 635/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4279 - acc: 0.7986 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 636/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4279 - acc: 0.7986 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 637/1500\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4278 - acc: 0.7986 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 638/1500\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4277 - acc: 0.7986 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 639/1500\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4277 - acc: 0.7986 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 640/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4276 - acc: 0.7986 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 641/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4276 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 642/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4276 - acc: 0.7969 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 643/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4276 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 644/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4275 - acc: 0.7986 - val_loss: 0.4982 - val_acc: 0.7604\n",
      "Epoch 645/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4275 - acc: 0.7986 - val_loss: 0.4982 - val_acc: 0.7604\n",
      "Epoch 646/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4274 - acc: 0.7986 - val_loss: 0.4982 - val_acc: 0.7604\n",
      "Epoch 647/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4273 - acc: 0.7986 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 648/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4273 - acc: 0.7986 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 649/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4273 - acc: 0.7986 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 650/1500\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4273 - acc: 0.8003 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 651/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4272 - acc: 0.7969 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 652/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4272 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 653/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4271 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 654/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4270 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 655/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4271 - acc: 0.7969 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 656/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4269 - acc: 0.8003 - val_loss: 0.4985 - val_acc: 0.7604\n",
      "Epoch 657/1500\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4269 - acc: 0.7986 - val_loss: 0.4985 - val_acc: 0.7604\n",
      "Epoch 658/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4269 - acc: 0.7969 - val_loss: 0.4985 - val_acc: 0.7552\n",
      "Epoch 659/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4268 - acc: 0.7986 - val_loss: 0.4985 - val_acc: 0.7552\n",
      "Epoch 660/1500\n",
      "576/576 [==============================] - 0s 206us/step - loss: 0.4268 - acc: 0.7986 - val_loss: 0.4986 - val_acc: 0.7552\n",
      "Epoch 661/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4267 - acc: 0.7986 - val_loss: 0.4986 - val_acc: 0.7552\n",
      "Epoch 662/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4267 - acc: 0.7951 - val_loss: 0.4986 - val_acc: 0.7552\n",
      "Epoch 663/1500\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4267 - acc: 0.7986 - val_loss: 0.4986 - val_acc: 0.7552\n",
      "Epoch 664/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4266 - acc: 0.7986 - val_loss: 0.4986 - val_acc: 0.7552\n",
      "Epoch 665/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4265 - acc: 0.7986 - val_loss: 0.4987 - val_acc: 0.7552\n",
      "Epoch 666/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4265 - acc: 0.7969 - val_loss: 0.4987 - val_acc: 0.7552\n",
      "Epoch 667/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4265 - acc: 0.7986 - val_loss: 0.4987 - val_acc: 0.7552\n",
      "Epoch 668/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4264 - acc: 0.7969 - val_loss: 0.4988 - val_acc: 0.7552\n",
      "Epoch 669/1500\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4264 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7552\n",
      "Epoch 670/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4263 - acc: 0.7969 - val_loss: 0.4988 - val_acc: 0.7552\n",
      "Epoch 671/1500\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4262 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7552\n",
      "Epoch 672/1500\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4262 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7552\n",
      "Epoch 673/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4262 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7552\n",
      "Epoch 674/1500\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4261 - acc: 0.8003 - val_loss: 0.4989 - val_acc: 0.7552\n",
      "Epoch 675/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4261 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7552\n",
      "Epoch 676/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4261 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7552\n",
      "Epoch 677/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4260 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7552\n",
      "Epoch 678/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4260 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7552\n",
      "Epoch 679/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4259 - acc: 0.7969 - val_loss: 0.4990 - val_acc: 0.7552\n",
      "Epoch 680/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4259 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7552\n",
      "Epoch 681/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4259 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7552\n",
      "Epoch 682/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4258 - acc: 0.7969 - val_loss: 0.4990 - val_acc: 0.7552\n",
      "Epoch 683/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4258 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7552\n",
      "Epoch 684/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4257 - acc: 0.7969 - val_loss: 0.4991 - val_acc: 0.7552\n",
      "Epoch 685/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4257 - acc: 0.7951 - val_loss: 0.4991 - val_acc: 0.7552\n",
      "Epoch 686/1500\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4257 - acc: 0.7986 - val_loss: 0.4991 - val_acc: 0.7552\n",
      "Epoch 687/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4256 - acc: 0.7969 - val_loss: 0.4991 - val_acc: 0.7552\n",
      "Epoch 688/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4256 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7552\n",
      "Epoch 689/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4256 - acc: 0.7969 - val_loss: 0.4992 - val_acc: 0.7552\n",
      "Epoch 690/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4255 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7552\n",
      "Epoch 691/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4254 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7552\n",
      "Epoch 692/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4255 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7552\n",
      "Epoch 693/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4254 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7552\n",
      "Epoch 694/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4253 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7552\n",
      "Epoch 695/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4254 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7552\n",
      "Epoch 696/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4253 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7552\n",
      "Epoch 697/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4252 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7552\n",
      "Epoch 698/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4252 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7552\n",
      "Epoch 699/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4251 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7552\n",
      "Epoch 700/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4251 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7552\n",
      "Epoch 701/1500\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4251 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7552\n",
      "Epoch 702/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4250 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7552\n",
      "Epoch 703/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4250 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7552\n",
      "Epoch 704/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4250 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7552\n",
      "Epoch 705/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4249 - acc: 0.8003 - val_loss: 0.4994 - val_acc: 0.7552\n",
      "Epoch 706/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4249 - acc: 0.7986 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 707/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4248 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 708/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4248 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 709/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4248 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 710/1500\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4247 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 711/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4247 - acc: 0.7986 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 712/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4247 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 713/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4246 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 714/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4246 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 715/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4246 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 716/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4245 - acc: 0.8021 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 717/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4245 - acc: 0.8021 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 718/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4244 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 719/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4244 - acc: 0.8021 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 720/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4244 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7552\n",
      "Epoch 721/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4244 - acc: 0.8021 - val_loss: 0.4996 - val_acc: 0.7552\n",
      "Epoch 722/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4243 - acc: 0.8021 - val_loss: 0.4996 - val_acc: 0.7552\n",
      "Epoch 723/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4242 - acc: 0.8021 - val_loss: 0.4996 - val_acc: 0.7552\n",
      "Epoch 724/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4242 - acc: 0.8021 - val_loss: 0.4996 - val_acc: 0.7552\n",
      "Epoch 725/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4241 - acc: 0.8021 - val_loss: 0.4996 - val_acc: 0.7552\n",
      "Epoch 726/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4241 - acc: 0.8021 - val_loss: 0.4996 - val_acc: 0.7552\n",
      "Epoch 727/1500\n",
      "576/576 [==============================] - 0s 169us/step - loss: 0.4241 - acc: 0.8021 - val_loss: 0.4996 - val_acc: 0.7552\n",
      "Epoch 728/1500\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4241 - acc: 0.8021 - val_loss: 0.4996 - val_acc: 0.7552\n",
      "Epoch 729/1500\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4240 - acc: 0.8021 - val_loss: 0.4996 - val_acc: 0.7552\n",
      "Epoch 730/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4240 - acc: 0.8021 - val_loss: 0.4996 - val_acc: 0.7552\n",
      "Epoch 731/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4240 - acc: 0.8021 - val_loss: 0.4997 - val_acc: 0.7552\n",
      "Epoch 732/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4239 - acc: 0.8003 - val_loss: 0.4997 - val_acc: 0.7552\n",
      "Epoch 733/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4239 - acc: 0.8021 - val_loss: 0.4997 - val_acc: 0.7552\n",
      "Epoch 734/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4239 - acc: 0.8021 - val_loss: 0.4997 - val_acc: 0.7552\n",
      "Epoch 735/1500\n",
      "576/576 [==============================] - 0s 162us/step - loss: 0.4238 - acc: 0.8021 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 736/1500\n",
      "576/576 [==============================] - 0s 178us/step - loss: 0.4238 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 737/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4238 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 738/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4237 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 739/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4236 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 740/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4236 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 741/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4236 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 742/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4236 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 743/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4236 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 744/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4235 - acc: 0.8021 - val_loss: 0.4999 - val_acc: 0.7604\n",
      "Epoch 745/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4235 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 746/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4234 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 747/1500\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4234 - acc: 0.8021 - val_loss: 0.4999 - val_acc: 0.7604\n",
      "Epoch 748/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4234 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 749/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4234 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 750/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4234 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 751/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4233 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 752/1500\n",
      "576/576 [==============================] - 0s 159us/step - loss: 0.4233 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 753/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4232 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 754/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4232 - acc: 0.8021 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 755/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4232 - acc: 0.8021 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 756/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4232 - acc: 0.8021 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 757/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4231 - acc: 0.8021 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 758/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4231 - acc: 0.8021 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 759/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4231 - acc: 0.8021 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 760/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4230 - acc: 0.8003 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 761/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4230 - acc: 0.8021 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 762/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4230 - acc: 0.8003 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 763/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4229 - acc: 0.8003 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 764/1500\n",
      "576/576 [==============================] - 0s 162us/step - loss: 0.4228 - acc: 0.8003 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 765/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4229 - acc: 0.7986 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 766/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4229 - acc: 0.8003 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 767/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4228 - acc: 0.7986 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 768/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4228 - acc: 0.8003 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 769/1500\n",
      "576/576 [==============================] - 0s 169us/step - loss: 0.4228 - acc: 0.8003 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 770/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4228 - acc: 0.7986 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 771/1500\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4227 - acc: 0.7986 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 772/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4226 - acc: 0.7986 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 773/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4226 - acc: 0.7986 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 774/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4226 - acc: 0.7986 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 775/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4227 - acc: 0.7986 - val_loss: 0.4995 - val_acc: 0.7604\n",
      "Epoch 776/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4226 - acc: 0.7986 - val_loss: 0.4995 - val_acc: 0.7604\n",
      "Epoch 777/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4225 - acc: 0.7986 - val_loss: 0.4995 - val_acc: 0.7604\n",
      "Epoch 778/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4224 - acc: 0.7986 - val_loss: 0.4995 - val_acc: 0.7604\n",
      "Epoch 779/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4225 - acc: 0.7986 - val_loss: 0.4995 - val_acc: 0.7604\n",
      "Epoch 780/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4224 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7604\n",
      "Epoch 781/1500\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4225 - acc: 0.7986 - val_loss: 0.4995 - val_acc: 0.7604\n",
      "Epoch 782/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4224 - acc: 0.7986 - val_loss: 0.4995 - val_acc: 0.7604\n",
      "Epoch 783/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4224 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 784/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4224 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 785/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4223 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 786/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4222 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 787/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4222 - acc: 0.8003 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 788/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4222 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 789/1500\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4221 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 790/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4222 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 791/1500\n",
      "576/576 [==============================] - 0s 218us/step - loss: 0.4221 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 792/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4221 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 793/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4222 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 794/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4220 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 795/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4220 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 796/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4220 - acc: 0.8003 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 797/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4220 - acc: 0.7986 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 798/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4219 - acc: 0.8003 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 799/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4219 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7604\n",
      "Epoch 800/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4219 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7604\n",
      "Epoch 801/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4218 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7604\n",
      "Epoch 802/1500\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4218 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7604\n",
      "Epoch 803/1500\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4218 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7604\n",
      "Epoch 804/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4217 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7604\n",
      "Epoch 805/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4218 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7604\n",
      "Epoch 806/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4217 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 807/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4217 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 808/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4217 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 809/1500\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4216 - acc: 0.8003 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 810/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4216 - acc: 0.8003 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 811/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4216 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 812/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4215 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 813/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4215 - acc: 0.7986 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 814/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4215 - acc: 0.8003 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 815/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4214 - acc: 0.7969 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 816/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4214 - acc: 0.8003 - val_loss: 0.4991 - val_acc: 0.7604\n",
      "Epoch 817/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4214 - acc: 0.7969 - val_loss: 0.4991 - val_acc: 0.7604\n",
      "Epoch 818/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4214 - acc: 0.8003 - val_loss: 0.4991 - val_acc: 0.7604\n",
      "Epoch 819/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4213 - acc: 0.8003 - val_loss: 0.4991 - val_acc: 0.7604\n",
      "Epoch 820/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4213 - acc: 0.7986 - val_loss: 0.4991 - val_acc: 0.7604\n",
      "Epoch 821/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4213 - acc: 0.8003 - val_loss: 0.4991 - val_acc: 0.7604\n",
      "Epoch 822/1500\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4213 - acc: 0.7986 - val_loss: 0.4991 - val_acc: 0.7604\n",
      "Epoch 823/1500\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4213 - acc: 0.7986 - val_loss: 0.4991 - val_acc: 0.7604\n",
      "Epoch 824/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4212 - acc: 0.7986 - val_loss: 0.4991 - val_acc: 0.7604\n",
      "Epoch 825/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4211 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7604\n",
      "Epoch 826/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4211 - acc: 0.7969 - val_loss: 0.4990 - val_acc: 0.7604\n",
      "Epoch 827/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4211 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7604\n",
      "Epoch 828/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4210 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7604\n",
      "Epoch 829/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4212 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7604\n",
      "Epoch 830/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4211 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7604\n",
      "Epoch 831/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4210 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7604\n",
      "Epoch 832/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4210 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7604\n",
      "Epoch 833/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4210 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7604\n",
      "Epoch 834/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4209 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 835/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4209 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 836/1500\n",
      "576/576 [==============================] - 0s 150us/step - loss: 0.4209 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 837/1500\n",
      "576/576 [==============================] - 0s 162us/step - loss: 0.4209 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 838/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4208 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 839/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4207 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 840/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4207 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 841/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4207 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 842/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4207 - acc: 0.7969 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 843/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4207 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 844/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4207 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 845/1500\n",
      "576/576 [==============================] - 0s 165us/step - loss: 0.4206 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 846/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4206 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 847/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4205 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 848/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4205 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 849/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4206 - acc: 0.7986 - val_loss: 0.4987 - val_acc: 0.7656\n",
      "Epoch 850/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4205 - acc: 0.7986 - val_loss: 0.4987 - val_acc: 0.7656\n",
      "Epoch 851/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4205 - acc: 0.7986 - val_loss: 0.4987 - val_acc: 0.7604\n",
      "Epoch 852/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4204 - acc: 0.7986 - val_loss: 0.4987 - val_acc: 0.7604\n",
      "Epoch 853/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4204 - acc: 0.7986 - val_loss: 0.4987 - val_acc: 0.7604\n",
      "Epoch 854/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4204 - acc: 0.7986 - val_loss: 0.4987 - val_acc: 0.7604\n",
      "Epoch 855/1500\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4203 - acc: 0.7986 - val_loss: 0.4986 - val_acc: 0.7604\n",
      "Epoch 856/1500\n",
      "576/576 [==============================] - 0s 174us/step - loss: 0.4203 - acc: 0.7986 - val_loss: 0.4986 - val_acc: 0.7604\n",
      "Epoch 857/1500\n",
      "576/576 [==============================] - 0s 246us/step - loss: 0.4202 - acc: 0.7986 - val_loss: 0.4986 - val_acc: 0.7604\n",
      "Epoch 858/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4202 - acc: 0.7986 - val_loss: 0.4986 - val_acc: 0.7604\n",
      "Epoch 859/1500\n",
      "576/576 [==============================] - 0s 180us/step - loss: 0.4202 - acc: 0.7986 - val_loss: 0.4986 - val_acc: 0.7604\n",
      "Epoch 860/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4202 - acc: 0.7986 - val_loss: 0.4986 - val_acc: 0.7604\n",
      "Epoch 861/1500\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.4201 - acc: 0.7986 - val_loss: 0.4986 - val_acc: 0.7604\n",
      "Epoch 862/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4201 - acc: 0.7986 - val_loss: 0.4985 - val_acc: 0.7604\n",
      "Epoch 863/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4200 - acc: 0.7986 - val_loss: 0.4985 - val_acc: 0.7604\n",
      "Epoch 864/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4201 - acc: 0.7986 - val_loss: 0.4985 - val_acc: 0.7604\n",
      "Epoch 865/1500\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4200 - acc: 0.7986 - val_loss: 0.4985 - val_acc: 0.7604\n",
      "Epoch 866/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4200 - acc: 0.7986 - val_loss: 0.4985 - val_acc: 0.7604\n",
      "Epoch 867/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4200 - acc: 0.7986 - val_loss: 0.4985 - val_acc: 0.7604\n",
      "Epoch 868/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4199 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 869/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4199 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 870/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4199 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 871/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4198 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 872/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4198 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 873/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4198 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 874/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4197 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 875/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4197 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 876/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4197 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 877/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4197 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 878/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4196 - acc: 0.7986 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 879/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4196 - acc: 0.7986 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 880/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4196 - acc: 0.7986 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 881/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4195 - acc: 0.7986 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 882/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4195 - acc: 0.7986 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 883/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4195 - acc: 0.7986 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 884/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4195 - acc: 0.7986 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 885/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4194 - acc: 0.7986 - val_loss: 0.4982 - val_acc: 0.7604\n",
      "Epoch 886/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4194 - acc: 0.7986 - val_loss: 0.4982 - val_acc: 0.7604\n",
      "Epoch 887/1500\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4194 - acc: 0.7986 - val_loss: 0.4982 - val_acc: 0.7604\n",
      "Epoch 888/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4193 - acc: 0.7986 - val_loss: 0.4982 - val_acc: 0.7604\n",
      "Epoch 889/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4194 - acc: 0.7986 - val_loss: 0.4982 - val_acc: 0.7604\n",
      "Epoch 890/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4193 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 891/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4192 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 892/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4192 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 893/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4192 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 894/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4192 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 895/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4191 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 896/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4191 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 897/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4191 - acc: 0.8003 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 898/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4190 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 899/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4190 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 900/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4189 - acc: 0.7969 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 901/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4189 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 902/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4189 - acc: 0.7969 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 903/1500\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4189 - acc: 0.8003 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 904/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4189 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 905/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4189 - acc: 0.8003 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 906/1500\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4188 - acc: 0.8003 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 907/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4188 - acc: 0.8003 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 908/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4187 - acc: 0.8003 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 909/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4187 - acc: 0.8003 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 910/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4187 - acc: 0.8003 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 911/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4187 - acc: 0.8003 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 912/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4186 - acc: 0.8003 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 913/1500\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4186 - acc: 0.8003 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 914/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4185 - acc: 0.8003 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 915/1500\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4185 - acc: 0.8003 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 916/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4185 - acc: 0.8003 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 917/1500\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4185 - acc: 0.8003 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 918/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4184 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 919/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4184 - acc: 0.7986 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 920/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4184 - acc: 0.7986 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 921/1500\n",
      "576/576 [==============================] - 0s 203us/step - loss: 0.4184 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 922/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4183 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 923/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4183 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 924/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4183 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 925/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4183 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 926/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4182 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 927/1500\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4182 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 928/1500\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4182 - acc: 0.8021 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 929/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4181 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 930/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4182 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 931/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4181 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 932/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4181 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 933/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4180 - acc: 0.8021 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 934/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4180 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 935/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4180 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 936/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4179 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 937/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4179 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 938/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4179 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 939/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4178 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 940/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4178 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 941/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4178 - acc: 0.8021 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 942/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4178 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 943/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4178 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 944/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4177 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 945/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4177 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 946/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4177 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 947/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4177 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 948/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4176 - acc: 0.7986 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 949/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4176 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 950/1500\n",
      "576/576 [==============================] - 0s 163us/step - loss: 0.4176 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 951/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4176 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 952/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4175 - acc: 0.8021 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 953/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4176 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 954/1500\n",
      "576/576 [==============================] - 0s 153us/step - loss: 0.4175 - acc: 0.7986 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 955/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4175 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 956/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4174 - acc: 0.8021 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 957/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4174 - acc: 0.8021 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 958/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4175 - acc: 0.7986 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 959/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4174 - acc: 0.8021 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 960/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4173 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 961/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4173 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 962/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4172 - acc: 0.8003 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 963/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4173 - acc: 0.7986 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 964/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4172 - acc: 0.7986 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 965/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4172 - acc: 0.8021 - val_loss: 0.4978 - val_acc: 0.7604\n",
      "Epoch 966/1500\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4172 - acc: 0.8021 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 967/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4172 - acc: 0.8021 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 968/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4171 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 969/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4171 - acc: 0.8003 - val_loss: 0.4979 - val_acc: 0.7604\n",
      "Epoch 970/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4170 - acc: 0.8003 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 971/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4171 - acc: 0.8003 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 972/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4170 - acc: 0.8021 - val_loss: 0.4980 - val_acc: 0.7604\n",
      "Epoch 973/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4170 - acc: 0.8003 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 974/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4170 - acc: 0.8003 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 975/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4169 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 976/1500\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4169 - acc: 0.7986 - val_loss: 0.4981 - val_acc: 0.7604\n",
      "Epoch 977/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4169 - acc: 0.8021 - val_loss: 0.4982 - val_acc: 0.7604\n",
      "Epoch 978/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4168 - acc: 0.7986 - val_loss: 0.4982 - val_acc: 0.7604\n",
      "Epoch 979/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4169 - acc: 0.8003 - val_loss: 0.4982 - val_acc: 0.7604\n",
      "Epoch 980/1500\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4168 - acc: 0.8021 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 981/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4168 - acc: 0.8003 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 982/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4168 - acc: 0.7986 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 983/1500\n",
      "576/576 [==============================] - 0s 105us/step - loss: 0.4168 - acc: 0.8003 - val_loss: 0.4983 - val_acc: 0.7604\n",
      "Epoch 984/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4167 - acc: 0.8003 - val_loss: 0.4984 - val_acc: 0.7604\n",
      "Epoch 985/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4167 - acc: 0.8003 - val_loss: 0.4985 - val_acc: 0.7604\n",
      "Epoch 986/1500\n",
      "576/576 [==============================] - 0s 211us/step - loss: 0.4166 - acc: 0.8003 - val_loss: 0.4985 - val_acc: 0.7604\n",
      "Epoch 987/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4166 - acc: 0.8021 - val_loss: 0.4986 - val_acc: 0.7604\n",
      "Epoch 988/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4166 - acc: 0.8003 - val_loss: 0.4986 - val_acc: 0.7604\n",
      "Epoch 989/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4165 - acc: 0.8003 - val_loss: 0.4987 - val_acc: 0.7604\n",
      "Epoch 990/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4165 - acc: 0.8003 - val_loss: 0.4988 - val_acc: 0.7604\n",
      "Epoch 991/1500\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4165 - acc: 0.7986 - val_loss: 0.4988 - val_acc: 0.7604\n",
      "Epoch 992/1500\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4165 - acc: 0.7986 - val_loss: 0.4989 - val_acc: 0.7604\n",
      "Epoch 993/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4164 - acc: 0.8003 - val_loss: 0.4989 - val_acc: 0.7604\n",
      "Epoch 994/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4164 - acc: 0.8003 - val_loss: 0.4990 - val_acc: 0.7604\n",
      "Epoch 995/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4164 - acc: 0.7986 - val_loss: 0.4990 - val_acc: 0.7604\n",
      "Epoch 996/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4165 - acc: 0.8003 - val_loss: 0.4991 - val_acc: 0.7604\n",
      "Epoch 997/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4163 - acc: 0.7986 - val_loss: 0.4991 - val_acc: 0.7604\n",
      "Epoch 998/1500\n",
      "576/576 [==============================] - 0s 156us/step - loss: 0.4163 - acc: 0.8021 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 999/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4163 - acc: 0.8003 - val_loss: 0.4992 - val_acc: 0.7604\n",
      "Epoch 1000/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4163 - acc: 0.8021 - val_loss: 0.4993 - val_acc: 0.7604\n",
      "Epoch 1001/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4162 - acc: 0.8003 - val_loss: 0.4993 - val_acc: 0.7604\n",
      "Epoch 1002/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4162 - acc: 0.8021 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 1003/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4161 - acc: 0.8003 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 1004/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4161 - acc: 0.8003 - val_loss: 0.4994 - val_acc: 0.7604\n",
      "Epoch 1005/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4161 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7604\n",
      "Epoch 1006/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4161 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7604\n",
      "Epoch 1007/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4161 - acc: 0.8003 - val_loss: 0.4995 - val_acc: 0.7604\n",
      "Epoch 1008/1500\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4161 - acc: 0.8003 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 1009/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4161 - acc: 0.8003 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 1010/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4160 - acc: 0.8021 - val_loss: 0.4996 - val_acc: 0.7604\n",
      "Epoch 1011/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4160 - acc: 0.8003 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 1012/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4159 - acc: 0.8003 - val_loss: 0.4997 - val_acc: 0.7604\n",
      "Epoch 1013/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4159 - acc: 0.8003 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 1014/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4159 - acc: 0.8003 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 1015/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4158 - acc: 0.8021 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 1016/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4159 - acc: 0.8003 - val_loss: 0.4998 - val_acc: 0.7604\n",
      "Epoch 1017/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4158 - acc: 0.8003 - val_loss: 0.4999 - val_acc: 0.7604\n",
      "Epoch 1018/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4158 - acc: 0.8003 - val_loss: 0.4999 - val_acc: 0.7604\n",
      "Epoch 1019/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4158 - acc: 0.8003 - val_loss: 0.4999 - val_acc: 0.7604\n",
      "Epoch 1020/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4157 - acc: 0.8003 - val_loss: 0.5000 - val_acc: 0.7604\n",
      "Epoch 1021/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4158 - acc: 0.8003 - val_loss: 0.5000 - val_acc: 0.7604\n",
      "Epoch 1022/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4157 - acc: 0.8003 - val_loss: 0.5000 - val_acc: 0.7604\n",
      "Epoch 1023/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4157 - acc: 0.7986 - val_loss: 0.5001 - val_acc: 0.7604\n",
      "Epoch 1024/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4156 - acc: 0.8003 - val_loss: 0.5001 - val_acc: 0.7604\n",
      "Epoch 1025/1500\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4156 - acc: 0.8003 - val_loss: 0.5001 - val_acc: 0.7604\n",
      "Epoch 1026/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4156 - acc: 0.8003 - val_loss: 0.5001 - val_acc: 0.7604\n",
      "Epoch 1027/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4156 - acc: 0.7986 - val_loss: 0.5001 - val_acc: 0.7604\n",
      "Epoch 1028/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4156 - acc: 0.7986 - val_loss: 0.5001 - val_acc: 0.7604\n",
      "Epoch 1029/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4155 - acc: 0.8003 - val_loss: 0.5002 - val_acc: 0.7604\n",
      "Epoch 1030/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4155 - acc: 0.7986 - val_loss: 0.5002 - val_acc: 0.7604\n",
      "Epoch 1031/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4155 - acc: 0.7986 - val_loss: 0.5002 - val_acc: 0.7604\n",
      "Epoch 1032/1500\n",
      "576/576 [==============================] - 0s 107us/step - loss: 0.4154 - acc: 0.7986 - val_loss: 0.5002 - val_acc: 0.7604\n",
      "Epoch 1033/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4155 - acc: 0.7986 - val_loss: 0.5002 - val_acc: 0.7604\n",
      "Epoch 1034/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4154 - acc: 0.7986 - val_loss: 0.5002 - val_acc: 0.7604\n",
      "Epoch 1035/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4154 - acc: 0.7986 - val_loss: 0.5003 - val_acc: 0.7604\n",
      "Epoch 1036/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4153 - acc: 0.7986 - val_loss: 0.5003 - val_acc: 0.7604\n",
      "Epoch 1037/1500\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4153 - acc: 0.8003 - val_loss: 0.5003 - val_acc: 0.7604\n",
      "Epoch 1038/1500\n",
      "576/576 [==============================] - 0s 165us/step - loss: 0.4153 - acc: 0.7986 - val_loss: 0.5003 - val_acc: 0.7604\n",
      "Epoch 1039/1500\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4153 - acc: 0.8003 - val_loss: 0.5004 - val_acc: 0.7604\n",
      "Epoch 1040/1500\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4153 - acc: 0.7986 - val_loss: 0.5004 - val_acc: 0.7604\n",
      "Epoch 1041/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4153 - acc: 0.7986 - val_loss: 0.5004 - val_acc: 0.7604\n",
      "Epoch 1042/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4152 - acc: 0.8003 - val_loss: 0.5004 - val_acc: 0.7604\n",
      "Epoch 1043/1500\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4152 - acc: 0.8003 - val_loss: 0.5005 - val_acc: 0.7604\n",
      "Epoch 1044/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4152 - acc: 0.7986 - val_loss: 0.5005 - val_acc: 0.7604\n",
      "Epoch 1045/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4152 - acc: 0.7986 - val_loss: 0.5005 - val_acc: 0.7604\n",
      "Epoch 1046/1500\n",
      "576/576 [==============================] - 0s 126us/step - loss: 0.4151 - acc: 0.7986 - val_loss: 0.5006 - val_acc: 0.7604\n",
      "Epoch 1047/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4151 - acc: 0.7986 - val_loss: 0.5006 - val_acc: 0.7604\n",
      "Epoch 1048/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4150 - acc: 0.7986 - val_loss: 0.5006 - val_acc: 0.7604\n",
      "Epoch 1049/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4151 - acc: 0.7986 - val_loss: 0.5006 - val_acc: 0.7604\n",
      "Epoch 1050/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4150 - acc: 0.8003 - val_loss: 0.5006 - val_acc: 0.7604\n",
      "Epoch 1051/1500\n",
      "576/576 [==============================] - 0s 175us/step - loss: 0.4150 - acc: 0.7986 - val_loss: 0.5006 - val_acc: 0.7604\n",
      "Epoch 1052/1500\n",
      "576/576 [==============================] - 0s 167us/step - loss: 0.4149 - acc: 0.7986 - val_loss: 0.5006 - val_acc: 0.7604\n",
      "Epoch 1053/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4150 - acc: 0.8003 - val_loss: 0.5006 - val_acc: 0.7604\n",
      "Epoch 1054/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4150 - acc: 0.7986 - val_loss: 0.5006 - val_acc: 0.7604\n",
      "Epoch 1055/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4149 - acc: 0.7986 - val_loss: 0.5006 - val_acc: 0.7604\n",
      "Epoch 1056/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4149 - acc: 0.8003 - val_loss: 0.5007 - val_acc: 0.7604\n",
      "Epoch 1057/1500\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4149 - acc: 0.7986 - val_loss: 0.5007 - val_acc: 0.7604\n",
      "Epoch 1058/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4149 - acc: 0.7986 - val_loss: 0.5007 - val_acc: 0.7604\n",
      "Epoch 1059/1500\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.4149 - acc: 0.7986 - val_loss: 0.5007 - val_acc: 0.7604\n",
      "Epoch 1060/1500\n",
      "576/576 [==============================] - 0s 174us/step - loss: 0.4149 - acc: 0.7986 - val_loss: 0.5007 - val_acc: 0.7604\n",
      "Epoch 1061/1500\n",
      "576/576 [==============================] - 0s 183us/step - loss: 0.4149 - acc: 0.7986 - val_loss: 0.5007 - val_acc: 0.7604\n",
      "Epoch 1062/1500\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4148 - acc: 0.7986 - val_loss: 0.5007 - val_acc: 0.7604\n",
      "Epoch 1063/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4147 - acc: 0.7986 - val_loss: 0.5008 - val_acc: 0.7604\n",
      "Epoch 1064/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4148 - acc: 0.7986 - val_loss: 0.5008 - val_acc: 0.7604\n",
      "Epoch 1065/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4147 - acc: 0.7986 - val_loss: 0.5008 - val_acc: 0.7604\n",
      "Epoch 1066/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4147 - acc: 0.7986 - val_loss: 0.5008 - val_acc: 0.7604\n",
      "Epoch 1067/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4147 - acc: 0.8003 - val_loss: 0.5009 - val_acc: 0.7604\n",
      "Epoch 1068/1500\n",
      "576/576 [==============================] - 0s 214us/step - loss: 0.4147 - acc: 0.7986 - val_loss: 0.5009 - val_acc: 0.7604\n",
      "Epoch 1069/1500\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4147 - acc: 0.7986 - val_loss: 0.5009 - val_acc: 0.7604\n",
      "Epoch 1070/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4146 - acc: 0.8003 - val_loss: 0.5010 - val_acc: 0.7604\n",
      "Epoch 1071/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4146 - acc: 0.7986 - val_loss: 0.5010 - val_acc: 0.7604\n",
      "Epoch 1072/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4146 - acc: 0.7986 - val_loss: 0.5010 - val_acc: 0.7604\n",
      "Epoch 1073/1500\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4145 - acc: 0.8003 - val_loss: 0.5010 - val_acc: 0.7604\n",
      "Epoch 1074/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4145 - acc: 0.7986 - val_loss: 0.5010 - val_acc: 0.7604\n",
      "Epoch 1075/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4145 - acc: 0.7986 - val_loss: 0.5011 - val_acc: 0.7604\n",
      "Epoch 1076/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4145 - acc: 0.7986 - val_loss: 0.5011 - val_acc: 0.7604\n",
      "Epoch 1077/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4145 - acc: 0.7986 - val_loss: 0.5011 - val_acc: 0.7552\n",
      "Epoch 1078/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4145 - acc: 0.7986 - val_loss: 0.5011 - val_acc: 0.7552\n",
      "Epoch 1079/1500\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4145 - acc: 0.7986 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 1080/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4144 - acc: 0.7986 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 1081/1500\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4144 - acc: 0.7986 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 1082/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4144 - acc: 0.7986 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 1083/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4144 - acc: 0.7986 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 1084/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4143 - acc: 0.7986 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 1085/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4143 - acc: 0.7986 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 1086/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4143 - acc: 0.7986 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 1087/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4143 - acc: 0.7986 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 1088/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4142 - acc: 0.7986 - val_loss: 0.5013 - val_acc: 0.7552\n",
      "Epoch 1089/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4142 - acc: 0.7986 - val_loss: 0.5014 - val_acc: 0.7552\n",
      "Epoch 1090/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4143 - acc: 0.7986 - val_loss: 0.5014 - val_acc: 0.7552\n",
      "Epoch 1091/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4142 - acc: 0.7986 - val_loss: 0.5014 - val_acc: 0.7552\n",
      "Epoch 1092/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4142 - acc: 0.7986 - val_loss: 0.5014 - val_acc: 0.7552\n",
      "Epoch 1093/1500\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4142 - acc: 0.7986 - val_loss: 0.5014 - val_acc: 0.7552\n",
      "Epoch 1094/1500\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4141 - acc: 0.7986 - val_loss: 0.5015 - val_acc: 0.7552\n",
      "Epoch 1095/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4141 - acc: 0.7986 - val_loss: 0.5015 - val_acc: 0.7552\n",
      "Epoch 1096/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4141 - acc: 0.7986 - val_loss: 0.5015 - val_acc: 0.7552\n",
      "Epoch 1097/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4140 - acc: 0.7986 - val_loss: 0.5015 - val_acc: 0.7552\n",
      "Epoch 1098/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4140 - acc: 0.7986 - val_loss: 0.5015 - val_acc: 0.7552\n",
      "Epoch 1099/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4140 - acc: 0.7986 - val_loss: 0.5016 - val_acc: 0.7552\n",
      "Epoch 1100/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4141 - acc: 0.7986 - val_loss: 0.5016 - val_acc: 0.7552\n",
      "Epoch 1101/1500\n",
      "576/576 [==============================] - 0s 151us/step - loss: 0.4140 - acc: 0.7986 - val_loss: 0.5016 - val_acc: 0.7552\n",
      "Epoch 1102/1500\n",
      "576/576 [==============================] - 0s 154us/step - loss: 0.4140 - acc: 0.7986 - val_loss: 0.5017 - val_acc: 0.7552\n",
      "Epoch 1103/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4139 - acc: 0.7986 - val_loss: 0.5017 - val_acc: 0.7552\n",
      "Epoch 1104/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4139 - acc: 0.7986 - val_loss: 0.5017 - val_acc: 0.7552\n",
      "Epoch 1105/1500\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4138 - acc: 0.7986 - val_loss: 0.5018 - val_acc: 0.7552\n",
      "Epoch 1106/1500\n",
      "576/576 [==============================] - 0s 109us/step - loss: 0.4138 - acc: 0.7986 - val_loss: 0.5018 - val_acc: 0.7552\n",
      "Epoch 1107/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4138 - acc: 0.7986 - val_loss: 0.5018 - val_acc: 0.7552\n",
      "Epoch 1108/1500\n",
      "576/576 [==============================] - 0s 157us/step - loss: 0.4138 - acc: 0.7986 - val_loss: 0.5018 - val_acc: 0.7552\n",
      "Epoch 1109/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4138 - acc: 0.7986 - val_loss: 0.5018 - val_acc: 0.7552\n",
      "Epoch 1110/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4137 - acc: 0.7986 - val_loss: 0.5019 - val_acc: 0.7552\n",
      "Epoch 1111/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4138 - acc: 0.7986 - val_loss: 0.5019 - val_acc: 0.7552\n",
      "Epoch 1112/1500\n",
      "576/576 [==============================] - 0s 165us/step - loss: 0.4137 - acc: 0.7986 - val_loss: 0.5019 - val_acc: 0.7552\n",
      "Epoch 1113/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4137 - acc: 0.7986 - val_loss: 0.5019 - val_acc: 0.7552\n",
      "Epoch 1114/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4136 - acc: 0.7986 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 1115/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4136 - acc: 0.7986 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 1116/1500\n",
      "576/576 [==============================] - 0s 220us/step - loss: 0.4136 - acc: 0.7986 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 1117/1500\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.4136 - acc: 0.7986 - val_loss: 0.5021 - val_acc: 0.7552\n",
      "Epoch 1118/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4136 - acc: 0.7986 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 1119/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4136 - acc: 0.7986 - val_loss: 0.5020 - val_acc: 0.7552\n",
      "Epoch 1120/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4136 - acc: 0.7986 - val_loss: 0.5021 - val_acc: 0.7552\n",
      "Epoch 1121/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4135 - acc: 0.7986 - val_loss: 0.5021 - val_acc: 0.7552\n",
      "Epoch 1122/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4135 - acc: 0.7986 - val_loss: 0.5021 - val_acc: 0.7552\n",
      "Epoch 1123/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4135 - acc: 0.7986 - val_loss: 0.5022 - val_acc: 0.7552\n",
      "Epoch 1124/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4134 - acc: 0.7986 - val_loss: 0.5022 - val_acc: 0.7552\n",
      "Epoch 1125/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4134 - acc: 0.7986 - val_loss: 0.5022 - val_acc: 0.7552\n",
      "Epoch 1126/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4134 - acc: 0.7986 - val_loss: 0.5022 - val_acc: 0.7552\n",
      "Epoch 1127/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4134 - acc: 0.7986 - val_loss: 0.5022 - val_acc: 0.7552\n",
      "Epoch 1128/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4133 - acc: 0.7986 - val_loss: 0.5023 - val_acc: 0.7552\n",
      "Epoch 1129/1500\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4133 - acc: 0.7986 - val_loss: 0.5023 - val_acc: 0.7552\n",
      "Epoch 1130/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4133 - acc: 0.7986 - val_loss: 0.5023 - val_acc: 0.7552\n",
      "Epoch 1131/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4133 - acc: 0.7986 - val_loss: 0.5023 - val_acc: 0.7552\n",
      "Epoch 1132/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4133 - acc: 0.7986 - val_loss: 0.5023 - val_acc: 0.7552\n",
      "Epoch 1133/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4133 - acc: 0.7986 - val_loss: 0.5024 - val_acc: 0.7552\n",
      "Epoch 1134/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4133 - acc: 0.7986 - val_loss: 0.5024 - val_acc: 0.7552\n",
      "Epoch 1135/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4132 - acc: 0.7986 - val_loss: 0.5024 - val_acc: 0.7552\n",
      "Epoch 1136/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4132 - acc: 0.7986 - val_loss: 0.5024 - val_acc: 0.7552\n",
      "Epoch 1137/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4132 - acc: 0.7986 - val_loss: 0.5024 - val_acc: 0.7552\n",
      "Epoch 1138/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4132 - acc: 0.8003 - val_loss: 0.5025 - val_acc: 0.7552\n",
      "Epoch 1139/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4131 - acc: 0.7986 - val_loss: 0.5025 - val_acc: 0.7552\n",
      "Epoch 1140/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4131 - acc: 0.7986 - val_loss: 0.5025 - val_acc: 0.7552\n",
      "Epoch 1141/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4131 - acc: 0.7986 - val_loss: 0.5025 - val_acc: 0.7552\n",
      "Epoch 1142/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4131 - acc: 0.8003 - val_loss: 0.5025 - val_acc: 0.7552\n",
      "Epoch 1143/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4131 - acc: 0.7986 - val_loss: 0.5026 - val_acc: 0.7552\n",
      "Epoch 1144/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4131 - acc: 0.7986 - val_loss: 0.5026 - val_acc: 0.7552\n",
      "Epoch 1145/1500\n",
      "576/576 [==============================] - 0s 162us/step - loss: 0.4130 - acc: 0.8003 - val_loss: 0.5026 - val_acc: 0.7552\n",
      "Epoch 1146/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4130 - acc: 0.7986 - val_loss: 0.5026 - val_acc: 0.7552\n",
      "Epoch 1147/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4130 - acc: 0.7986 - val_loss: 0.5026 - val_acc: 0.7552\n",
      "Epoch 1148/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4129 - acc: 0.8003 - val_loss: 0.5026 - val_acc: 0.7552\n",
      "Epoch 1149/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4129 - acc: 0.7986 - val_loss: 0.5027 - val_acc: 0.7552\n",
      "Epoch 1150/1500\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4130 - acc: 0.7986 - val_loss: 0.5027 - val_acc: 0.7552\n",
      "Epoch 1151/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4129 - acc: 0.8003 - val_loss: 0.5027 - val_acc: 0.7552\n",
      "Epoch 1152/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4129 - acc: 0.8003 - val_loss: 0.5027 - val_acc: 0.7552\n",
      "Epoch 1153/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4129 - acc: 0.8003 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 1154/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4129 - acc: 0.8003 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 1155/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4128 - acc: 0.8003 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 1156/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4128 - acc: 0.8003 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 1157/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4128 - acc: 0.8003 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 1158/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4127 - acc: 0.8003 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 1159/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4128 - acc: 0.7986 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 1160/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4127 - acc: 0.8003 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 1161/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4127 - acc: 0.8003 - val_loss: 0.5028 - val_acc: 0.7552\n",
      "Epoch 1162/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4127 - acc: 0.8003 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 1163/1500\n",
      "576/576 [==============================] - 0s 150us/step - loss: 0.4126 - acc: 0.8003 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 1164/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4126 - acc: 0.8003 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 1165/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4126 - acc: 0.8003 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 1166/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4126 - acc: 0.8003 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 1167/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4126 - acc: 0.8003 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 1168/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4126 - acc: 0.8003 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 1169/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4125 - acc: 0.8003 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 1170/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4126 - acc: 0.8003 - val_loss: 0.5029 - val_acc: 0.7552\n",
      "Epoch 1171/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4126 - acc: 0.8003 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1172/1500\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.4125 - acc: 0.8003 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1173/1500\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4124 - acc: 0.8003 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1174/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4124 - acc: 0.8003 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1175/1500\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4124 - acc: 0.8003 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1176/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4124 - acc: 0.7986 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1177/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4124 - acc: 0.8003 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1178/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4124 - acc: 0.7986 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1179/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4123 - acc: 0.8003 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1180/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4124 - acc: 0.8003 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1181/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4123 - acc: 0.7986 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1182/1500\n",
      "576/576 [==============================] - 0s 195us/step - loss: 0.4123 - acc: 0.8003 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1183/1500\n",
      "576/576 [==============================] - 0s 153us/step - loss: 0.4123 - acc: 0.8003 - val_loss: 0.5030 - val_acc: 0.7552\n",
      "Epoch 1184/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4123 - acc: 0.7986 - val_loss: 0.5031 - val_acc: 0.7552\n",
      "Epoch 1185/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4122 - acc: 0.7986 - val_loss: 0.5031 - val_acc: 0.7552\n",
      "Epoch 1186/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4122 - acc: 0.8003 - val_loss: 0.5031 - val_acc: 0.7552\n",
      "Epoch 1187/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4122 - acc: 0.8003 - val_loss: 0.5031 - val_acc: 0.7552\n",
      "Epoch 1188/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4122 - acc: 0.8003 - val_loss: 0.5031 - val_acc: 0.7552\n",
      "Epoch 1189/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4122 - acc: 0.8003 - val_loss: 0.5031 - val_acc: 0.7552\n",
      "Epoch 1190/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4121 - acc: 0.7986 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1191/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4121 - acc: 0.8003 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1192/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4121 - acc: 0.7986 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1193/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4121 - acc: 0.8003 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1194/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4120 - acc: 0.7986 - val_loss: 0.5032 - val_acc: 0.7552\n",
      "Epoch 1195/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4120 - acc: 0.8003 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1196/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4120 - acc: 0.7969 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1197/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4120 - acc: 0.7986 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1198/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4120 - acc: 0.7969 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1199/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4120 - acc: 0.8003 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1200/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4120 - acc: 0.8003 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1201/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4120 - acc: 0.7986 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1202/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4120 - acc: 0.7969 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1203/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4119 - acc: 0.8003 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1204/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4120 - acc: 0.7986 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1205/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4119 - acc: 0.7986 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1206/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4118 - acc: 0.7969 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1207/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4118 - acc: 0.7986 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1208/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4119 - acc: 0.7986 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1209/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4118 - acc: 0.7986 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1210/1500\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4117 - acc: 0.7969 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1211/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4118 - acc: 0.7986 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1212/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4117 - acc: 0.7969 - val_loss: 0.5033 - val_acc: 0.7552\n",
      "Epoch 1213/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4117 - acc: 0.7969 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1214/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4117 - acc: 0.7986 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1215/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4117 - acc: 0.7969 - val_loss: 0.5034 - val_acc: 0.7552\n",
      "Epoch 1216/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4117 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1217/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4117 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1218/1500\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4116 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1219/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4117 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1220/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4116 - acc: 0.7986 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1221/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4115 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1222/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4115 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1223/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4115 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1224/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4116 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1225/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4115 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1226/1500\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.4115 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1227/1500\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4115 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1228/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4115 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1229/1500\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4114 - acc: 0.7969 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1230/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4115 - acc: 0.7969 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1231/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4114 - acc: 0.7969 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1232/1500\n",
      "576/576 [==============================] - 0s 106us/step - loss: 0.4114 - acc: 0.7969 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1233/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4114 - acc: 0.7969 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1234/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4113 - acc: 0.7986 - val_loss: 0.5035 - val_acc: 0.7552\n",
      "Epoch 1235/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4114 - acc: 0.7969 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1236/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4114 - acc: 0.7969 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1237/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4113 - acc: 0.7969 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1238/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4113 - acc: 0.7969 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1239/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4113 - acc: 0.7969 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1240/1500\n",
      "576/576 [==============================] - 0s 173us/step - loss: 0.4113 - acc: 0.7969 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1241/1500\n",
      "576/576 [==============================] - 0s 171us/step - loss: 0.4113 - acc: 0.7969 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1242/1500\n",
      "576/576 [==============================] - 0s 166us/step - loss: 0.4112 - acc: 0.7969 - val_loss: 0.5036 - val_acc: 0.7552\n",
      "Epoch 1243/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4112 - acc: 0.7969 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1244/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4112 - acc: 0.7969 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1245/1500\n",
      "576/576 [==============================] - 0s 149us/step - loss: 0.4112 - acc: 0.7969 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1246/1500\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4111 - acc: 0.7969 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1247/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4111 - acc: 0.7969 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1248/1500\n",
      "576/576 [==============================] - 0s 146us/step - loss: 0.4111 - acc: 0.7969 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1249/1500\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.4111 - acc: 0.7969 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1250/1500\n",
      "576/576 [==============================] - 0s 161us/step - loss: 0.4111 - acc: 0.7969 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1251/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4111 - acc: 0.7969 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1252/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4111 - acc: 0.7969 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1253/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4111 - acc: 0.7969 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1254/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4110 - acc: 0.7969 - val_loss: 0.5037 - val_acc: 0.7552\n",
      "Epoch 1255/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4110 - acc: 0.7969 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1256/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4110 - acc: 0.7969 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1257/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4110 - acc: 0.7969 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1258/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4111 - acc: 0.7969 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1259/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4110 - acc: 0.7969 - val_loss: 0.5038 - val_acc: 0.7552\n",
      "Epoch 1260/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4110 - acc: 0.7969 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1261/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4110 - acc: 0.7969 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1262/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4109 - acc: 0.7969 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1263/1500\n",
      "576/576 [==============================] - 0s 147us/step - loss: 0.4109 - acc: 0.7969 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1264/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4109 - acc: 0.7969 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1265/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4109 - acc: 0.7969 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1266/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4109 - acc: 0.7951 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1267/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4109 - acc: 0.7969 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1268/1500\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4109 - acc: 0.7969 - val_loss: 0.5039 - val_acc: 0.7552\n",
      "Epoch 1269/1500\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4108 - acc: 0.7951 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1270/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4108 - acc: 0.7969 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1271/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4108 - acc: 0.7969 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1272/1500\n",
      "576/576 [==============================] - 0s 160us/step - loss: 0.4109 - acc: 0.7951 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1273/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4107 - acc: 0.7969 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1274/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4108 - acc: 0.7951 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1275/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4107 - acc: 0.7951 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 1276/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4107 - acc: 0.7969 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1277/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4107 - acc: 0.7969 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1278/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4107 - acc: 0.7951 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1279/1500\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.4107 - acc: 0.7951 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1280/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4107 - acc: 0.7951 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1281/1500\n",
      "576/576 [==============================] - 0s 145us/step - loss: 0.4107 - acc: 0.7969 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1282/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4107 - acc: 0.7951 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1283/1500\n",
      "576/576 [==============================] - 0s 211us/step - loss: 0.4107 - acc: 0.7951 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1284/1500\n",
      "576/576 [==============================] - 0s 271us/step - loss: 0.4106 - acc: 0.7951 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 1285/1500\n",
      "576/576 [==============================] - 0s 284us/step - loss: 0.4106 - acc: 0.7951 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1286/1500\n",
      "576/576 [==============================] - 0s 245us/step - loss: 0.4106 - acc: 0.7951 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1287/1500\n",
      "576/576 [==============================] - 0s 282us/step - loss: 0.4105 - acc: 0.7951 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1288/1500\n",
      "576/576 [==============================] - 0s 244us/step - loss: 0.4106 - acc: 0.7951 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1289/1500\n",
      "576/576 [==============================] - 0s 318us/step - loss: 0.4105 - acc: 0.7951 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1290/1500\n",
      "576/576 [==============================] - 0s 273us/step - loss: 0.4106 - acc: 0.7951 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1291/1500\n",
      "576/576 [==============================] - 0s 316us/step - loss: 0.4105 - acc: 0.7951 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1292/1500\n",
      "576/576 [==============================] - 0s 238us/step - loss: 0.4105 - acc: 0.7951 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1293/1500\n",
      "576/576 [==============================] - 0s 237us/step - loss: 0.4105 - acc: 0.7969 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1294/1500\n",
      "576/576 [==============================] - 0s 247us/step - loss: 0.4105 - acc: 0.7951 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1295/1500\n",
      "576/576 [==============================] - 0s 271us/step - loss: 0.4104 - acc: 0.7951 - val_loss: 0.5042 - val_acc: 0.7552\n",
      "Epoch 1296/1500\n",
      "576/576 [==============================] - 0s 340us/step - loss: 0.4104 - acc: 0.7969 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1297/1500\n",
      "576/576 [==============================] - 0s 279us/step - loss: 0.4104 - acc: 0.7951 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1298/1500\n",
      "576/576 [==============================] - 0s 315us/step - loss: 0.4103 - acc: 0.7951 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1299/1500\n",
      "576/576 [==============================] - 0s 285us/step - loss: 0.4104 - acc: 0.7951 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1300/1500\n",
      "576/576 [==============================] - 0s 272us/step - loss: 0.4103 - acc: 0.7951 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1301/1500\n",
      "576/576 [==============================] - 0s 278us/step - loss: 0.4103 - acc: 0.7969 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1302/1500\n",
      "576/576 [==============================] - 0s 278us/step - loss: 0.4103 - acc: 0.7969 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1303/1500\n",
      "576/576 [==============================] - 0s 250us/step - loss: 0.4103 - acc: 0.7969 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1304/1500\n",
      "576/576 [==============================] - 0s 240us/step - loss: 0.4103 - acc: 0.7969 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1305/1500\n",
      "576/576 [==============================] - 0s 210us/step - loss: 0.4102 - acc: 0.7969 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1306/1500\n",
      "576/576 [==============================] - 0s 309us/step - loss: 0.4102 - acc: 0.7951 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1307/1500\n",
      "576/576 [==============================] - 0s 276us/step - loss: 0.4103 - acc: 0.7969 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1308/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4102 - acc: 0.7969 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1309/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4102 - acc: 0.7951 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1310/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4101 - acc: 0.7969 - val_loss: 0.5043 - val_acc: 0.7552\n",
      "Epoch 1311/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4102 - acc: 0.7969 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1312/1500\n",
      "576/576 [==============================] - 0s 122us/step - loss: 0.4101 - acc: 0.7969 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1313/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4102 - acc: 0.7969 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1314/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4101 - acc: 0.7969 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1315/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4101 - acc: 0.7969 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1316/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4101 - acc: 0.7969 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1317/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4101 - acc: 0.7969 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1318/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4101 - acc: 0.7969 - val_loss: 0.5044 - val_acc: 0.7552\n",
      "Epoch 1319/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4101 - acc: 0.7969 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1320/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4101 - acc: 0.7986 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1321/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4101 - acc: 0.7969 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1322/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4100 - acc: 0.7969 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1323/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4100 - acc: 0.7969 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1324/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4100 - acc: 0.7969 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1325/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4099 - acc: 0.7969 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1326/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4099 - acc: 0.7969 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1327/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4099 - acc: 0.8003 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1328/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4100 - acc: 0.7986 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1329/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4099 - acc: 0.7969 - val_loss: 0.5045 - val_acc: 0.7552\n",
      "Epoch 1330/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4099 - acc: 0.7969 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1331/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4099 - acc: 0.7969 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1332/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4099 - acc: 0.7986 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1333/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4098 - acc: 0.7986 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1334/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4099 - acc: 0.7986 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1335/1500\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4099 - acc: 0.7969 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1336/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4098 - acc: 0.7986 - val_loss: 0.5046 - val_acc: 0.7552\n",
      "Epoch 1337/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4098 - acc: 0.7986 - val_loss: 0.5047 - val_acc: 0.7552\n",
      "Epoch 1338/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4098 - acc: 0.7986 - val_loss: 0.5047 - val_acc: 0.7552\n",
      "Epoch 1339/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4098 - acc: 0.7986 - val_loss: 0.5047 - val_acc: 0.7552\n",
      "Epoch 1340/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4097 - acc: 0.7969 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1341/1500\n",
      "576/576 [==============================] - 0s 158us/step - loss: 0.4097 - acc: 0.7986 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1342/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4098 - acc: 0.7986 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1343/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4098 - acc: 0.7986 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1344/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4097 - acc: 0.7986 - val_loss: 0.5047 - val_acc: 0.7552\n",
      "Epoch 1345/1500\n",
      "576/576 [==============================] - 0s 179us/step - loss: 0.4097 - acc: 0.7969 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1346/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4097 - acc: 0.7986 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1347/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4096 - acc: 0.7986 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1348/1500\n",
      "576/576 [==============================] - 0s 124us/step - loss: 0.4096 - acc: 0.7986 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1349/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4097 - acc: 0.7986 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1350/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4096 - acc: 0.7986 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1351/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4096 - acc: 0.7986 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 1352/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4096 - acc: 0.7986 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1353/1500\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4095 - acc: 0.7986 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1354/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4096 - acc: 0.8003 - val_loss: 0.5049 - val_acc: 0.7552\n",
      "Epoch 1355/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4096 - acc: 0.7986 - val_loss: 0.5050 - val_acc: 0.7552\n",
      "Epoch 1356/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4096 - acc: 0.8003 - val_loss: 0.5050 - val_acc: 0.7552\n",
      "Epoch 1357/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4095 - acc: 0.8003 - val_loss: 0.5050 - val_acc: 0.7552\n",
      "Epoch 1358/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4095 - acc: 0.8003 - val_loss: 0.5050 - val_acc: 0.7552\n",
      "Epoch 1359/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4094 - acc: 0.8003 - val_loss: 0.5051 - val_acc: 0.7552\n",
      "Epoch 1360/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4095 - acc: 0.7986 - val_loss: 0.5051 - val_acc: 0.7552\n",
      "Epoch 1361/1500\n",
      "576/576 [==============================] - 0s 120us/step - loss: 0.4094 - acc: 0.7986 - val_loss: 0.5051 - val_acc: 0.7552\n",
      "Epoch 1362/1500\n",
      "576/576 [==============================] - 0s 156us/step - loss: 0.4094 - acc: 0.7986 - val_loss: 0.5051 - val_acc: 0.7552\n",
      "Epoch 1363/1500\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4094 - acc: 0.7986 - val_loss: 0.5051 - val_acc: 0.7552\n",
      "Epoch 1364/1500\n",
      "576/576 [==============================] - 0s 114us/step - loss: 0.4095 - acc: 0.7969 - val_loss: 0.5052 - val_acc: 0.7552\n",
      "Epoch 1365/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4094 - acc: 0.7969 - val_loss: 0.5052 - val_acc: 0.7552\n",
      "Epoch 1366/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4093 - acc: 0.7969 - val_loss: 0.5052 - val_acc: 0.7552\n",
      "Epoch 1367/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4093 - acc: 0.7986 - val_loss: 0.5052 - val_acc: 0.7552\n",
      "Epoch 1368/1500\n",
      "576/576 [==============================] - 0s 228us/step - loss: 0.4093 - acc: 0.7986 - val_loss: 0.5052 - val_acc: 0.7552\n",
      "Epoch 1369/1500\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4093 - acc: 0.7969 - val_loss: 0.5052 - val_acc: 0.7552\n",
      "Epoch 1370/1500\n",
      "576/576 [==============================] - 0s 168us/step - loss: 0.4093 - acc: 0.7986 - val_loss: 0.5052 - val_acc: 0.7552\n",
      "Epoch 1371/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4093 - acc: 0.8021 - val_loss: 0.5053 - val_acc: 0.7552\n",
      "Epoch 1372/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4092 - acc: 0.7986 - val_loss: 0.5053 - val_acc: 0.7552\n",
      "Epoch 1373/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4093 - acc: 0.7969 - val_loss: 0.5053 - val_acc: 0.7552\n",
      "Epoch 1374/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4092 - acc: 0.7986 - val_loss: 0.5053 - val_acc: 0.7552\n",
      "Epoch 1375/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4092 - acc: 0.7969 - val_loss: 0.5053 - val_acc: 0.7552\n",
      "Epoch 1376/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4093 - acc: 0.8003 - val_loss: 0.5053 - val_acc: 0.7552\n",
      "Epoch 1377/1500\n",
      "576/576 [==============================] - 0s 131us/step - loss: 0.4092 - acc: 0.7986 - val_loss: 0.5054 - val_acc: 0.7552\n",
      "Epoch 1378/1500\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4092 - acc: 0.7969 - val_loss: 0.5054 - val_acc: 0.7552\n",
      "Epoch 1379/1500\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4092 - acc: 0.7969 - val_loss: 0.5054 - val_acc: 0.7552\n",
      "Epoch 1380/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4092 - acc: 0.7969 - val_loss: 0.5054 - val_acc: 0.7552\n",
      "Epoch 1381/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4092 - acc: 0.7969 - val_loss: 0.5054 - val_acc: 0.7552\n",
      "Epoch 1382/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4091 - acc: 0.7986 - val_loss: 0.5054 - val_acc: 0.7552\n",
      "Epoch 1383/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4091 - acc: 0.7969 - val_loss: 0.5055 - val_acc: 0.7552\n",
      "Epoch 1384/1500\n",
      "576/576 [==============================] - 0s 119us/step - loss: 0.4091 - acc: 0.7969 - val_loss: 0.5055 - val_acc: 0.7552\n",
      "Epoch 1385/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4091 - acc: 0.7951 - val_loss: 0.5055 - val_acc: 0.7552\n",
      "Epoch 1386/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4091 - acc: 0.7986 - val_loss: 0.5055 - val_acc: 0.7552\n",
      "Epoch 1387/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4090 - acc: 0.7986 - val_loss: 0.5056 - val_acc: 0.7552\n",
      "Epoch 1388/1500\n",
      "576/576 [==============================] - 0s 170us/step - loss: 0.4090 - acc: 0.7969 - val_loss: 0.5056 - val_acc: 0.7552\n",
      "Epoch 1389/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4090 - acc: 0.7986 - val_loss: 0.5056 - val_acc: 0.7552\n",
      "Epoch 1390/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4090 - acc: 0.7986 - val_loss: 0.5057 - val_acc: 0.7552\n",
      "Epoch 1391/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4091 - acc: 0.7951 - val_loss: 0.5057 - val_acc: 0.7552\n",
      "Epoch 1392/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4090 - acc: 0.7969 - val_loss: 0.5057 - val_acc: 0.7552\n",
      "Epoch 1393/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4089 - acc: 0.7951 - val_loss: 0.5057 - val_acc: 0.7552\n",
      "Epoch 1394/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4089 - acc: 0.7951 - val_loss: 0.5057 - val_acc: 0.7552\n",
      "Epoch 1395/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4089 - acc: 0.7969 - val_loss: 0.5058 - val_acc: 0.7552\n",
      "Epoch 1396/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4089 - acc: 0.7951 - val_loss: 0.5058 - val_acc: 0.7552\n",
      "Epoch 1397/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4089 - acc: 0.7969 - val_loss: 0.5058 - val_acc: 0.7552\n",
      "Epoch 1398/1500\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4089 - acc: 0.7951 - val_loss: 0.5058 - val_acc: 0.7552\n",
      "Epoch 1399/1500\n",
      "576/576 [==============================] - 0s 128us/step - loss: 0.4089 - acc: 0.7969 - val_loss: 0.5058 - val_acc: 0.7552\n",
      "Epoch 1400/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4088 - acc: 0.7986 - val_loss: 0.5059 - val_acc: 0.7552\n",
      "Epoch 1401/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4089 - acc: 0.7969 - val_loss: 0.5059 - val_acc: 0.7552\n",
      "Epoch 1402/1500\n",
      "576/576 [==============================] - 0s 127us/step - loss: 0.4089 - acc: 0.7969 - val_loss: 0.5060 - val_acc: 0.7552\n",
      "Epoch 1403/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4088 - acc: 0.7969 - val_loss: 0.5060 - val_acc: 0.7552\n",
      "Epoch 1404/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4089 - acc: 0.7951 - val_loss: 0.5059 - val_acc: 0.7552\n",
      "Epoch 1405/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4088 - acc: 0.8003 - val_loss: 0.5059 - val_acc: 0.7552\n",
      "Epoch 1406/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4088 - acc: 0.7969 - val_loss: 0.5060 - val_acc: 0.7552\n",
      "Epoch 1407/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4087 - acc: 0.7951 - val_loss: 0.5060 - val_acc: 0.7552\n",
      "Epoch 1408/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4087 - acc: 0.7969 - val_loss: 0.5060 - val_acc: 0.7552\n",
      "Epoch 1409/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4087 - acc: 0.7969 - val_loss: 0.5061 - val_acc: 0.7552\n",
      "Epoch 1410/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4088 - acc: 0.7969 - val_loss: 0.5061 - val_acc: 0.7552\n",
      "Epoch 1411/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4087 - acc: 0.7969 - val_loss: 0.5061 - val_acc: 0.7552\n",
      "Epoch 1412/1500\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.4087 - acc: 0.7969 - val_loss: 0.5062 - val_acc: 0.7552\n",
      "Epoch 1413/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4087 - acc: 0.7969 - val_loss: 0.5062 - val_acc: 0.7552\n",
      "Epoch 1414/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4087 - acc: 0.7969 - val_loss: 0.5063 - val_acc: 0.7552\n",
      "Epoch 1415/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4087 - acc: 0.7969 - val_loss: 0.5063 - val_acc: 0.7552\n",
      "Epoch 1416/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4086 - acc: 0.7969 - val_loss: 0.5063 - val_acc: 0.7552\n",
      "Epoch 1417/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4087 - acc: 0.7951 - val_loss: 0.5063 - val_acc: 0.7552\n",
      "Epoch 1418/1500\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4086 - acc: 0.7969 - val_loss: 0.5063 - val_acc: 0.7552\n",
      "Epoch 1419/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4086 - acc: 0.7969 - val_loss: 0.5063 - val_acc: 0.7552\n",
      "Epoch 1420/1500\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4086 - acc: 0.7969 - val_loss: 0.5063 - val_acc: 0.7552\n",
      "Epoch 1421/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4086 - acc: 0.7969 - val_loss: 0.5063 - val_acc: 0.7552\n",
      "Epoch 1422/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4085 - acc: 0.7969 - val_loss: 0.5064 - val_acc: 0.7552\n",
      "Epoch 1423/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4085 - acc: 0.7969 - val_loss: 0.5064 - val_acc: 0.7552\n",
      "Epoch 1424/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4085 - acc: 0.7969 - val_loss: 0.5064 - val_acc: 0.7552\n",
      "Epoch 1425/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4085 - acc: 0.7969 - val_loss: 0.5064 - val_acc: 0.7552\n",
      "Epoch 1426/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4085 - acc: 0.7969 - val_loss: 0.5064 - val_acc: 0.7552\n",
      "Epoch 1427/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4085 - acc: 0.7969 - val_loss: 0.5065 - val_acc: 0.7552\n",
      "Epoch 1428/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4085 - acc: 0.7969 - val_loss: 0.5065 - val_acc: 0.7552\n",
      "Epoch 1429/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4085 - acc: 0.7969 - val_loss: 0.5065 - val_acc: 0.7552\n",
      "Epoch 1430/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4084 - acc: 0.7969 - val_loss: 0.5066 - val_acc: 0.7552\n",
      "Epoch 1431/1500\n",
      "576/576 [==============================] - 0s 179us/step - loss: 0.4084 - acc: 0.7969 - val_loss: 0.5065 - val_acc: 0.7552\n",
      "Epoch 1432/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4084 - acc: 0.7986 - val_loss: 0.5065 - val_acc: 0.7552\n",
      "Epoch 1433/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4084 - acc: 0.7969 - val_loss: 0.5066 - val_acc: 0.7552\n",
      "Epoch 1434/1500\n",
      "576/576 [==============================] - 0s 142us/step - loss: 0.4084 - acc: 0.7986 - val_loss: 0.5066 - val_acc: 0.7552\n",
      "Epoch 1435/1500\n",
      "576/576 [==============================] - 0s 125us/step - loss: 0.4084 - acc: 0.7969 - val_loss: 0.5066 - val_acc: 0.7552\n",
      "Epoch 1436/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4083 - acc: 0.7969 - val_loss: 0.5066 - val_acc: 0.7552\n",
      "Epoch 1437/1500\n",
      "576/576 [==============================] - 0s 200us/step - loss: 0.4083 - acc: 0.7969 - val_loss: 0.5067 - val_acc: 0.7552\n",
      "Epoch 1438/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4083 - acc: 0.7951 - val_loss: 0.5066 - val_acc: 0.7552\n",
      "Epoch 1439/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4083 - acc: 0.7986 - val_loss: 0.5067 - val_acc: 0.7552\n",
      "Epoch 1440/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4083 - acc: 0.7969 - val_loss: 0.5067 - val_acc: 0.7552\n",
      "Epoch 1441/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4083 - acc: 0.7969 - val_loss: 0.5067 - val_acc: 0.7552\n",
      "Epoch 1442/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4082 - acc: 0.7986 - val_loss: 0.5067 - val_acc: 0.7552\n",
      "Epoch 1443/1500\n",
      "576/576 [==============================] - 0s 143us/step - loss: 0.4082 - acc: 0.7986 - val_loss: 0.5067 - val_acc: 0.7552\n",
      "Epoch 1444/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4082 - acc: 0.7969 - val_loss: 0.5068 - val_acc: 0.7552\n",
      "Epoch 1445/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4082 - acc: 0.7969 - val_loss: 0.5068 - val_acc: 0.7552\n",
      "Epoch 1446/1500\n",
      "576/576 [==============================] - 0s 141us/step - loss: 0.4082 - acc: 0.7986 - val_loss: 0.5068 - val_acc: 0.7552\n",
      "Epoch 1447/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4082 - acc: 0.7969 - val_loss: 0.5068 - val_acc: 0.7552\n",
      "Epoch 1448/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4083 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1449/1500\n",
      "576/576 [==============================] - 0s 144us/step - loss: 0.4082 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1450/1500\n",
      "576/576 [==============================] - 0s 153us/step - loss: 0.4081 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1451/1500\n",
      "576/576 [==============================] - 0s 148us/step - loss: 0.4082 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1452/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4081 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1453/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4081 - acc: 0.7969 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1454/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4081 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1455/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4080 - acc: 0.7969 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1456/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4080 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1457/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4080 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1458/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4080 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1459/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4080 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1460/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4080 - acc: 0.7986 - val_loss: 0.5070 - val_acc: 0.7552\n",
      "Epoch 1461/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4080 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1462/1500\n",
      "576/576 [==============================] - 0s 118us/step - loss: 0.4079 - acc: 0.7986 - val_loss: 0.5069 - val_acc: 0.7552\n",
      "Epoch 1463/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4080 - acc: 0.7986 - val_loss: 0.5070 - val_acc: 0.7552\n",
      "Epoch 1464/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4079 - acc: 0.7969 - val_loss: 0.5070 - val_acc: 0.7552\n",
      "Epoch 1465/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4079 - acc: 0.7969 - val_loss: 0.5070 - val_acc: 0.7552\n",
      "Epoch 1466/1500\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.4080 - acc: 0.7986 - val_loss: 0.5070 - val_acc: 0.7552\n",
      "Epoch 1467/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4079 - acc: 0.7969 - val_loss: 0.5070 - val_acc: 0.7552\n",
      "Epoch 1468/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4078 - acc: 0.7986 - val_loss: 0.5070 - val_acc: 0.7552\n",
      "Epoch 1469/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4079 - acc: 0.7969 - val_loss: 0.5070 - val_acc: 0.7552\n",
      "Epoch 1470/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4078 - acc: 0.7969 - val_loss: 0.5071 - val_acc: 0.7552\n",
      "Epoch 1471/1500\n",
      "576/576 [==============================] - 0s 137us/step - loss: 0.4078 - acc: 0.7986 - val_loss: 0.5071 - val_acc: 0.7552\n",
      "Epoch 1472/1500\n",
      "576/576 [==============================] - 0s 134us/step - loss: 0.4078 - acc: 0.7969 - val_loss: 0.5071 - val_acc: 0.7552\n",
      "Epoch 1473/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4078 - acc: 0.7969 - val_loss: 0.5071 - val_acc: 0.7552\n",
      "Epoch 1474/1500\n",
      "576/576 [==============================] - 0s 113us/step - loss: 0.4077 - acc: 0.7969 - val_loss: 0.5072 - val_acc: 0.7552\n",
      "Epoch 1475/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4077 - acc: 0.7986 - val_loss: 0.5072 - val_acc: 0.7552\n",
      "Epoch 1476/1500\n",
      "576/576 [==============================] - 0s 164us/step - loss: 0.4077 - acc: 0.7969 - val_loss: 0.5072 - val_acc: 0.7552\n",
      "Epoch 1477/1500\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.4077 - acc: 0.7986 - val_loss: 0.5073 - val_acc: 0.7552\n",
      "Epoch 1478/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4077 - acc: 0.7986 - val_loss: 0.5073 - val_acc: 0.7552\n",
      "Epoch 1479/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4077 - acc: 0.7969 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 1480/1500\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4077 - acc: 0.7969 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 1481/1500\n",
      "576/576 [==============================] - 0s 130us/step - loss: 0.4077 - acc: 0.7969 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 1482/1500\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4076 - acc: 0.7986 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 1483/1500\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4076 - acc: 0.7969 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 1484/1500\n",
      "576/576 [==============================] - 0s 138us/step - loss: 0.4076 - acc: 0.7969 - val_loss: 0.5075 - val_acc: 0.7552\n",
      "Epoch 1485/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4076 - acc: 0.7969 - val_loss: 0.5075 - val_acc: 0.7552\n",
      "Epoch 1486/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4075 - acc: 0.7969 - val_loss: 0.5075 - val_acc: 0.7552\n",
      "Epoch 1487/1500\n",
      "576/576 [==============================] - 0s 111us/step - loss: 0.4075 - acc: 0.7969 - val_loss: 0.5075 - val_acc: 0.7552\n",
      "Epoch 1488/1500\n",
      "576/576 [==============================] - 0s 112us/step - loss: 0.4076 - acc: 0.7969 - val_loss: 0.5075 - val_acc: 0.7552\n",
      "Epoch 1489/1500\n",
      "576/576 [==============================] - 0s 140us/step - loss: 0.4076 - acc: 0.7969 - val_loss: 0.5076 - val_acc: 0.7552\n",
      "Epoch 1490/1500\n",
      "576/576 [==============================] - 0s 133us/step - loss: 0.4075 - acc: 0.7969 - val_loss: 0.5076 - val_acc: 0.7552\n",
      "Epoch 1491/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4074 - acc: 0.7969 - val_loss: 0.5076 - val_acc: 0.7552\n",
      "Epoch 1492/1500\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.4074 - acc: 0.7969 - val_loss: 0.5076 - val_acc: 0.7552\n",
      "Epoch 1493/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4074 - acc: 0.7969 - val_loss: 0.5076 - val_acc: 0.7552\n",
      "Epoch 1494/1500\n",
      "576/576 [==============================] - 0s 135us/step - loss: 0.4074 - acc: 0.7969 - val_loss: 0.5077 - val_acc: 0.7552\n",
      "Epoch 1495/1500\n",
      "576/576 [==============================] - 0s 108us/step - loss: 0.4074 - acc: 0.7969 - val_loss: 0.5077 - val_acc: 0.7552\n",
      "Epoch 1496/1500\n",
      "576/576 [==============================] - 0s 132us/step - loss: 0.4073 - acc: 0.7969 - val_loss: 0.5077 - val_acc: 0.7552\n",
      "Epoch 1497/1500\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.4073 - acc: 0.7969 - val_loss: 0.5077 - val_acc: 0.7552\n",
      "Epoch 1498/1500\n",
      "576/576 [==============================] - 0s 121us/step - loss: 0.4074 - acc: 0.7969 - val_loss: 0.5078 - val_acc: 0.7552\n",
      "Epoch 1499/1500\n",
      "576/576 [==============================] - 0s 129us/step - loss: 0.4073 - acc: 0.7969 - val_loss: 0.5078 - val_acc: 0.7552\n",
      "Epoch 1500/1500\n",
      "576/576 [==============================] - 0s 136us/step - loss: 0.4073 - acc: 0.7969 - val_loss: 0.5078 - val_acc: 0.7552\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\")) # output layer - 1 node to predict 1 or 0\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"acc\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_acc\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.755\n",
      "roc-auc is 0.812\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "prev_pub_hash": "30b1fc428859ab438b764ed616fdf71d5544d8828f0effc96e9c74ccabbdc852"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
